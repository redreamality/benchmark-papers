[
  {
    "id": 1,
    "title": "A New Benchmark and Model for Challenging Image Manipulation Detection",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2,
    "title": "A Survey of Learning Criteria Going beyond the Usual Risk (Abstract Reprint)",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 3,
    "title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 4,
    "title": "Advancing Video Synchronization with Fractional Frame Analysis: Introducing a Novel Dataset and Model",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 5,
    "title": "Adventures of Trustworthy Vision-Language Models: A Survey",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 6,
    "title": "BAND: Biomedical Alert News Dataset",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 7,
    "title": "BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 8,
    "title": "Better than Random: Reliable NLG Human Evaluation with Constrained Active Sampling",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 9,
    "title": "BirdCollect: A Comprehensive Benchmark for Analyzing Dense Bird Flock Attributes",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 10,
    "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 11,
    "title": "CK12: A Rounded K12 Knowledge Graph Based Benchmark for Chinese Holistic Cognition Evaluation",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 12,
    "title": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks for Chinese Large Language Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 13,
    "title": "Cross-Covariate Gait Recognition: A Benchmark",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 14,
    "title": "DINGO: Towards Diverse and Fine-Grained Instruction-Following Evaluation",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 15,
    "title": "DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 16,
    "title": "DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 17,
    "title": "DexFuncGrasp: A Robotic Dexterous Functional Grasp Dataset Constructed from a Cost-Effective Real-Simulation Annotation System",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 18,
    "title": "Dialogues Are Not Just Text: Modeling Cognition for Dialogue Coherence Evaluation",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 19,
    "title": "Distributional Off-Policy Evaluation for Slate Recommendations",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 20,
    "title": "Diverse Person: Customize Your Own Dataset for Text-Based Person Search",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 21,
    "title": "DocMSU: A Comprehensive Benchmark for Document-Level Multimodal Sarcasm Understanding",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 22,
    "title": "Domain Generalizable Person Search Using Unreal Dataset",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 23,
    "title": "Exploring Domain Incremental Video Highlights Detection with the LiveFood Benchmark",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 24,
    "title": "GLH-Water: A Large-Scale Dataset for Global Surface Water Detection in Large-Size Very-High-Resolution Satellite Imagery",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 25,
    "title": "GSDD: Generative Space Dataset Distillation for Image Super-resolution",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 26,
    "title": "Generalized Planning for the Abstraction and Reasoning Corpus",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 27,
    "title": "HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using Harvest Piles and Remote Sensing",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 28,
    "title": "How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 29,
    "title": "HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 30,
    "title": "I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets Initiatives",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 31,
    "title": "Improving Automatic VQA Evaluation Using Large Language Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 32,
    "title": "IndicCONAN: A Multilingual Dataset for Combating Hate Speech in Indian Context",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 33,
    "title": "InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 34,
    "title": "Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 35,
    "title": "Iterative Token Evaluation and Refinement for Real-World Super-resolution",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 36,
    "title": "LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 37,
    "title": "M3D: Dataset Condensation by Minimizing Maximum Mean Discrepancy",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 38,
    "title": "MESED: A Multi-Modal Entity Set Expansion Dataset with Fine-Grained Semantic Classes and Hard Negative Entities",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 39,
    "title": "MID-FiLD: MIDI Dataset for Fine-Level Dynamics",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 40,
    "title": "MedAlign: A Clinician-Generated Dataset for Instruction Following with Electronic Medical Records",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 41,
    "title": "MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 42,
    "title": "Mixed Fair Division: A Survey",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 43,
    "title": "NuScenes-QA: A Multi-Modal Visual Question Answering Benchmark for Autonomous Driving Scenario",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 44,
    "title": "PoseGen: Learning to Generate 3D Human Pose Dataset with NeRF",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 45,
    "title": "QuerySum: A Multi-Document Query-Focused Summarization Dataset Augmented with Similar Query Clusters",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 46,
    "title": "Robust Evaluation Measures for Evaluating Social Biases in Masked Language Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 47,
    "title": "SDAC: A Multimodal Synthetic Dataset for Anomaly and Corner Case Detection in Autonomous Driving",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 48,
    "title": "Scaling Offline Evaluation of Reinforcement Learning Agents through Abstraction",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 49,
    "title": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 50,
    "title": "SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 51,
    "title": "SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in Generative Language Models",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 52,
    "title": "Spanning the Spectrum of Hatred Detection: A Persian Multi-Label Hate Speech Dataset with Annotator Rationales",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 53,
    "title": "Talk Funny! A Large-Scale Humor Response Dataset with Chain-of-Humor Interpretation",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 54,
    "title": "Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 55,
    "title": "Towards Automated Chinese Ancient Character Restoration: A Diffusion-Based Method with a New Dataset",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 56,
    "title": "Visual Redundancy Removal for Composite Images: A Benchmark Dataset and a Multi-Visual-Effects Driven Incremental Method",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 57,
    "title": "WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 58,
    "title": "Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation",
    "conference": "AAAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 59,
    "title": "3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 60,
    "title": "A Black-Box Evaluation Framework for Semantic Robustness in Bird’s Eye View Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 61,
    "title": "A Comprehensive Evaluation on Event Reasoning of Large Language Models",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 62,
    "title": "A Novel Diffusion Model for Pairwise Geoscience Data Generation with Unbalanced Training Dataset",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 63,
    "title": "A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 64,
    "title": "A Simple and Comprehensive Benchmark for Single-Cell Transcriptomics",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 65,
    "title": "A Video-grounded Dialogue Dataset and Metric for Event-driven Activities",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 66,
    "title": "ALLVB: All-in-One Long Video Understanding Benchmark",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 67,
    "title": "Adaptive Dataset Quantization",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 68,
    "title": "Alignment-Free RGB-T Salient Object Detection: A Large-Scale Dataset and Progressive Correlation Network",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 69,
    "title": "An Evaluation Framework for Product Images Background Inpainting Based on Human Feedback and Product Consistency",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 70,
    "title": "BeyondGender: A Multifaceted Bilingual Dataset for Practical Sexism Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 71,
    "title": "Bi-Directional Multi-Scale Graph Dataset Condensation via Information Bottleneck",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 72,
    "title": "CROSSNEWS: A Cross-Genre Authorship Verification and Attribution Benchmark",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 73,
    "title": "CUPCase: Clinically Uncommon Patient Cases and Diagnoses Dataset",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 74,
    "title": "CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 75,
    "title": "Can LVLMs Obtain a Driver’s License? A Benchmark Towards Reliable AGI for Autonomous Driving",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 76,
    "title": "CoMT: A Novel Benchmark for Chain of Multi-modal Thought on Large Vision-Language Models",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 77,
    "title": "ComprehendEdit: A Comprehensive Dataset and Evaluation Framework for Multimodal Knowledge Editing",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 78,
    "title": "ConceptSearch: Towards Efficient Program Search Using LLMs for Abstraction and Reasoning Corpus (ARC)",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 79,
    "title": "Constrained Offline Black-Box Optimization via Risk Evaluation and Management",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 80,
    "title": "CraftFactory: A Conditioned Control Policy Benchmark for Compositional Generalization",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 81,
    "title": "Cross-Validated Off-Policy Evaluation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 82,
    "title": "DMT-RoleBench: A Dynamic Multi-Turn Dialogue Based Benchmark for Role-Playing Evaluation of Large Language Model and Agent",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 83,
    "title": "DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 84,
    "title": "Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 85,
    "title": "Defeasible Visual Entailment: Benchmark, Evaluator, and Reward-Driven Optimization",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 86,
    "title": "Distributionally Robust Policy Evaluation and Learning for Continuous Treatment with Observational Data",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 87,
    "title": "EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 88,
    "title": "ERF: A Benchmark Dataset for Robust Semantic Segmentation Under Extreme Rainfall Conditions",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 89,
    "title": "EXCGEC: A Benchmark for Edit-Wise Explainable Chinese Grammatical Error Correction",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 90,
    "title": "Each Fake News Is Fake in Its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 91,
    "title": "EditBoard: Towards a Comprehensive Evaluation Benchmark for Text-Based Video Editing Models",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 92,
    "title": "Efficient Multi-Policy Evaluation for Reinforcement Learning",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 93,
    "title": "Efficient Robustness Evaluation via Constraint Relaxation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 94,
    "title": "Evaluating the Evaluator: Measuring LLMs’ Adherence to Task Evaluation Instructions",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 95,
    "title": "EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese Multi-News Documents",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 96,
    "title": "EvoChart: A Benchmark and a Self-Training Approach Towards Real-World Chart Understanding",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 97,
    "title": "Expand VSR Benchmark for VLLM to Expertize in Spatial Rules",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 98,
    "title": "Exploring Intrinsic Alignments Within Text Corpus",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 99,
    "title": "Fields of The World: A Machine Learning Benchmark Dataset for Global Agricultural Field Boundary Segmentation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 100,
    "title": "Fine-Grained Perception in Panoramic Scenes: A Novel Task, Dataset, and Method for Object Importance Ranking",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 101,
    "title": "FlexDataset: Crafting Annotated Dataset Generation for Diverse Applications",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 102,
    "title": "Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 103,
    "title": "FriendsQA: A New Large-Scale Deep Video Understanding Dataset with Fine-grained Topic Categorization for Story Videos",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 104,
    "title": "GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 105,
    "title": "Game4Loc: A UAV Geo-Localization Benchmark from Game Data",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 106,
    "title": "Geodesic Flow Kernels for Semi-Supervised Learning on Mixed-Variable Tabular Dataset",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 107,
    "title": "Graph-Based Cross-Domain Knowledge Distillation for Cross-Dataset Text-to-Image Person Retrieval",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 108,
    "title": "HSOD-BIT-V2: A Challenging Benchmark for Hyperspectral Salient Object Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 109,
    "title": "Hierarchical Divide-and-Conquer for Fine-Grained Alignment in LLM-Based Medical Evaluation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 110,
    "title": "Identity-Text Video Corpus Grounding",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 111,
    "title": "In-Dataset Trajectory Return Regularization for Offline Preference-based Reinforcement Learning",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 112,
    "title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 113,
    "title": "MM-CamObj: A Comprehensive Multimodal Dataset for Camouflaged Object Scenarios",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 114,
    "title": "M^3EL: A Multi-task Multi-topic Dataset for Multi-modal Entity Linking",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 115,
    "title": "McHirc: A Multimodal Benchmark for Chinese Idiom Reading Comprehension",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 116,
    "title": "Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 117,
    "title": "Multi-View Pedestrian Occupancy Prediction with a Novel Synthetic Dataset",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 118,
    "title": "NightReID: A Large-Scale Nighttime Person Re-Identification Benchmark",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 119,
    "title": "ObjVariantEnsemble: Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Objects",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 120,
    "title": "On the Power of Strategic Corpus Enrichment in Content Creation Games",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 121,
    "title": "Pedestrian Attribute Recognition: A New Benchmark Dataset and a Large Language Model Augmented Framework",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 122,
    "title": "Pioneering Explainable Video Fact-Checking with a New Dataset and Multi-role Multimodal Model Approach",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 123,
    "title": "Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 124,
    "title": "RA-GAR: A Richly Annotated Benchmark for Gait Attribute Recognition",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 125,
    "title": "RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 126,
    "title": "Representing Sounds as Neural Amplitude Fields: A Benchmark of Coordinate-MLPs and a Fourier Kolmogorov-Arnold Framework",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 127,
    "title": "SIDL: A Real-World Dataset for Restoring Smartphone Images with Dirty Lenses",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 128,
    "title": "Seeing Beyond Noise: Joint Graph Structure Evaluation and Denoising for Multimodal Recommendation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 129,
    "title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 130,
    "title": "Sentence-level Aggregation of Lexical Metrics Correlates Stronger with Human Judgements than Corpus-level Aggregation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 131,
    "title": "TableBench: A Comprehensive and Complex Benchmark for Table Question Answering",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 132,
    "title": "Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 133,
    "title": "Thermal-Aware Low-Light Image Enhancement: A Real-World Benchmark and a New Light-Weight Model",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 134,
    "title": "Towards Adversarially Robust Dataset Distillation by Curvature Regularization",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 135,
    "title": "Towards Audio-Visual Navigation in Noisy Environments: A Large-Scale Benchmark Dataset and an Architecture Considering Multiple Sound-Sources",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 136,
    "title": "Towards Efficient and Intelligent Laser Weeding: Method and Dataset for Weed Stem Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 137,
    "title": "Towards Ship License Plate Recognition in the Wild: A Large Benchmark and Strong Baseline",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 138,
    "title": "Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 139,
    "title": "Towards Universal Rainy Image Restoration: Benchmark and Baseline",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 140,
    "title": "Training on the Benchmark Is Not All You Need",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 141,
    "title": "TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 142,
    "title": "UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 143,
    "title": "UniDet3D: Multi-dataset Indoor 3D Object Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 144,
    "title": "Unsupervised Anomaly Detection for Tabular Data Using Deep Noise Evaluation",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 145,
    "title": "UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 146,
    "title": "UrbanWaste: In-the-Bin Dataset for Waste Disposal Inspection with Multi-Granularity Hierarchical Labels",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 147,
    "title": "VE-Bench: Subjective-Aligned Benchmark Suite for Text-Driven Video Editing Quality Assessment",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 148,
    "title": "ViFactCheck: A New Benchmark Dataset and Methods for Multi-Domain News Fact-Checking In Vietnamese",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 149,
    "title": "VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 150,
    "title": "VidSole: A Multimodal Dataset for Joint Kinetics Quantification and Disease Detection with Deep Learning",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 151,
    "title": "Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 152,
    "title": "When Hypergraph Meets Heterophily: New Benchmark Datasets and Baseline",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 153,
    "title": "When Open-Vocabulary Visual Question Answering Meets Causal Adapter: Benchmark and Approach",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 154,
    "title": "WildFake: A Large-Scale and Hierarchical Dataset for AI-Generated Images Detection",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 155,
    "title": "Zero-Shot Learning in Industrial Scenarios: New Large-Scale Benchmark, Challenges and Baseline",
    "conference": "AAAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 156,
    "title": "A Benchmark Study on Calibration",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 157,
    "title": "A Benchmark for Learning to Translate a New Language from One Grammar Book",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 158,
    "title": "ADOPD: A Large-Scale Document Page Decomposition Dataset",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 159,
    "title": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 160,
    "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 161,
    "title": "CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 162,
    "title": "Consistent Video-to-Video Transfer Using Synthetic Dataset",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 163,
    "title": "DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 164,
    "title": "Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 165,
    "title": "DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 166,
    "title": "EX-Graph: A Pioneering Dataset Bridging Ethereum and X",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 167,
    "title": "Embarrassingly Simple Dataset Distillation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 168,
    "title": "Energy-based Automated Model Evaluation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 169,
    "title": "FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 170,
    "title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 171,
    "title": "FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 172,
    "title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 173,
    "title": "GAIA: a benchmark for General AI Assistants",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 174,
    "title": "GIO: Gradient Information Optimization for Training Dataset Selection",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 175,
    "title": "ImagenHub: Standardizing the evaluation of conditional image generation models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 176,
    "title": "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 177,
    "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 178,
    "title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 179,
    "title": "Light-MILPopt: Solving Large-scale Mixed Integer Linear Programs with Lightweight Optimizer and Small-scale Training Dataset",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 180,
    "title": "MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 181,
    "title": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 182,
    "title": "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 183,
    "title": "MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 184,
    "title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 185,
    "title": "Multisize Dataset Condensation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 186,
    "title": "Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 187,
    "title": "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 188,
    "title": "On Trajectory Augmentations for Off-Policy Evaluation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 189,
    "title": "Online GNN Evaluation Under Test-time Graph Distribution Shifts",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 190,
    "title": "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 191,
    "title": "PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 192,
    "title": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 193,
    "title": "Predicting Emergent Abilities with Infinite Resolution Evaluation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 194,
    "title": "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 195,
    "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 196,
    "title": "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 197,
    "title": "Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 198,
    "title": "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 199,
    "title": "Robust NAS under adversarial training: benchmark, theory, and beyond",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 200,
    "title": "SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 201,
    "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 202,
    "title": "STREAM: Spatio-TempoRal Evaluation and  Analysis Metric for Video Generative Models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 203,
    "title": "Self-Supervised Dataset Distillation for Transfer Learning",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 204,
    "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 205,
    "title": "SmartPlay : A Benchmark for LLMs as Intelligent Agents",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 206,
    "title": "The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 207,
    "title": "Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 208,
    "title": "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 209,
    "title": "Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 210,
    "title": "Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 211,
    "title": "Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 212,
    "title": "Training Unbiased Diffusion Models From Biased Dataset",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 213,
    "title": "Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 214,
    "title": "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 215,
    "title": "VFLAIR: A Research Library and Benchmark for Vertical Federated Learning",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 216,
    "title": "ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 217,
    "title": "Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML",
    "conference": "ICLR",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 218,
    "title": "(Mis)Fitting Scaling Laws: A Survey of Scaling Law Fitting Techniques in Deep Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 219,
    "title": "A Benchmark for Semantic Sensitive Information in LLMs Outputs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 220,
    "title": "A Decade's Battle on Dataset Bias: Are We There Yet?",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 221,
    "title": "A Large-scale Dataset and Benchmark for Commuting Origin-Destination Flow Generation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 222,
    "title": "AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 223,
    "title": "AIR-BENCH 2024: A Safety Benchmark based on Regulation and Policies Specified Risk Categories",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 224,
    "title": "API Pack: A Massive Multi-Programming Language Dataset for API Call Generation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 225,
    "title": "AVHBench: A Cross-Modal Hallucination Benchmark for Audio-Visual Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 226,
    "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 227,
    "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 228,
    "title": "AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 229,
    "title": "AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 230,
    "title": "AutoBencher: Towards Declarative Benchmark Construction",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 231,
    "title": "Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 232,
    "title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 233,
    "title": "Behavioral Entropy-Guided Dataset Generation for Offline Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 234,
    "title": "BenTo: Benchmark Reduction with In-Context Transferability",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 235,
    "title": "Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 236,
    "title": "Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 237,
    "title": "Beyond FVD: An Enhanced Evaluation Metrics for Video Generation Distribution Quality",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 238,
    "title": "Beyond correlation: The impact of human uncertainty in measuring the effectiveness of automatic evaluation and LLM-as-a-judge",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 239,
    "title": "BigDocs: An Open Dataset for Training Multimodal Models on Document and Code Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 240,
    "title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 241,
    "title": "BoneMet: An Open Large-Scale Multi-Modal Murine Dataset for Breast Cancer Bone Metastasis Diagnosis and Prognosis",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 242,
    "title": "Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 243,
    "title": "Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 244,
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 245,
    "title": "CG-Bench: Clue-grounded Question Answering Benchmark for Long Video Understanding",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 246,
    "title": "CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 247,
    "title": "CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 248,
    "title": "Century: A Framework and Dataset for Evaluating Historical Contextualisation of Sensitive Images",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 249,
    "title": "CertainlyUncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 250,
    "title": "ClimaQA: An Automated Evaluation Framework for Climate Question Answering Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 251,
    "title": "CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding & Reasoning Capabilities of CodeLLMs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 252,
    "title": "CofCA: A STEP-WISE Counterfactual Multi-hop QA benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 253,
    "title": "Cross-Domain Off-Policy Evaluation and Learning for Contextual Bandits",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 254,
    "title": "Cross-Domain Offline Policy Adaptation with Optimal Transport and Dataset Constraint",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 255,
    "title": "Data Taggants: Dataset Ownership Verification Via Harmless Targeted Data Poisoning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 256,
    "title": "DataGen: Unified Synthetic Dataset Generation via Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 257,
    "title": "Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 258,
    "title": "Dataset Ownership Verification in Contrastive Pre-trained Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 259,
    "title": "Distilling Dataset into Neural Field",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 260,
    "title": "Do Contemporary Causal Inference Models Capture Real-World Heterogeneity? Findings from a Large-Scale Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 261,
    "title": "Doubly Optimal Policy Evaluation for Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 262,
    "title": "DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 263,
    "title": "DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 264,
    "title": "Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 265,
    "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 266,
    "title": "Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception Ability of LVLMs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 267,
    "title": "ECD: A Machine Learning Benchmark for Predicting Enhanced-Precision Electronic Charge Density in Crystalline Inorganic Materials",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 268,
    "title": "Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 269,
    "title": "Efficient Policy Evaluation with Safety Constraint for Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 270,
    "title": "Episodic Memories Generation and Evaluation Benchmark for Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 271,
    "title": "Exploring Learning Complexity for Efficient Downstream Dataset Pruning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 272,
    "title": "F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 273,
    "title": "Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 274,
    "title": "Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 275,
    "title": "ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 276,
    "title": "FormalAlign: Automated Alignment Evaluation for Autoformalization",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 277,
    "title": "GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 278,
    "title": "GLoRa: A Benchmark to Evaluate the Ability to Learn Long-Range Dependencies in Graphs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 279,
    "title": "GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 280,
    "title": "GenDataAgent: On-the-fly Dataset Augmentation with Synthetic Data",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 281,
    "title": "GeoILP: A Synthetic Dataset to Guide Large-Scale Rule Induction",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 282,
    "title": "GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 283,
    "title": "Going Beyond Feature Similarity: Effective Dataset distillation based on Class-aware Conditional Mutual Information",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 284,
    "title": "GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 285,
    "title": "Group Distributionally Robust Dataset Distillation with Risk Minimization",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 286,
    "title": "HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 287,
    "title": "HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 288,
    "title": "HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 289,
    "title": "HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 290,
    "title": "Has the Deep Neural Network learned the Stochastic Process? An Evaluation Viewpoint",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 291,
    "title": "Herald: A Natural Language Annotated Lean 4 Dataset",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 292,
    "title": "Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 293,
    "title": "How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 294,
    "title": "How efficient is LLM-generated code? A rigorous & high-standard benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 295,
    "title": "How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 296,
    "title": "IGL-Bench: Establishing the Comprehensive Benchmark for Imbalanced Graph Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 297,
    "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 298,
    "title": "Influence-Guided Diffusion for Dataset Distillation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 299,
    "title": "InvestESG: A multi-agent reinforcement learning benchmark for studying climate investment as a social dilemma",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 300,
    "title": "JudgeBench: A Benchmark for Evaluating LLM-Based Judges",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 301,
    "title": "K-HALU: Multiple Answer Korean Hallucination Benchmark for Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 302,
    "title": "LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 303,
    "title": "LR0.FM: Low-Res Benchmark and  Improving robustness for Zero-Shot Classification in Foundation Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 304,
    "title": "Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 305,
    "title": "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 306,
    "title": "Limits to scalable evaluation at the frontier: LLM as judge won’t beat twice the data",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 307,
    "title": "LiveBench: A Challenging, Contamination-Limited LLM Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 308,
    "title": "LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 309,
    "title": "LiveXiv - A Multi-Modal live benchmark based on Arxiv papers content",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 310,
    "title": "LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 311,
    "title": "MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 312,
    "title": "MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 313,
    "title": "MMAD: A Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 314,
    "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 315,
    "title": "MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 316,
    "title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 317,
    "title": "MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 318,
    "title": "MMR: A Large-scale Benchmark Dataset for Multi-target and Multi-granularity Reasoning Segmentation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 319,
    "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 320,
    "title": "MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 321,
    "title": "MR-GSM8K: A Meta-Reasoning Benchmark for Large Language Model Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 322,
    "title": "MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 323,
    "title": "MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 324,
    "title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 325,
    "title": "ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home Rearrangement Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 326,
    "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 327,
    "title": "McEval: Massively Multilingual Code Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 328,
    "title": "MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 329,
    "title": "MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 330,
    "title": "NutriBench: A Dataset for Evaluating Large Language Models in Nutrition Estimation from Meal Descriptions",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 331,
    "title": "OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 332,
    "title": "Omni-MATH: A Universal Olympiad Level Mathematic Benchmark for Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 333,
    "title": "OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 334,
    "title": "On Speeding Up Language Model Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 335,
    "title": "OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 336,
    "title": "PALMBENCH: A COMPREHENSIVE BENCHMARK OF COMPRESSED LARGE LANGUAGE MODELS ON MOBILE PLATFORMS",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 337,
    "title": "PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 338,
    "title": "POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 339,
    "title": "Painting with Words: Elevating Detailed Image Captioning with Benchmark and Alignment Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 340,
    "title": "Pedestrian Motion Reconstruction: A Large-scale Benchmark via Mixed Reality Rendering with Multiple Perspectives and Modalities",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 341,
    "title": "PhysPDE: Rethinking PDE Discovery and a Physical Hypothesis Selection Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 342,
    "title": "Physiome-ODE: A Benchmark for Irregularly Sampled Multivariate Time-Series Forecasting Based on Biological ODEs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 343,
    "title": "PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 344,
    "title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 345,
    "title": "Predictive Uncertainty Quantification for Bird's Eye View Segmentation: A Benchmark and Novel Loss Function",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 346,
    "title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 347,
    "title": "RGB-Event ISP: The Dataset and Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 348,
    "title": "Re-evaluating Open-ended Evaluation of Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 349,
    "title": "ReSi: A Comprehensive Benchmark for Representational Similarity Measures",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 350,
    "title": "Realistic Evaluation of Deep Partial-Label Learning Algorithms",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 351,
    "title": "RecFlow: An Industrial Full Flow Recommendation Dataset",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 352,
    "title": "Reframing Structure-Based Drug Design Model Evaluation via Metrics Correlated to Practical Needs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 353,
    "title": "Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 354,
    "title": "Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 355,
    "title": "Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 356,
    "title": "Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 357,
    "title": "Revisiting text-to-image evaluation with Gecko: on metrics, prompts, and human rating",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 358,
    "title": "Robotouille: An Asynchronous Planning Benchmark for LLM Agents",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 359,
    "title": "Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 360,
    "title": "RocketEval: Efficient automated LLM evaluation via grading checklist",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 361,
    "title": "SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 362,
    "title": "SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 363,
    "title": "ST-GCond: Self-supervised and Transferable Graph Dataset Condensation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 364,
    "title": "SVBench: A Benchmark with Temporal Multi-Turn Dialogues for Streaming Video Understanding",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 365,
    "title": "SWEb: A Large Web Dataset for the Scandinavian Languages",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 366,
    "title": "ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 367,
    "title": "Shot2Story: A New Benchmark for Comprehensive Understanding of Multi-shot Videos",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 368,
    "title": "SimXRD-4M: Big Simulated X-ray Diffraction Data and Crystal Symmetry Classification Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 369,
    "title": "Size-Generalizable RNA Structure Evaluation by Exploring Hierarchical Geometries",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 370,
    "title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 371,
    "title": "SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus Searches",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 372,
    "title": "Speech Robust Bench: A Robustness Benchmark For Speech Recognition",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 373,
    "title": "Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 374,
    "title": "Structuring Benchmark into Knowledge Graphs to Assist Large Language Models in Retrieving and Designing Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 375,
    "title": "TAU-106K: A New Dataset for Comprehensive Understanding of Traffic Accident",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 376,
    "title": "TDDBench: A Benchmark for Training data detection",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 377,
    "title": "TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 378,
    "title": "Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 379,
    "title": "TestGenEval: A Real World Unit Test Generation and Test Completion Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 380,
    "title": "The 3D-PC: a benchmark for visual perspective taking in humans and machines",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 381,
    "title": "The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "corpus"
    ]
  },
  {
    "id": 382,
    "title": "Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 383,
    "title": "Towards Synergistic Path-based Explanations for Knowledge Graph Completion: Exploration and Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 384,
    "title": "Training on the Test Task Confounds Evaluation and Emergence",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 385,
    "title": "Training-Free Dataset Pruning for Instance Segmentation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 386,
    "title": "UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 387,
    "title": "Uni$^2$Det: Unified and Universal Framework for Prompt-Guided Multi-dataset 3D Detection",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 388,
    "title": "UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 389,
    "title": "UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 390,
    "title": "Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 391,
    "title": "VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical Reasoning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 392,
    "title": "VTDexManip: A Dataset and Benchmark for Visual-tactile Pretraining and Dexterous Manipulation with Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 393,
    "title": "Vec2Face: Scaling Face Dataset Generation with Loosely Constrained Vectors",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 394,
    "title": "Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 395,
    "title": "Ward: Provable RAG Dataset Inference via LLM Watermarks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 396,
    "title": "XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 397,
    "title": "YouTube-SL-25: A Large-Scale, Open-Domain Multilingual Sign Language Parallel Corpus",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 398,
    "title": "Youku Dense Caption: A Large-scale Chinese Video Dense Caption Dataset and Benchmarks",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 399,
    "title": "ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 400,
    "title": "Zero-cost Proxy for Adversarial Robustness Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 401,
    "title": "metabench - A Sparse Benchmark of Reasoning and Knowledge in Large Language Models",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 402,
    "title": "xFinder: Large Language Models as Automated Evaluators for Reliable Evaluation",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 403,
    "title": "{$\\tau$}-bench: A Benchmark for \\underline{T}ool-\\underline{A}gent-\\underline{U}ser Interaction in Real-World Domains",
    "conference": "ICLR",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 404,
    "title": "$PhyWorldBench$: A Comprehensive Evaluation of Physical Realism in Text-to-Video Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 405,
    "title": "3DCS: Datasets and Benchmark for Evaluating Conformational Sensitivity in Molecular Representations",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 406,
    "title": "A Benchmark for Deep Information Synthesis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 407,
    "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 408,
    "title": "A High Quality Dataset and Reliable Evaluation for Interleaved Image-Text Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 409,
    "title": "A Relative Error-Based Evaluation Framework of Heterogeneous Treatment Effect Estimators",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 410,
    "title": "A Statistical Benchmark for Diffusion Posterior Sampling Algorithms",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 411,
    "title": "A Structured, Tagged, and Localized Visual Question Answering Dataset with Full Sentence Answers and Scene Graphs for Chest X-ray Images",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 412,
    "title": "A Unifying View of Coverage in Linear Off-policy Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 413,
    "title": "A2ASecBench: A Protocol-Aware Security Benchmark for Agent-to-Agent Multi-Agent Systems",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 414,
    "title": "ADM-v2: Pursuing Full-Horizon Roll-out in Dynamics Models for Offline Policy Learning and Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 415,
    "title": "AFD-INSTRUCTION: A Comprehensive Antibody Instruction Dataset with Functional Annotations for LLM-Based Understanding and Design",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 416,
    "title": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 417,
    "title": "ATLAS: Alibaba Dataset and Benchmark for Learning-Augmented Scheduling",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 418,
    "title": "Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 419,
    "title": "Accessible, Realistic, and Fair Evaluation of Positive-Unlabeled Learning Algorithms",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 420,
    "title": "AdAEM: An Adaptively and Automated Extensible Evaluation Method of LLMs' Value Difference",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 421,
    "title": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 422,
    "title": "An Open-Ended Benchmark and Formal Framework for Adjuvant Research with MLLM",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 423,
    "title": "AnesSuite: A Comprehensive Benchmark and Dataset Suite for Anesthesiology Reasoning in LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 424,
    "title": "Are EEG Foundation Models Worth It? Comparative Evaluation with Traditional Decoders in Diverse BCI Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 425,
    "title": "Asymmetric Synthetic Data Update for Domain Incremental Dataset Distillation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 426,
    "title": "Asynchronous Matching with Dynamic Sampling for Multimodal Dataset Distillation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 427,
    "title": "AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 428,
    "title": "AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 429,
    "title": "BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Behavioural Change",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 430,
    "title": "BANZ-FS: BANZSL Fingerspelling Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 431,
    "title": "BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation via Lens of Dynamic Interactions",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 432,
    "title": "BTZSC: A Benchmark for Zero-Shot Text Classification Across Cross-Encoders, Embedding Models, and Rerankers",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 433,
    "title": "Battery Fault: A Comprehensive Dataset and Benchmark for Battery Fault Diagnosis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 434,
    "title": "Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 435,
    "title": "Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 436,
    "title": "Beyond the Heatmap: A Rigorous Evaluation of Component Impact in MCTS-Based TSP Solvers",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 437,
    "title": "BeyondBench: Benchmark-Free Evaluation of Reasoning in Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 438,
    "title": "BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 439,
    "title": "BiasScope: Towards Automated Detection of Bias in LLM-as-a-Judge Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 440,
    "title": "BigMac3D: A Big Macaque Motion and Animation Dataset Bridging Image and 3D Pose Representations",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 441,
    "title": "CAGE: A Framework for Culturally Adaptive Red-Teaming Benchmark Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 442,
    "title": "CAPSUL: A Comprehensive Human Protein Benchmark for Subcellular Localization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 443,
    "title": "CIMemories: A Compositional Benchmark For Contextual Integrity In LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 444,
    "title": "CLARC: C/C++ Benchmark for Robust Code Search",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 445,
    "title": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 446,
    "title": "CMT-Benchmark: A Benchmark for Condensed Matter Theory Built by Expert Researchers",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 447,
    "title": "CTBench: Cryptocurrency Time Series Generation Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 448,
    "title": "CaReBench: A Fine-grained Benchmark for Video Captioning and Retrieval",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 449,
    "title": "Can Vision–Language Models Assess Graphic Design Aesthetics? A Benchmark, Evaluation, and Dataset Perspective.",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 450,
    "title": "Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 451,
    "title": "CatalystBench: A Comprehensive Multi-Task Benchmark for Advancing Language Models in Catalysis Science",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 452,
    "title": "Certified Evaluation of Model-Level Explanations for Graph Neural Networks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 453,
    "title": "Characterizing Deep Research: A Benchmark and Formal Definition",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 454,
    "title": "ChemEval: A Multi-level and Fine-grained Chemical Capability Evaluation for Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 455,
    "title": "Children's Intelligence Tests Pose Challenges for MLLMs? KidGym: A 2D Grid-Based Reasoning Benchmark for MLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 456,
    "title": "ChinaTravel: An Open-Ended Travel Planning Benchmark with Compositional Constraint Validation for Language Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 457,
    "title": "CircuitNet 3.0: A Multi-Modal Dataset with Task-Oriented Augmentation for AI-Driven Circuit Design",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 458,
    "title": "CircuitSense: A Hierarchical Circuit System Benchmark Bridging Visual Comprehension and Symbolic Reasoning in Engineering Design Process",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 459,
    "title": "CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 460,
    "title": "CoNavBench: Collaborative Long-Horizon Vision-Language Navigation Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 461,
    "title": "Code2Bench: Scaling Source and Rigor for Dynamic Benchmark Construction",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 462,
    "title": "CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 463,
    "title": "CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 464,
    "title": "Common Corpus: The Largest Collection of Ethical Data for LLM Pre-Training",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 465,
    "title": "Computer Agent Arena: Toward Human-Centric Evaluation and Analysis of Computer-Use Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 466,
    "title": "CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmarking of Large Language Models in Mental Health Question Answering",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 467,
    "title": "Critic–Adviser–Reviser Cyclic Refinement: Towards High-Quality EMR Corpus Generation with LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 468,
    "title": "CrossPL: Systematic Evaluation of Large Language Models for Cross Programming Language Interoperating Code Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 469,
    "title": "Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 470,
    "title": "Culture In a Frame: C$^3$B as a Comic-Based Benchmark for Multimodal Culturally Awareness",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 471,
    "title": "Customizing Visual Emotion Evaluation for MLLMs: An Open-vocabulary, Multifaceted, and Scalable Approach",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 472,
    "title": "DHG-Bench: A Comprehensive Benchmark for Deep Hypergraph Learning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 473,
    "title": "DISCO: Diversifying Sample Condensation for Accelerating Model Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 474,
    "title": "DRBench: A Realistic Benchmark for Enterprise Deep Research",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 475,
    "title": "DUET: Optimizing Training Data Mixtures via Coarse, Noisy Feedback from Unseen Evaluation Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 476,
    "title": "Dataset Color Quantization: A Training-Oriented Framework for Dataset-Level Compression",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 477,
    "title": "Dataset Distillation as Pushforward Optimal Quantization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 478,
    "title": "Dataset Distillation for Memorized Data: Soft Labels can Leak Held-Out Teacher Knowledge",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 479,
    "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 480,
    "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 481,
    "title": "Demystifying Deep Search: A Holistic Evaluation with Hint-free Multi-Hop Questions and Factorised Metrics",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 482,
    "title": "Diffusion Models as Dataset Distillation Priors",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 483,
    "title": "Do LLM Agents Know How to Ground,  Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 484,
    "title": "Don’t Pass@$k$: A Bayesian Framework for Large Language Model Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 485,
    "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 486,
    "title": "EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 487,
    "title": "EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 488,
    "title": "EdiVal-Agent: An Object-Centric Framework for  Automated,    Fine-Grained Evaluation of Multi-Turn  Editing",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 489,
    "title": "EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 490,
    "title": "Elastic Optimal Transport: Theory, Application, and Empirical Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 491,
    "title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 492,
    "title": "Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 493,
    "title": "Entering the Era of Discrete Diffusion Models: A Benchmark for Schrödinger Bridges and Entropic Optimal Transport",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 494,
    "title": "Evaluating Text Creativity across Diverse Domains: a Dataset and Large Language Model Evaluator",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 495,
    "title": "ExpVid: A Benchmark for Experiment Video Understanding & Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 496,
    "title": "FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 497,
    "title": "FETAL-GAUGE: A BENCHMARK FOR ASSESSING VISION-LANGUAGE MODELS IN FETAL ULTRASOUND",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 498,
    "title": "FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 499,
    "title": "FRABench and UFEval: Unified Fine-grained Evaluation with Task and Aspect Generalization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 500,
    "title": "FREAK: A Fine-grained Hallucination Evaluation Benchmark for Advanced MLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 501,
    "title": "Fair in Mind, Fair in Action? A Synchronous Benchmark for Understanding and Generation in UMLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 502,
    "title": "Faithfulness Under the Distribution: A New Look at Attribution Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 503,
    "title": "FeDaL: Federated Dataset Learning for General Time Series Foundation Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 504,
    "title": "Fewer Battles, More Gain: An Information-Efficient Framework for Arena-based LLM Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 505,
    "title": "FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 506,
    "title": "FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 507,
    "title": "FlowGen: Synthesizing Diverse Flowcharts to Enhance and Benchmark MLLM Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 508,
    "title": "ForestPersons: A Large-Scale Dataset for Under-Canopy Missing Person Detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 509,
    "title": "FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 510,
    "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Reasoning-Driven Pedagogical Visualization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 511,
    "title": "From Evaluation to Defense: Advancing Safety in Video Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 512,
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 513,
    "title": "FrontierCO: Real-World and Large-Scale Evaluation of Machine Learning Solvers for Combinatorial Optimization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 514,
    "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 515,
    "title": "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 516,
    "title": "GIR-Bench: Versatile Benchmark for Generating Images with Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 517,
    "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 518,
    "title": "GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 519,
    "title": "GeomMotif: A Benchmark for Arbitrary Geometric Preservation in Protein Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 520,
    "title": "GraphOmni: A Comprehensive and Extensible Benchmark Framework for Large Language Models on Graph-theoretic Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 521,
    "title": "GraphUniverse: Enabling Systematic Evaluation of Inductive Generalization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 522,
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 523,
    "title": "Guidance Matters: Rethinking the Evaluation Pitfall for Text-to-Image Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 524,
    "title": "GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 525,
    "title": "HSG-12M: A Large-Scale Benchmark of Spatial Multigraphs from the Energy Spectra of Non-Hermitian Crystals",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 526,
    "title": "Harnessing Temporal Databases for Systematic Evaluation of Factual Time-Sensitive Question-Answering in LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 527,
    "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 528,
    "title": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "leaderboard"
    ]
  },
  {
    "id": 529,
    "title": "How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation.",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 530,
    "title": "Human-MME: A Holistic Evaluation Benchmark for Human-Centric Multimodal Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 531,
    "title": "INTIMA: A Benchmark for Human-AI Companionship Behavior",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 532,
    "title": "IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 533,
    "title": "IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 534,
    "title": "ImagenWorld: Stress-Testing Image Generation Models with Explainable Human Evaluation on Open-ended Real-World Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 535,
    "title": "InfoDet: A Dataset for Infographic Element Detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 536,
    "title": "Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box Retrieval",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 537,
    "title": "InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 538,
    "title": "Internal Evaluation of Density-Based Clusterings with Noise",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 539,
    "title": "Is Graph Unlearning Ready for Practice? A Benchmark on Efficiency, Utility, and Forgetting",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 540,
    "title": "JailNewsBench: Multi-Lingual and Regional Benchmark for Fake News Generation under Jailbreak Attacks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 541,
    "title": "Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 542,
    "title": "JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 543,
    "title": "K-Sort Eval: Efficient Preference Evaluation for Visual Generation via Corrected VLM-as-a-Judge",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 544,
    "title": "KRAMABENCH: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 545,
    "title": "Kaleidoscope: In-language Exams for Massively  Multilingual Vision Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 546,
    "title": "LAMDA: A Longitudinal Android Malware Benchmark for Concept Drift Analysis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 547,
    "title": "LFQA-E: Carefully Benchmarking Long-form QA Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 548,
    "title": "LRIM: a Physics-Based Benchmark for Provably Evaluating Long-Range Capabilities in Graph Learning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 549,
    "title": "LiveClin: A Live Clinical Benchmark without Leakage",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 550,
    "title": "LiveWeb-IE: A Benchmark For Online Web Information Extraction",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 551,
    "title": "Long-Context Attention Benchmark: From Kernel Efficiency to Distributed Context Parallelism",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 552,
    "title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 553,
    "title": "M4PQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 554,
    "title": "MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 555,
    "title": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 556,
    "title": "MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 557,
    "title": "MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 558,
    "title": "MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 559,
    "title": "MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 560,
    "title": "MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 561,
    "title": "MMReD: a Cross-Modal Benchmark for Dense Context Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 562,
    "title": "MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 563,
    "title": "MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 564,
    "title": "MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 565,
    "title": "ManipEvalAgent: Promptable and Efficient Evaluation Framework for Robotic Manipulation Policies",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 566,
    "title": "MathNet: A Global Multimodal Benchmark for Mathematical Reasoning and Retrieval",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 567,
    "title": "Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 568,
    "title": "MedAraBench: Large-scale Arabic Medical Question Answering Dataset and Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 569,
    "title": "MedLesionVQA: A Multimodal Benchmark Emulating Clinical Visual Diagnosis for Body Surface Health",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 570,
    "title": "Memory, Benchmark & Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 571,
    "title": "MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 572,
    "title": "Moving Beyond Medical Exams: A Clinician-Annotated Fairness Dataset of Real-World Tasks and Ambiguity in Mental Healthcare",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 573,
    "title": "Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 574,
    "title": "Multimodal Dataset Distillation Made Simple by Prototype-guided Data Synthesis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 575,
    "title": "Multimodal Dataset Distillation via Phased Teacher Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 576,
    "title": "Multiverse Mechanica: A Testbed for Learning Game Mechanics via Counterfactual Worlds",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 577,
    "title": "NC-Bench and NCfold: A Benchmark and Closed-Loop Framework for RNA Non-Canonical Base-Pair Prediction",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 578,
    "title": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 579,
    "title": "Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 580,
    "title": "Neural Theorem Proving for Verification Conditions: A Real-World Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 581,
    "title": "Noisy but Valid: Robust Statistical Evaluation of LLMs with Imperfect Judges",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 582,
    "title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 583,
    "title": "OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 584,
    "title": "OD$^3$: Optimization-free Dataset Distillation for Object Detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 585,
    "title": "OPRIDE: Efficient Offline Preference-based Reinforcement Learning via In-Dataset Exploration",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 586,
    "title": "OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 587,
    "title": "Off-Policy Evaluation for Ranking Policies under Deterministic Logging Policies",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 588,
    "title": "Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 589,
    "title": "Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 590,
    "title": "OmniCVR: A Benchmark for Omni-Composed Video Retrieval with Vision, Audio, and Text",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 591,
    "title": "OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 592,
    "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 593,
    "title": "OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 594,
    "title": "On The Fragility of Benchmark Contamination Detection in Reasoning Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 595,
    "title": "OpenPros: A Large-Scale Dataset for Limited View Prostate Ultrasound Computed Tomography",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 596,
    "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 597,
    "title": "P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 598,
    "title": "PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 599,
    "title": "PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 600,
    "title": "PU-BENCH: A UNIFIED BENCHMARK FOR RIGOROUS AND REPRODUCIBLE PU LEARNING",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 601,
    "title": "Parameterization-Based Dataset Distillation of 3D Point Clouds through Learnable Shape Morphing",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 602,
    "title": "PepBenchmark: A Standardized Benchmark for Peptide Machine Learning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 603,
    "title": "PerSpectra: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 604,
    "title": "Phantom-Data:  Towards a General Subject-Consistent Video Generation Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 605,
    "title": "PlantRSR: A New Plant Dataset and Method for Reference-based Super-Resolution",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 606,
    "title": "Point-MoE: Large-Scale Multi-Dataset Training with Mixture-of-Experts for 3D Semantic Segmentation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 607,
    "title": "Predicting Training Re-evaluation Curves Enables Effective Data Curriculums for LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 608,
    "title": "Preference-based Policy Optimization from Sparse-reward Offline Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 609,
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 610,
    "title": "PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 611,
    "title": "Quantum machine learning advantages beyond hardness of evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 612,
    "title": "RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 613,
    "title": "RECODE: A Benchmark for Research Code DEvelopment with Interactive Human Feedback",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 614,
    "title": "RF-MatID: Dataset and Benchmark for Radio Frequency Material Identification",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 615,
    "title": "RIVER: Real-time Video Interaction Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 616,
    "title": "ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 617,
    "title": "RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 618,
    "title": "Rectified Decoupled Dataset Distillation: A Closer Look for Fair and Comprehensive Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 619,
    "title": "Reliable Evaluation of MRI Motion Correction: Dataset and Insights",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 620,
    "title": "Reliable Fine-Grained Evaluation of Natural Language Math Proofs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 621,
    "title": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Deep Research Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 622,
    "title": "Rethinking LLM Evaluation: Can We Evaluate LLMs with 200× Less Data?",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 623,
    "title": "RewardEval: Advancing Reward Model Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 624,
    "title": "S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 625,
    "title": "SAIR: Enabling Deep Learning for Protein-Ligand Interactions with a Synthetic Structural Dataset",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 626,
    "title": "SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 627,
    "title": "SCUBA: Salesforce Computer Use Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 628,
    "title": "SEED: Towards More Accurate Semantic Evaluation for Visual Brain Decoding",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 629,
    "title": "SMAN-Bench: A Cross-System Benchmark for Mobile Agents under Single- and Multi-path, Ambiguous, and Noisy Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 630,
    "title": "SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 631,
    "title": "ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 632,
    "title": "SafeDialBench: A Fine-Grained Safety Evaluation Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 633,
    "title": "ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 634,
    "title": "Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 635,
    "title": "SelvaBox: A high‑resolution dataset for tropical tree crown detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 636,
    "title": "Semantic Voting: A Self-Evaluation-Free Approach for Efficient LLM Self-Improvement on Unverifiable Open-ended Tasks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 637,
    "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 638,
    "title": "SkyEvents: A Large-Scale Event-enhanced UAV Dataset for Robust 3D Scene Reconstruction",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 639,
    "title": "Smarter Not Harder: Generative Process Evaluation with Intrinsic-Signal Driving and Ability‑Adaptive Reward Shaping",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 640,
    "title": "SmellNet: A Large-scale Dataset for Real-world Smell Recognition",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 641,
    "title": "SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 642,
    "title": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 643,
    "title": "SpaCE-Eval: A Benchmark for Real-World Multi-Modal Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 644,
    "title": "SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 645,
    "title": "SpatialViz-Bench: A Cognitively-Grounded Benchmark for Diagnosing Spatial Visualization in MLLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 646,
    "title": "SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 647,
    "title": "SpotIt: Evaluating Text-to-SQL Evaluation with Formal Verification",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 648,
    "title": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 649,
    "title": "SurvHTE-Bench: A Benchmark for Heterogeneous Treatment Effect Estimation in Survival Analysis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 650,
    "title": "Systematic Biosafety Evaluation of DNA Language Models under Jailbreak Attacks",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 651,
    "title": "TABLET: A Large-Scale Dataset for Robust Visual Table Understanding",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 652,
    "title": "THEMIS: Towards Holistic Evaluation of MLLMs for Scientific Paper Fraud Forensics",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 653,
    "title": "TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 654,
    "title": "TTSDS2: Resources and Benchmark for Evaluating Human-Quality Text to Speech Systems",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 655,
    "title": "TaCo:  A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 656,
    "title": "Tab-MIA: A Benchmark Dataset for Membership Inference Attacks on Tabular Data in LLMs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 657,
    "title": "Take Note: Your Molecular Dataset Is Probably Aligned",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 658,
    "title": "Talk, Evaluate, Diagnose: User-aware Agent Evaluation with Automated Error Analysis",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 659,
    "title": "Teach2Eval: An Interaction-Driven LLMs Evaluation Method via Teaching Effectiveness",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 660,
    "title": "Text2Arch: A Dataset for Generating Scientific Architecture Diagrams from Natural Language Descriptions",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 661,
    "title": "The Lie of the Average: How Class Incremental Learning Evaluation Deceives You?",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 662,
    "title": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 663,
    "title": "The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT Distillation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 664,
    "title": "The Quest for Generalizable Motion Generation: Data, Model, and Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 665,
    "title": "Theory-Grounded Evaluation of Human-Like Fallacy Patterns in LLM Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 666,
    "title": "Towards Quantifying Long-Range Interactions in Graph Machine Learning: a Large Graph Dataset and a Measurement",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 667,
    "title": "Towards Reliable Benchmarking: A Contamination Free, Controllable Evaluation Framework for Multi-step LLM Function Calling",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 668,
    "title": "Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Method",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 669,
    "title": "ULTRA-360: Unconstrained Dataset for Large-scale Temporal 3D Reconstruction across Altitudes and Omnidirectional Views",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 670,
    "title": "Understanding Dataset Distillation via Spectral Filtering",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 671,
    "title": "Unlearning Evaluation through Subset Statistical Independence",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 672,
    "title": "Unpacking Human Preference for LLMs: Demographically Aware Evaluation with the HUMAINE Framework",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 673,
    "title": "Unraveling the Complexity of Memory in RL Agents: an Approach for Classification and Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 674,
    "title": "Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 675,
    "title": "UrbanFeel：A Comprehensive Benchmark for Temporal and Perceptual Understanding of City Scenes through Human Perspective",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 676,
    "title": "VERIFY: A Novel Multi-Domain Dataset Grounding LTL in Contextual Natural Language via Provable Intermediate Logic",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 677,
    "title": "VUDG: A Dataset for Video Understanding Domain Generalization",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 678,
    "title": "VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 679,
    "title": "VideoPhy-2: A Challenging Action-Centric Physical Commonsense Evaluation in Video Generation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 680,
    "title": "Virne: A Comprehensive Benchmark for RL-based Network Resource Allocation in NFV",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 681,
    "title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 682,
    "title": "VisualPRM400K: An Effective Dataset for Training Multimodal Process Reward Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 683,
    "title": "VoxPrivacy: A Benchmark for Evaluating Interactional Privacy of Speech Language Models",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 684,
    "title": "WARC-Bench: Web Archive based Benchmark for GUI Subtask Executions",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 685,
    "title": "WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 686,
    "title": "WebDS: An End-to-End Benchmark for Web-based Data Science",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 687,
    "title": "WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 688,
    "title": "WorldGym: World Model as An Environment for Policy Evaluation",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 689,
    "title": "Zebra-CoT: A Dataset for Interleaved Vision-Language Reasoning",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 690,
    "title": "jqBench: a benchmark for reading and editing JSON from natural language and/or examples",
    "conference": "ICLR",
    "year": 2026,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 691,
    "title": "A Fine-grained Analysis of Fitted Q-evaluation: Beyond Parametric Models",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 692,
    "title": "A Touch, Vision, and Language Dataset for Multimodal Alignment",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 693,
    "title": "Ameliorate Spurious Correlations in Dataset Condensation",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 694,
    "title": "An Interpretable Evaluation of Entropy-based Novelty of Generative Models",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 695,
    "title": "ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 696,
    "title": "Attribute Based Interpretable Evaluation Metrics for Generative Models",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 697,
    "title": "Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 698,
    "title": "Beyond ELBOs: A Large-Scale Evaluation of Variational Methods for Sampling",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 699,
    "title": "CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 700,
    "title": "Challenges and Considerations in the Evaluation of Bayesian Causal Discovery",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 701,
    "title": "Combining Experimental and Historical Data for Policy Evaluation",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 702,
    "title": "Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 703,
    "title": "CurBench: Curriculum Learning Benchmark",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 704,
    "title": "Diving into Underwater: Segment Anything Model Guided Underwater Salient Instance Segmentation and A Large-scale Dataset",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 705,
    "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 706,
    "title": "Dynamic Evaluation of Large Language Models by Meta Probing Agents",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 707,
    "title": "Efficient Policy Evaluation with Offline Data Informed Behavior Policy Design",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 708,
    "title": "Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 709,
    "title": "Evaluation of Test-Time Adaptation Under Computational Time Constraints",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 710,
    "title": "Evaluation of Trajectory Distribution Predictions with Energy Score",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 711,
    "title": "FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 712,
    "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 713,
    "title": "Kernel-Based Evaluation of Conditional Biological Sequence Models",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 714,
    "title": "Large Scale Dataset Distillation with Domain Shift",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 715,
    "title": "Low-Rank Similarity Mining for Multimodal Dataset Distillation",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 716,
    "title": "MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 717,
    "title": "MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 718,
    "title": "OODRobustBench: a Benchmark and Large-Scale Analysis of Adversarial Robustness under Distribution Shift",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 719,
    "title": "Off-policy Evaluation Beyond Overlap: Sharp Partial Identification Under Smoothness",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 720,
    "title": "Open-Domain Text Evaluation via Contrastive Distribution Methods",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 721,
    "title": "Policy Evaluation for Variance in Average Reward Reinforcement Learning",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 722,
    "title": "Position: A Safe Harbor for AI Evaluation and Red Teaming",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 723,
    "title": "Position: Insights from Survey Methodology can Improve Training Data",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 724,
    "title": "Position: Measure Dataset Diversity, Don't Just Claim It",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 725,
    "title": "Privacy-Preserving Embedding via Look-up Table Evaluation with Fully Homomorphic Encryption",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 726,
    "title": "PruNeRF: Segment-Centric Dataset Pruning via 3D Spatial Consistency",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 727,
    "title": "Rethinking Generative Large Language Model Evaluation for Semantic Comprehension",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 728,
    "title": "Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 729,
    "title": "SaVeR: Optimal Data Collection Strategy for Safe Policy Evaluation in Tabular MDP",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 730,
    "title": "SelMatch: Effectively Scaling Up Dataset Distillation via Selection-Based Initialization and Partial Updates by Trajectory Matching",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 731,
    "title": "Stability Evaluation through Distributional Perturbation Analysis",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 732,
    "title": "The WMDP Benchmark: Measuring and Reducing Malicious Use with Unlearning",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 733,
    "title": "Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded Adversarial Perturbations",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 734,
    "title": "Trained Random Forests Completely Reveal your Dataset",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 735,
    "title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 736,
    "title": "Unsupervised Evaluation of Code LLMs with Round-Trip Correctness",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 737,
    "title": "VinT-6D: A Large-Scale Object-in-hand Dataset from Vision, Touch and Proprioception",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 738,
    "title": "What is Dataset Distillation Learning?",
    "conference": "ICML",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 739,
    "title": "Accelerating Unbiased LLM Evaluation via Synthetic Feedback",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 740,
    "title": "Active Evaluation Acquisition for Efficient LLM Benchmarking",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 741,
    "title": "Adaptive Exploration for Multi-Reward Multi-Policy Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 742,
    "title": "AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 743,
    "title": "Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 744,
    "title": "Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 745,
    "title": "AutoEval Done Right: Using Synthetic Data for Model Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 746,
    "title": "Automated Benchmark Generation for Repository-Level Coding Tasks",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 747,
    "title": "Beyond Cropped Regions: New Benchmark and Corresponding Baseline for Chinese Scene Text Retrieval in Diverse Layouts",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 748,
    "title": "Boosting Virtual Agent Learning and Reasoning: A Step-Wise, Multi-Dimensional, and Generalist Reward Model with Benchmark",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 749,
    "title": "CASE-Bench: Context-Aware SafEty Benchmark for Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 750,
    "title": "CTBench: A Library and Benchmark for Certified Training",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 751,
    "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 752,
    "title": "Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 753,
    "title": "Certifiably Robust Model Evaluation in Federated Learning under Meta-Distributional Shifts",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 754,
    "title": "CoastalBench: A Decade-Long High-Resolution Dataset to Emulate Complex Coastal Processes",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 755,
    "title": "Compositional Causal Reasoning Evaluation in Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 756,
    "title": "Concept Reachability in Diffusion Models: Beyond Dataset Constraints",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 757,
    "title": "Context is Key: A Benchmark for Forecasting with Essential Textual Information",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 758,
    "title": "Copilot Arena: A Platform for Code LLM Evaluation in the Wild",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 759,
    "title": "Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 760,
    "title": "Deep Electromagnetic Structure Design Under Limited Evaluation Budgets",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 761,
    "title": "Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 762,
    "title": "ELITE: Enhanced Language-Image Toxicity Evaluation for Safety",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 763,
    "title": "Efficient Graph Continual Learning via Lightweight Graph Neural Tangent Kernels-based Dataset Distillation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 764,
    "title": "Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 765,
    "title": "GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via Multi-Step Reasoning",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 766,
    "title": "Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 767,
    "title": "How Contaminated Is Your Benchmark? Measuring Dataset Leakage in Large Language Models with Kernel Divergence",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 768,
    "title": "How to set AdamW's weight decay as you scale model and dataset size",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 769,
    "title": "Human Body Restoration with One-Step Diffusion Model and A New Benchmark",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 770,
    "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 771,
    "title": "Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 772,
    "title": "KinDEL: DNA-Encoded Library Dataset for Kinase Inhibitors",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 773,
    "title": "LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 774,
    "title": "LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 775,
    "title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 776,
    "title": "LMAct: A Benchmark for In-Context Imitation Learning with Long Multimodal Demonstrations",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 777,
    "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 778,
    "title": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 779,
    "title": "Lightspeed Geometric Dataset Distance via Sliced Optimal Transport",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 780,
    "title": "Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 781,
    "title": "MGD$^3$ : Mode-Guided Dataset Distillation using Diffusion Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 782,
    "title": "MIB: A Mechanistic Interpretability Benchmark",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 783,
    "title": "Minerva: A Programmable Memory Test Benchmark for Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 784,
    "title": "Multiple-policy Evaluation via Density Estimation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 785,
    "title": "NICE Data Selection for Instruction Tuning in LLMs with Non-differentiable Evaluation Metric",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 786,
    "title": "NoLiMa: Long-Context Evaluation Beyond Literal Matching",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 787,
    "title": "OR-Bench: An Over-Refusal Benchmark for Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 788,
    "title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 789,
    "title": "Off-Policy Evaluation under Nonignorable Missing Data",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 790,
    "title": "OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 791,
    "title": "Optimal Survey Design for Private Mean Estimation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 792,
    "title": "Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination’s Impact on Machine Translation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 793,
    "title": "PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 794,
    "title": "Point Cloud Dataset Distillation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 795,
    "title": "Prompt-to-Leaderboard: Prompt-Adaptive LLM Evaluations",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "leaderboard"
    ]
  },
  {
    "id": 796,
    "title": "Putnam-AXIOM: A Functional & Static Benchmark for Measuring Higher Level Mathematical Reasoning in LLMs",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 797,
    "title": "PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 798,
    "title": "RBench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 799,
    "title": "RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 800,
    "title": "Random Policy Evaluation Uncovers Policies of Generative Flow Networks",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 801,
    "title": "Regression for the Mean: Auto-Evaluation and Inference with Few Labels through Post-hoc Regression",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 802,
    "title": "Reliable and Efficient Amortized Model-based Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 803,
    "title": "Rethinking Causal Ranking: A Balanced Perspective on Uplift Model Evaluation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 804,
    "title": "SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language Model Interpretability",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 805,
    "title": "STAMP Your Content: Proving Dataset Membership via Watermarked Rephrasings",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 806,
    "title": "Sliding Puzzles Gym: A Scalable Benchmark for State Representation in Visual Reinforcement Learning",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 807,
    "title": "Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 808,
    "title": "TUMTraf VideoQA: Dataset and Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 809,
    "title": "TabFSBench: Tabular Benchmark for Feature Shifts in Open Environments",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 810,
    "title": "Taming Diffusion for Dataset Distillation with High Representativeness",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 811,
    "title": "Test-Time Graph Neural Dataset Search With Generative Projection",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 812,
    "title": "The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "leaderboard"
    ]
  },
  {
    "id": 813,
    "title": "The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 814,
    "title": "Three-Dimensional Trajectory Prediction with 3DMoTraj Dataset",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 815,
    "title": "Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 816,
    "title": "Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 817,
    "title": "UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 818,
    "title": "UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 819,
    "title": "Unbiased Evaluation of Large Language Models from a Causal Perspective",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 820,
    "title": "Uncertainty Quantification for LLM-Based Survey Simulations",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 821,
    "title": "Understanding Sharpness Dynamics in NN Training with a Minimalist Example: The Effects of Dataset Difficulty, Depth, Stochasticity, and More",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 822,
    "title": "Unlocking Post-hoc Dataset Inference with Synthetic Data",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 823,
    "title": "WOMD-Reasoning: A Large-Scale Dataset for Interaction Reasoning in Driving",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 824,
    "title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities",
    "conference": "ICML",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 825,
    "title": "3DBench: A Scalable 3D Benchmark and Instruction-Tuning Dataset",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 826,
    "title": "A Comprehensive Survey and Taxonomy on Point Cloud Registration Based on Deep Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 827,
    "title": "A Comprehensive Survey of Cross-Domain Policy Transfer for Embodied Agents",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 828,
    "title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 829,
    "title": "A Dataset and Model for Realistic License Plate Deblurring",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 830,
    "title": "A Meta-Game Evaluation Framework for Deep Multiagent Reinforcement Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 831,
    "title": "A Survey of Constraint Formulations in Safe Reinforcement Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 832,
    "title": "A Survey of Data-Efficient Graph Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 833,
    "title": "A Survey of Graph Meets Large Language Model: Progress and Future Directions",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 834,
    "title": "A Survey of Multimodal Sarcasm Detection",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 835,
    "title": "A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 836,
    "title": "A Survey on Cross-Domain Sequential Recommendation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 837,
    "title": "A Survey on Efficient Federated Learning Methods for Foundation Model Training",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 838,
    "title": "A Survey on Extractive Knowledge Graph Summarization: Applications, Approaches, Evaluation, and Future Directions",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 839,
    "title": "A Survey on Model-Free Goal Recognition",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 840,
    "title": "A Survey on Network Alignment: Approaches, Applications and Future Directions",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 841,
    "title": "A Survey on Neural Question Generation: Methods, Applications, and Prospects",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 842,
    "title": "A Survey on Plan Optimization",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 843,
    "title": "A Survey on Rank Aggregation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 844,
    "title": "A Systematic Survey on Federated Semi-supervised Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 845,
    "title": "A Teacher Classroom Dress Assessment Method Based on a New Assessment Dataset",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 846,
    "title": "AI-Enhanced Virtual Reality in Medicine: A Comprehensive Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 847,
    "title": "Benchmarking Fish Dataset and Evaluation Metric in Keypoint Detection - Towards Precise Fish Morphological Assessment in Aquaculture Breeding",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 848,
    "title": "Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 849,
    "title": "Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 850,
    "title": "Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 851,
    "title": "Budget Feasible Mechanisms: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 852,
    "title": "CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 853,
    "title": "Continual Learning with Pre-Trained Models: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 854,
    "title": "DANCE: Dual-View Distribution Alignment for Dataset Condensation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 855,
    "title": "Deciphering the Projection Head: Representation Evaluation Self-supervised Learning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 856,
    "title": "Digital Avatars: Framework Development and Their Evaluation",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 857,
    "title": "Empowering Time Series Analysis with Large Language Models: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 858,
    "title": "Enhancing Controlled Query Evaluation through Epistemic Policies",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 859,
    "title": "Enhancing Scalability of Metric Differential Privacy via Secret Dataset Partitioning and Benders Decomposition",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 860,
    "title": "Evaluation of Project Performance in Participatory Budgeting",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 861,
    "title": "Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 862,
    "title": "Formalisation and Evaluation of Properties for Consequentialist Machine Ethics",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 863,
    "title": "GRASP: A Novel Benchmark for Evaluating Language GRounding and Situated Physics Understanding in Multimodal Language Models",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 864,
    "title": "GUIDE: A Guideline-Guided Dataset for Instructional Video Comprehension",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 865,
    "title": "Graph Neural Networks for Brain Graph Learning: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 866,
    "title": "IntEr-HRI Competition: Intrinsic Error Evaluation during Human - Robot Interaction",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Human-Robot Interaction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 867,
    "title": "Intelligent Agents for Auction-based Federated Learning: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 868,
    "title": "LEEC for Judicial Fairness: A Legal Element Extraction Dataset with Extensive Extra-Legal Labels",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 869,
    "title": "Label Leakage in Vertical Federated Learning: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 870,
    "title": "Large Language Model Based Multi-agents: A Survey of Progress and Challenges",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 871,
    "title": "Large Language Models for Time Series: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 872,
    "title": "Laying the Foundations for Solving FOND HTN Problems: Grounding, Search, Heuristics (and Benchmark Problems)",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 873,
    "title": "Learning to Resolve Social Dilemmas: A Survey (Abstract Reprint)",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 874,
    "title": "MMVQA:  A Comprehensive Dataset for Investigating Multipage Multimodal Information Retrieval in PDF-based Visual Question Answering",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 875,
    "title": "Medical Neural Architecture Search: Survey and Taxonomy",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 876,
    "title": "MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 877,
    "title": "MuEP: A Multimodal Benchmark for Embodied Planning with Foundation Models",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 878,
    "title": "MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering Medical Knowledge",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 879,
    "title": "PDENNEval: A Comprehensive Evaluation of Neural Network Methods for Solving PDEs",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 880,
    "title": "Policy Space Response Oracles: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 881,
    "title": "Predicting Carpark Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 882,
    "title": "Reassessing Evaluation Functions in Algorithmic Recourse: An Empirical Study from a Human-Centered Perspective",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 883,
    "title": "Reframing Spatial Reasoning Evaluation in Language Models: A Real-World Simulation Benchmark for Qualitative Reasoning",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 884,
    "title": "Revealing Hierarchical Structure of Leaf Venations in Plant Science via Label-Efficient Segmentation: Dataset and Method",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 885,
    "title": "Robust Counterfactual Explanations in Machine Learning: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 886,
    "title": "Social Learning through Interactions with Other Agents: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 887,
    "title": "Speech-Forensics: Towards Comprehensive Synthetic Speech Dataset Establishment and Analysis",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 888,
    "title": "Strategic Aspects of Stable Matching Markets: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 889,
    "title": "Supervised Algorithmic Fairness in Distribution Shifts: A Survey",
    "conference": "IJCAI",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 890,
    "title": "40 Years of Research in Possibilistic Logic – a Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 891,
    "title": "A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 892,
    "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 893,
    "title": "A Survey of Pathology Foundation Model: Progress and Future Directions",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 894,
    "title": "A Survey of Structural Entropy: Theory, Methods, and Applications",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 895,
    "title": "A Survey on Bandit Learning in Matching Markets",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 896,
    "title": "A Survey on Model Repair in AI Planning",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 897,
    "title": "A Survey on Multi-View Knowledge Graph: Generation, Fusion, Applications and Future Directions",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 898,
    "title": "A Survey on One-To-Many Negotiation: A Taxonomy of Interdependency",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 899,
    "title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 900,
    "title": "A Survey on the Feedback Mechanism of LLM-based AI Agents",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 901,
    "title": "BTPG: A Platform and Benchmark for Behavior Tree Planning in Everyday Service Robots",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 902,
    "title": "BinMetric: A Comprehensive Binary Code Analysis Benchmark for Large Language Models",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 903,
    "title": "Breaking the Self-Evaluation Barrier: Reinforced Neuro-Symbolic Planning with Large Language Models",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 904,
    "title": "CD^2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 905,
    "title": "CFDONEval: A Comprehensive Evaluation of Operator-Learning Neural Network Models for Computational Fluid Dynamics",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 906,
    "title": "Connector-S: A Survey of Connectors in Multi-modal Large Language Models",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 907,
    "title": "Deep Learning for Multivariate Time Series Imputation: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 908,
    "title": "Deep Learning-Based Pedestrian Simulation with Limited Real-World Training Data: An Evaluation Framework",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 909,
    "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 910,
    "title": "Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 911,
    "title": "Evaluation of Medical Large Language Models: Taxonomy, Review, and Directions",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 912,
    "title": "Exploring the Frontiers of Animation Video Generation in the Sora Era: Method, Dataset and Benchmark",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 913,
    "title": "Federated Low-Rank Adaptation for Foundation Models: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 914,
    "title": "Game Theory Meets Large Language Models: A Systematic Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 915,
    "title": "Graph Neural Networks for Databases: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 916,
    "title": "Graph OOD Detection via Plug-and-Play Energy-based Evaluation and Propagation",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 917,
    "title": "Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 918,
    "title": "Grounding Open-Domain Knowledge from LLMs to Real-World Reinforcement Learning Tasks: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 919,
    "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 920,
    "title": "How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 921,
    "title": "Image Captioning Evaluation in the Age of Multimodal LLMs: Challenges and Future Perspectives",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 922,
    "title": "Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 923,
    "title": "Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object Reconstruction",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 924,
    "title": "JT8:NovPhy: A physical reasoning benchmark for open-world AI systems",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 925,
    "title": "Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 926,
    "title": "M4Bench: A Benchmark of Multi-domain Multi-granularity Multi-image Understanding for Multi-modal Large Language Models",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 927,
    "title": "Multimodal Fake News Detection: MFND Dataset and Shallow-Deep Multitask Learning",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 928,
    "title": "Multimodal Retina Image Analysis Survey: Datasets, Tasks and Methods",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 929,
    "title": "Neuro-Symbolic Artificial Intelligence: A Task-Directed Survey in the Black-Box Models Era",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 930,
    "title": "Neuromorphic Sequential Arena: A Benchmark for Neuromorphic Temporal Processing",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 931,
    "title": "Optical Flow Estimation for Tiny Objects: New Problem, Specialized Benchmark, and Bioinspired Scheme",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 932,
    "title": "Paradigms of AI Evaluation: Mapping Goals, Methodologies and Culture",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 933,
    "title": "PatternCIR Benchmark and TisCIR: Advancing Zero-Shot Composed Image Retrieval in Remote Sensing",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 934,
    "title": "Q-MiniSAM2: A Quantization-based Benchmark for Resource-Efficient Video Segmentation",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 935,
    "title": "RenderBender: A Survey on Adversarial Attacks Using Differentiable Rendering",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 936,
    "title": "Reward Models in Deep Reinforcement Learning: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 937,
    "title": "Rule-Guided Reinforcement Learning Policy Evaluation and Improvement",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 938,
    "title": "SCVBench: A Benchmark with Multi-turn Dialogues for Story-Centric Video Understanding",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 939,
    "title": "Safety of Embodied Navigation: A Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 940,
    "title": "Survey on Strategic Mining in Blockchain: A Reinforcement Learning Approach",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 941,
    "title": "TP-Eval: Tap Multimodal LLMs’ Potential in Evaluation by Customizing Prompts",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 942,
    "title": "The Devil is in Fine-tuning and Long-tailed Problems: A New Benchmark for Scene Text Detection",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 943,
    "title": "Toward Robust Non-Transferable Learning: A Survey and Benchmark",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "survey"
    ]
  },
  {
    "id": 944,
    "title": "Towards Anytime Retrieval: A Benchmark for Anytime Person Re-Identification",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 945,
    "title": "Towards Cross-Modality Modeling for Time Series Analytics: A Survey in the LLM Era",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 946,
    "title": "Understanding PII Leakage in Large Language Models: A Systematic Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 947,
    "title": "Unveiling Maternity and Infant Care Conversations: A Chinese Dialogue Dataset for Enhanced Parenting Support",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 948,
    "title": "Zero-shot Quantization: A Comprehensive Survey",
    "conference": "IJCAI",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 949,
    "title": "$E^3$: Exploring Embodied Emotion Through A Large-Scale Egocentric Video Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 950,
    "title": "$\\nabla^2$DFT: A Universal Quantum Chemistry Dataset of Drug-Like Molecules and a Benchmark for Neural Network Potentials",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 951,
    "title": "$\\texttt{ConflictBank}$: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 952,
    "title": "3DCoMPaT200: Language Grounded Large-Scale 3D Vision Dataset for Compositional Recognition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 953,
    "title": "A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 954,
    "title": "A Benchmark Suite for Evaluating Neural Mutual Information Estimators on Unstructured Datasets",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 955,
    "title": "A Critical Evaluation of AI Feedback for Aligning Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 956,
    "title": "A Cross-Domain Benchmark for Active Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 957,
    "title": "A Label is Worth A Thousand Images in Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 958,
    "title": "A Large-Scale Human-Centric Benchmark for Referring Expression Comprehension in the LMM Era",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 959,
    "title": "A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 960,
    "title": "A New Multi-Source Light Detection Benchmark and Semi-Supervised Focal Light Detection",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 961,
    "title": "A SARS-CoV-2 Interaction Dataset and VHH Sequence Corpus for Antibody Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "corpus"
    ]
  },
  {
    "id": 962,
    "title": "A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 963,
    "title": "A Simulation Benchmark for Autonomous Racing with Large-Scale Human Data",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 964,
    "title": "A Synthetic Dataset for Personal Attribute Inference",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 965,
    "title": "A Systematic Review of NeurIPS Dataset Management Practices",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 966,
    "title": "A benchmark for prediction of transcriptomic responses to chemical perturbations across cell types",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 967,
    "title": "A survey and benchmark of high-dimensional Bayesian optimization of discrete sequences",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "survey"
    ]
  },
  {
    "id": 968,
    "title": "ABCFair: an Adaptable Benchmark approach for Comparing Fairness Methods",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 969,
    "title": "AFBench: A Large-scale Benchmark for Airfoil Design",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 970,
    "title": "ALI-Agent: Assessing LLMs'  Alignment with Human Values via Agent-based Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 971,
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 972,
    "title": "APDDv2:  Aesthetics of Paintings and Drawings Dataset with Artist Labeled Scores and Comments",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 973,
    "title": "APEBench: A Benchmark for Autoregressive Neural Emulators of PDEs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 974,
    "title": "Abstract Reward Processes: Leveraging State Abstraction for Consistent Off-Policy Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 975,
    "title": "ActionAtlas: A VideoQA Benchmark for Domain-specialized Action Recognition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 976,
    "title": "Adaptive Labeling for Efficient Out-of-distribution Model Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 977,
    "title": "Advancing Video Anomaly Detection: A Concise Review and a New Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 978,
    "title": "AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 979,
    "title": "AllClear: A Comprehensive Dataset and Benchmark for Cloud Removal in Satellite Imagery",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 980,
    "title": "Arctique: An artificial histopathological dataset unifying realism and controllability for uncertainty quantification",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 981,
    "title": "Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 982,
    "title": "Assemblage: Automatic Binary Dataset Construction for Machine Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 983,
    "title": "AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 984,
    "title": "Automated Label Unification for Multi-Dataset Semantic Segmentation with GNNs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 985,
    "title": "Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 986,
    "title": "BEACON: Benchmark for Comprehensive RNA Tasks and Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 987,
    "title": "BIGOS V2 Benchmark for Polish ASR: Curated Datasets and Tools for Reproducible Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 988,
    "title": "BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 989,
    "title": "BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 990,
    "title": "BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 991,
    "title": "BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 992,
    "title": "Benchmark Data Repositories for Better Benchmarking",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 993,
    "title": "Benchmarking Estimators for Natural Experiments: A Novel Dataset and a Doubly Robust Algorithm",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 994,
    "title": "BiVLC: Extending Vision-Language Compositionality Evaluation with Text-to-Image Retrieval",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 995,
    "title": "BioTrove: A Large Curated Image Dataset Enabling AI for Biodiversity",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 996,
    "title": "BuckTales: A multi-UAV dataset for multi-object tracking and re-identification of wild antelopes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 997,
    "title": "Building Timeseries Dataset: Empowering Large-Scale Building Analytics",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 998,
    "title": "CARE: a Benchmark Suite for the Classification and Retrieval of Enzymes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 999,
    "title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1000,
    "title": "CRAG - Comprehensive RAG Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1001,
    "title": "CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1002,
    "title": "CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper Influence",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1003,
    "title": "CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1004,
    "title": "CableInspect-AD: An Expert-Annotated Anomaly Detection Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1005,
    "title": "Can LLMs Solve Molecule Puzzles? A Multimodal Benchmark for Molecular Structure Elucidation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1006,
    "title": "Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1007,
    "title": "CaptainCook4D: A Dataset for Understanding Errors in Procedural Activities",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1008,
    "title": "CausalChaos! Dataset for Comprehensive Causal Action Question Answering Over Longer Causal Chains Grounded in Dynamic Visual Scenes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1009,
    "title": "ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1010,
    "title": "ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1011,
    "title": "CoIN: A Benchmark of Continual Instruction Tuning for Multimodel Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1012,
    "title": "CoMix: A Comprehensive Benchmark for Multi-Task Comic Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1013,
    "title": "Color-Oriented Redundancy Reduction in Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1014,
    "title": "ComBack: A Versatile Dataset for Enhancing Compiler Backend Development Efficiency",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1015,
    "title": "ConMe: Rethinking Evaluation of Compositional Reasoning for Modern VLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1016,
    "title": "ConceptMix: A Compositional Image Generation Benchmark with Controllable Difficulty",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1017,
    "title": "CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1018,
    "title": "ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Ablation Capability for Large Vision-Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1019,
    "title": "Copycats: the many lives of a publicly available medical imaging dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1020,
    "title": "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1021,
    "title": "DART-Eval: A Comprehensive DNA Language Model Evaluation Benchmark on Regulatory DNA",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1022,
    "title": "DECO-Bench: Unified Benchmark for Decoupled Task-Agnostic Synthetic Data Release",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1023,
    "title": "DMC-VB: A Benchmark for Representation Learning for Control with Visual Distractors",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1024,
    "title": "DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1025,
    "title": "DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1026,
    "title": "Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1027,
    "title": "Dataset and Lessons Learned from the 2024 SaTML LLM Capture-the-Flag Competition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1028,
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1029,
    "title": "DevBench: A multimodal developmental benchmark for language learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1030,
    "title": "Dispelling the Mirage of Progress in Offline MARL through Standardised Baselines and Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1031,
    "title": "Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1032,
    "title": "DreamCatcher: A Wearer-aware Multi-modal Sleep Event Dataset Based on Earables in Non-restrictive Environments",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1033,
    "title": "DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1034,
    "title": "DrivAerNet++: A Large-Scale Multimodal Car Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1035,
    "title": "DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1036,
    "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1037,
    "title": "EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1038,
    "title": "EHRNoteQA: An LLM Benchmark for Real-World Clinical Practice Using Discharge Summaries",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1039,
    "title": "ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1040,
    "title": "Efficient Lifelong Model Evaluation in an Era of Rapid Progress",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1041,
    "title": "Efficient Policy Evaluation Across Multiple Different Experimental Datasets",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1042,
    "title": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1043,
    "title": "Efficient multi-prompt evaluation of LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1044,
    "title": "EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1045,
    "title": "Einsum Benchmark: Enabling the Development of Next-Generation Tensor Execution Engines",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1046,
    "title": "Elo Uncovered: Robustness and Best Practices in Language Model Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1047,
    "title": "Elucidating the Design Space of Dataset Condensation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1048,
    "title": "Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1049,
    "title": "EpiCare: A Reinforcement Learning Benchmark for Dynamic Treatment Regimes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1050,
    "title": "Evaluation of Text-to-Video Generation Models: A Dynamics Perspective",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1051,
    "title": "EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1052,
    "title": "Externally Valid Policy Evaluation from Randomized Trials Using Additional Observational Data",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1053,
    "title": "FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1054,
    "title": "FIRE: A Dataset for Feedback Integration and Refinement Evaluation of Multimodal Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1055,
    "title": "FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event Detection",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1056,
    "title": "FUSU: A Multi-temporal-source Land Use Change Segmentation Dataset for Fine-grained Urban Semantic Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1057,
    "title": "FairJob: A Real-World Dataset for Fairness in Online Systems",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1058,
    "title": "Feint Behaviors and Strategies: Formalization, Implementation and Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1059,
    "title": "Fetch and Forge: Efficient Dataset Condensation for Object Detection",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1060,
    "title": "Few-shot Algorithms for Consistent Neural Decoding (FALCON) Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1061,
    "title": "FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1062,
    "title": "FinBen: A Holistic Financial Benchmark for Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1063,
    "title": "FindingEmo: An Image Dataset for Emotion Recognition in the Wild",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1064,
    "title": "Fit for our purpose, not yours: Benchmark for a low-resource, Indigenous language",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1065,
    "title": "GC-Bench: An Open and Unified Benchmark for Graph Condensation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1066,
    "title": "GLBench: A Comprehensive Benchmark for Graph with Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1067,
    "title": "GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1068,
    "title": "GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1069,
    "title": "GS-Blur: A 3D Scene-Based Dataset for Realistic Image Deblurring",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1070,
    "title": "GTA: A Benchmark for General Tool Agents",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1071,
    "title": "GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1072,
    "title": "GV-Rep: A Large-Scale Dataset for Genetic Variant Representation Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1073,
    "title": "GarmentLab: A Unified Simulation and Benchmark for Garment Manipulation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1074,
    "title": "GenAI Arena: An Open Evaluation Platform for Generative Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1075,
    "title": "GeoPlant: Spatial Plant Species Prediction Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1076,
    "title": "GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1077,
    "title": "HEMM: Holistic Evaluation of Multimodal Foundation Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1078,
    "title": "HEST-1k: A Dataset For Spatial Transcriptomics and Histology Image Analysis",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1079,
    "title": "HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1080,
    "title": "Harmony4D: A Video Dataset for In-The-Wild Close Human Interactions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1081,
    "title": "HelpSteer 2: Open-source dataset for training top-performing reward models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1082,
    "title": "I2EBench: A Comprehensive Benchmark for Instruction-based Image Editing",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1083,
    "title": "IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1084,
    "title": "II-Bench: An Image Implication Understanding Benchmark for Multimodal Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1085,
    "title": "IMDL-BenCo: A Comprehensive Benchmark and Codebase for Image Manipulation Detection & Localization",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1086,
    "title": "IMPACT: A Large-scale Integrated Multimodal Patent Analysis and Creation Dataset for Design Patents",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1087,
    "title": "INQUIRE: A Natural World Text-to-Image Retrieval Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1088,
    "title": "IQA-EVAL: Automatic Evaluation of Human-Model Interactive Question Answering",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1089,
    "title": "IaC-Eval: A Code Generation Benchmark for Cloud Infrastructure-as-Code Programs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1090,
    "title": "Image-aware Evaluation of Generated Medical Reports",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1091,
    "title": "Implicit Zoo: A Large-Scale Dataset of Neural Implicit Functions for 2D Images and 3D Scenes",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1092,
    "title": "IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1093,
    "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1094,
    "title": "Indoor Air Quality Dataset with Activities of Daily Living in Low to Middle-income Communities",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1095,
    "title": "Infer Induced Sentiment of Comment Response to Video: A New Task, Dataset and Baseline",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1096,
    "title": "Is Function Similarity Over-Engineered? Building a Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1097,
    "title": "JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1098,
    "title": "Job-SDF: A Multi-Granularity Dataset for Job Skill Demand Forecasting and Benchmarking",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1099,
    "title": "JourneyBench: A Challenging One-Stop Vision-Language Understanding Benchmark of Generated Images",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1100,
    "title": "Kuro Siwo: 33 billion $m^2$ under the water. A global multi-temporal satellite dataset for rapid flood mapping",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1101,
    "title": "LAVIB: A Large-scale Video Interpolation Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1102,
    "title": "LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low Resource and Extinct Languages",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1103,
    "title": "LLM Dataset Inference: Did you train on my dataset?",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1104,
    "title": "LVD-2M: A Long-take Video Dataset with Temporally Dense Captions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1105,
    "title": "Language Without Borders: A Dataset and Benchmark for Code-Switching Lip Reading",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1106,
    "title": "Large Language Models' Expert-level Global History Knowledge Benchmark (HiST-LLM)",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1107,
    "title": "LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1108,
    "title": "Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1109,
    "title": "LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1110,
    "title": "LucidAction: A Hierarchical and Multi-model Dataset for Comprehensive Action Quality Assessment",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1111,
    "title": "M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and Multispectral Data",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1112,
    "title": "MAN TruckScenes: A multimodal dataset for autonomous trucking in diverse conditions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1113,
    "title": "MARPLE: A Benchmark for Long-Horizon Inference",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1114,
    "title": "MARVEL: Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1115,
    "title": "MEQA: A Benchmark for Multi-hop Event-centric Question Answering with Explanations",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1116,
    "title": "MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1117,
    "title": "MLLM-CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1118,
    "title": "MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1119,
    "title": "MM-WLAuslan: Multi-View Multi-Modal Word-Level Australian Sign Language Recognition Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1120,
    "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1121,
    "title": "MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1122,
    "title": "MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1123,
    "title": "MMM-RS: A Multi-modal, Multi-GSD, Multi-scene Remote Sensing  Dataset and Benchmark for Text-to-Image Generation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1124,
    "title": "MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1125,
    "title": "MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1126,
    "title": "MassSpecGym: A benchmark for the discovery and identification of molecules",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1127,
    "title": "MathPile: A Billion-Token-Scale Pretraining Corpus for Math",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1128,
    "title": "Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1129,
    "title": "Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1130,
    "title": "MedJourney: Benchmark and Evaluation of Large Language Models over Patient Clinical Journey",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1131,
    "title": "MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1132,
    "title": "Mercury: A Code Efficiency Benchmark for Code Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1133,
    "title": "Micro-Bench: A Microscopy Benchmark for Vision-Language Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1134,
    "title": "MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1135,
    "title": "MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1136,
    "title": "MmCows: A Multimodal Dataset for Dairy Cattle Monitoring",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1137,
    "title": "Muharaf: Manuscripts of Handwritten Arabic Dataset for Cursive Text Recognition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1138,
    "title": "MultiOrg: A Multi-rater Organoid-detection Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1139,
    "title": "MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1140,
    "title": "NYU CTF Bench: A Scalable Open-Source Benchmark Dataset for Evaluating LLMs in Offensive Security",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1141,
    "title": "NanoBaseLib: A Multi-Task Benchmark Dataset for Nanopore Sequencing",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1142,
    "title": "Noisy Ostracods: A Fine-Grained, Imbalanced Real-World Dataset for Benchmarking Robust Machine Learning and Label Correction Methods",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1143,
    "title": "NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1144,
    "title": "Nonparametric Evaluation of Noisy ICA Solutions",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1145,
    "title": "Nuclear Fusion Diamond Polishing Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1146,
    "title": "OAM-TCD: A globally diverse dataset of high-resolution tree cover maps",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1147,
    "title": "ODRL: A Benchmark for Off-Dynamics Reinforcement Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1148,
    "title": "OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1149,
    "title": "OVT-B: A New Large-Scale Benchmark for Open-Vocabulary Multi-Object Tracking",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1150,
    "title": "Off to new Shores: A Dataset & Benchmark for (near-)coastal Flood Inundation Forecasting",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1151,
    "title": "On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1152,
    "title": "On-Road Object Importance Estimation: A New Dataset and A Model with Multi-Fold Top-Down Guidance",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1153,
    "title": "OpenDebateEvidence: A Massive-Scale Argument Mining and Summarization Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1154,
    "title": "OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1155,
    "title": "OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1156,
    "title": "Overcoming Common Flaws in the Evaluation of Selective Classification Systems",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1157,
    "title": "PEACE: A Dataset of Pharmaceutical Care for Cancer Pain Analgesia Evaluation and Medication Decision",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1158,
    "title": "PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1159,
    "title": "PROSPECT PTMs: Rich Labeled Tandem Mass Spectrometry Dataset of Modified Peptides for Machine Learning in Proteomics",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1160,
    "title": "PUZZLES: A Benchmark for Neural Algorithmic Reasoning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1161,
    "title": "Paloma: A Benchmark for Evaluating Language Model Fit",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1162,
    "title": "PersonalSum: A User-Subjective Guided Personalized Summarization Dataset for Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1163,
    "title": "PowerGraph: A power grid benchmark dataset for graph neural networks",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1164,
    "title": "ProG: A Graph Prompt Learning Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1165,
    "title": "Provable and Efficient Dataset Distillation for Kernel Ridge Regression",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1166,
    "title": "Questioning the Survey Responses of Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1167,
    "title": "RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1168,
    "title": "Re-assembling the past: The RePAIR dataset and benchmark for real world 2D and 3D puzzle solving",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1169,
    "title": "ReMI: A Dataset for Reasoning with Multiple Images",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1170,
    "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1171,
    "title": "ReactZyme: A Benchmark for Enzyme-Reaction Prediction",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1172,
    "title": "RealMAN: A Real-Recorded and Annotated Microphone Array Dataset for Dynamic Speech Enhancement and Localization",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1173,
    "title": "Recovering Complete Actions for Cross-dataset Skeleton Action Recognition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1174,
    "title": "RedCode: Risky Code Execution and Generation Benchmark for Code Agents",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1175,
    "title": "RedPajama: an Open Dataset for Training Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1176,
    "title": "RelBench: A Benchmark for Deep Learning on Relational Databases",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1177,
    "title": "RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1178,
    "title": "Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing Reliability, Reproducibility, and Practicality",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1179,
    "title": "Rethinking The Training And Evaluation of Rich-Context Layout-to-Image Generation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1180,
    "title": "Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1181,
    "title": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1182,
    "title": "SCRREAM : SCan, Register, REnder And Map: A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1183,
    "title": "SD-Eval: A  Benchmark Dataset for Spoken Dialogue Understanding Beyond Words",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1184,
    "title": "SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image Classification",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1185,
    "title": "SHDocs: A dataset, benchmark, and method to efficiently generate high-quality, real-world specular highlight data with near-perfect alignment",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1186,
    "title": "SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1187,
    "title": "SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1188,
    "title": "SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1189,
    "title": "SR-CACO-2: A Dataset for Confocal Fluorescence Microscopy Image Super-Resolution",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1190,
    "title": "SRFUND: A Multi-Granularity Hierarchical Structure Reconstruction Benchmark in Form Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1191,
    "title": "SS3DM: Benchmarking Street-View Surface Reconstruction with a Synthetic 3D Mesh Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1192,
    "title": "STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1193,
    "title": "SUGARCREPE++ Dataset: Vision-Language Model Sensitivity to Semantic and Lexical Alterations",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1194,
    "title": "SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1195,
    "title": "SciCode: A Research Coding Benchmark Curated by Scientists",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1196,
    "title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1197,
    "title": "SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "survey"
    ]
  },
  {
    "id": 1198,
    "title": "Semi-Truths: A Large-Scale Dataset of AI-Augmented Images for Evaluating Robustness of AI-Generated Image detectors",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1199,
    "title": "Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1200,
    "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1201,
    "title": "Sim2Real-Fire: A Multi-modal Simulation Dataset for Forecast and Backtracking of Real-world Forest Fire",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1202,
    "title": "Slice-100K: A Multimodal Dataset for Extrusion-based 3D Printing",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1203,
    "title": "SolarCube: An Integrative Benchmark Dataset Harnessing Satellite and In-situ Observations for Large-scale Solar Energy Forecasting",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1204,
    "title": "Stratified Prediction-Powered Inference for Effective Hybrid Evaluation of Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1205,
    "title": "SureMap: Simultaneous mean estimation for single-task and multi-task disaggregated evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1206,
    "title": "SynRS3D: A Synthetic Dataset for Global 3D Semantic Understanding from Monocular Remote Sensing Imagery",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1207,
    "title": "T2Vs Meet VLMs: A Scalable Multimodal Dataset for Visual Harmfulness Recognition",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1208,
    "title": "TAPVid-3D: A Benchmark for Tracking Any Point in 3D",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1209,
    "title": "TARP-VP: Towards Evaluation of Transferred  Adversarial Robustness and Privacy on Label  Mapping Visual Prompting Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1210,
    "title": "TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1211,
    "title": "TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1212,
    "title": "Task-oriented Time Series Imputation Evaluation via Generalized Representers",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1213,
    "title": "Terra: A Multimodal Spatio-Temporal Dataset Spanning the Earth",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1214,
    "title": "The Elephant in the Room: Towards A Reliable Time-Series Anomaly Detection Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1215,
    "title": "The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1216,
    "title": "The State of Data Curation at NeurIPS: An Assessment of Dataset Development Practices in the Datasets and Benchmarks Track",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1217,
    "title": "The iNaturalist Sounds Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1218,
    "title": "Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1219,
    "title": "To Err Like Human: Affective Bias-Inspired Measures for Visual Emotion Recognition Evaluation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1220,
    "title": "Topic-Conversation Relevance (TCR)  Dataset and Benchmarks",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1221,
    "title": "TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1222,
    "title": "Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1223,
    "title": "Toward a Stable, Fair, and Comprehensive Evaluation of Object Hallucination in Large Vision-Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1224,
    "title": "Towards General Loop Invariant Generation: A Benchmark of Programs with Memory Manipulation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1225,
    "title": "Towards a Scalable Reference-Free Evaluation of Generative Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1226,
    "title": "Two-way Deconfounder for Off-policy Evaluation in Causal Reinforcement Learning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1227,
    "title": "UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1228,
    "title": "UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-World Document Analysis",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1229,
    "title": "USCILab3D: A Large-scale, Long-term, Semantically Annotated Outdoor Dataset",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1230,
    "title": "UniTox: Leveraging LLMs to Curate a Unified Dataset of Drug-Induced Toxicity from FDA Labels",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1231,
    "title": "UnlearnCanvas:  Stylized Image Dataset for Enhanced Machine Unlearning Evaluation in Diffusion Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1232,
    "title": "Unleashing Multispectral Video's Potential in Semantic Segmentation: A Semi-supervised Viewpoint and New UAV-View Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1233,
    "title": "Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for Chemistry",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1234,
    "title": "V-PETL Bench: A Unified Visual Parameter-Efficient Transfer Learning Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1235,
    "title": "VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "corpus"
    ]
  },
  {
    "id": 1236,
    "title": "VHELM: A Holistic Evaluation of Vision Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1237,
    "title": "VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1238,
    "title": "VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1239,
    "title": "VRSBench: A Versatile Vision-Language Benchmark Dataset for Remote Sensing Image Understanding",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1240,
    "title": "ViLCo-Bench: VIdeo Language COntinual learning Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1241,
    "title": "VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1242,
    "title": "VideoGUI: A Benchmark for GUI Automation from Instructional Videos",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1243,
    "title": "Vision Transformer Neural Architecture Search for Out-of-Distribution Generalization: Benchmark and Insights",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1244,
    "title": "Visual CoT: Advancing Multi-Modal Language Models with a Comprehensive Dataset and Benchmark for Chain-of-Thought Reasoning",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1245,
    "title": "Vocal Call Locator Benchmark (VCL) for localizing rodent vocalizations from multi-channel audio",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1246,
    "title": "WFCRL: A Multi-Agent Reinforcement Learning Benchmark for Wind Farm Control",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1247,
    "title": "WONDERBREAD: A Benchmark for Evaluating Multimodal Foundation Models on Business Process Management Tasks",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1248,
    "title": "Weak Supervision Performance Evaluation via Partial Identification",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1249,
    "title": "Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1250,
    "title": "WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1251,
    "title": "WenMind: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Classical Literature and Language Arts",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1252,
    "title": "What to Say and When to Say it: Live Fitness Coaching as a Testbed for Situated Interaction",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 1253,
    "title": "When LLMs Meet Cunning Texts: A Fallacy Understanding Benchmark for Large Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1254,
    "title": "WikiContradict: A Benchmark for Evaluating LLMs on Real-World Knowledge Conflicts from Wikipedia",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1255,
    "title": "WikiDBs: A Large-Scale Corpus Of Relational Databases From Wikidata",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1256,
    "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1257,
    "title": "WildPPG: A Real-World PPG Dataset of Long Continuous Recordings",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1258,
    "title": "WindsorML: High-Fidelity Computational Fluid Dynamics Dataset For Automotive Aerodynamics",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1259,
    "title": "ZSC-Eval: An Evaluation Toolkit and Benchmark for Multi-agent Zero-shot Coordination",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1260,
    "title": "ZeroMark: Towards Dataset Ownership Verification without Disclosing Watermark",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1261,
    "title": "cPAPERS: A Dataset of Situated and Multimodal Interactive Conversations in Scientific Papers",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1262,
    "title": "dopanim: A Dataset of Doppelganger Animals with Noisy Annotations from Multiple Humans",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1263,
    "title": "emg2pose: A Large and Diverse Benchmark for Surface Electromyographic Hand Pose Estimation",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1264,
    "title": "emg2qwerty: A Large Dataset with Baselines for Touch Typing using Surface Electromyography",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1265,
    "title": "kGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution",
    "conference": "NEURIPS",
    "year": 2024,
    "domain": "AI/ML",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1266,
    "title": "A Principled Path to Fitted Distributional Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1267,
    "title": "A Reliable Cryptographic Framework for Empirical Machine Unlearning Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1268,
    "title": "ADG: Ambient Diffusion-Guided Dataset Recovery for Corruption-Robust Offline Reinforcement Learning",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1269,
    "title": "ARECHO: Autoregressive Evaluation via Chain-Based Hypothesis Optimization for Speech Multi-Metric Estimation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1270,
    "title": "AgentAuditor: Human-level Safety and Security Evaluation for LLM Agents",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1271,
    "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1272,
    "title": "ArchCAD-400K: A Large-Scale CAD drawings Dataset and New Baseline for Panoptic Symbol Spotting",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1273,
    "title": "Beyond Modality Collapse: Representation Blending for Multimodal Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1274,
    "title": "Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1275,
    "title": "Breaking the Order Barrier: Off-Policy Evaluation for Confounded POMDPs",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1276,
    "title": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1277,
    "title": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1278,
    "title": "Cost-aware LLM-based Online Dataset Annotation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1279,
    "title": "CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1280,
    "title": "DataRater: Meta-Learned Dataset Curation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1281,
    "title": "Dataset Distillation for Pre-Trained Self-Supervised Vision Models",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1282,
    "title": "Dataset Distillation of 3D Point Clouds via Distribution Matching",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1283,
    "title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1284,
    "title": "Diffusion Federated Dataset",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1285,
    "title": "Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1286,
    "title": "EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1287,
    "title": "Efficient Multimodal Dataset Distillation via Generative Models",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1288,
    "title": "Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1289,
    "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1290,
    "title": "FairDD: Fair Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1291,
    "title": "Finite-Sample Analysis of Policy Evaluation for Robust Average Reward Reinforcement Learning",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1292,
    "title": "Handling Missing Responses under Cluster Dependence with Applications to Language Model Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1293,
    "title": "HollowFlow: Efficient Sample Likelihood Evaluation using Hollow Message Passing",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1294,
    "title": "How Benchmark Prediction from Fewer Data Misses the Mark",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1295,
    "title": "Hyperbolic Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1296,
    "title": "Image Stitching in Adverse Condition: A Bidirectional-Consistency Learning Framework and Benchmark",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1297,
    "title": "Impact of Dataset Properties on Membership Inference Vulnerability of Deep Transfer Learning",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1298,
    "title": "Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1299,
    "title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1300,
    "title": "Learning to Solve Complex Problems via Dataset Decomposition",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1301,
    "title": "Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1302,
    "title": "Model–Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn’t the Right One",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1303,
    "title": "Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable Affective Computing",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1304,
    "title": "Optimizing Distributional Geometry Alignment with Optimal Transport for Generative Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1305,
    "title": "Personalized Safety in LLMs: A Benchmark and A Planning-Based Agent Approach",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1306,
    "title": "Pessimistic Data Integration for Policy Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1307,
    "title": "Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1308,
    "title": "SNEAKDOOR: Stealthy Backdoor Attacks against Distribution Matching-based Dataset Condensation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1309,
    "title": "STITCH-OPE: Trajectory Stitching with Guided Diffusion for Off-Policy Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1310,
    "title": "Scalable Evaluation and Neural Models for Compositional Generalization",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1311,
    "title": "ShoeFit: A New Dataset and Dual-image-stream DiT Framework for Virtual Footwear Try-On",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1312,
    "title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1313,
    "title": "Silencer: From Discovery to Mitigation of Self-Bias in LLM-as-Benchmark-Generator",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1314,
    "title": "Simultaneous Statistical Inference for Off-Policy Evaluation in Reinforcement Learning",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1315,
    "title": "Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1316,
    "title": "Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1317,
    "title": "Toward Interpretable Evaluation Measures for Time Series Segmentation",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1318,
    "title": "Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1319,
    "title": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1320,
    "title": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1321,
    "title": "Unlocking Dataset Distillation with Diffusion Models",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1322,
    "title": "VIBE: Annotation-Free Video-to-Text Information Bottleneck Evaluation for TL;DR",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1323,
    "title": "Wide-Horizon Thinking and Simulation-Based Evaluation for Real-World LLM Planning with Multifaceted Constraints",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1324,
    "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1325,
    "title": "rStar-Coder: Scaling Competitive Code Reasoning  with a  Large-Scale Verified  Dataset",
    "conference": "NEURIPS",
    "year": 2025,
    "domain": "AI/ML",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1326,
    "title": "$360+x$: A Panoptic Multi-modal Scene Understanding Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1327,
    "title": "$M^3$-UDA: A New Benchmark for Unsupervised Domain Adaptive Fetal Cardiac Structure Detection",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1328,
    "title": "360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1329,
    "title": "4D-DRESS: A 4D Dataset of Real-World Human Clothing With Semantic Annotations",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1330,
    "title": "A Call to Reflect on Evaluation Practices for Age Estimation: Comparative Analysis of the State-of-the-Art and a Unified Benchmark",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1331,
    "title": "Advancing Saliency Ranking with Human Fixations: Dataset, Models and Benchmarks",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1332,
    "title": "BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1333,
    "title": "CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1334,
    "title": "Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1335,
    "title": "ConCon-Chi: Concept-Context Chimera Benchmark for Personalized Vision-Language Tasks",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1336,
    "title": "Continuous Optical Zooming: A Benchmark for Arbitrary-Scale Image Super-Resolution in Real World",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1337,
    "title": "D$^4$M: Dataset Distillation via Disentangled Diffusion Model",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1338,
    "title": "DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1339,
    "title": "DiLiGenRT: A Photometric Stereo Dataset with Quantified Roughness and Translucency",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1340,
    "title": "DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1341,
    "title": "Domain Gap Embeddings for Generative Dataset Augmentation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1342,
    "title": "DriveTrack: A Benchmark for Long-Range Point Tracking in Real-World Videos",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1343,
    "title": "DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1344,
    "title": "EFHQ: Multi-purpose ExtremePose-Face-HQ dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1345,
    "title": "Efficient Dataset Distillation via Minimax Diffusion",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1346,
    "title": "EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1347,
    "title": "Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1348,
    "title": "Exploiting Inter-sample and Inter-feature Relations in Dataset Distillation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1349,
    "title": "FISBe: A real-world benchmark dataset for instance segmentation of long-range thin filamentous structures",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1350,
    "title": "FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1351,
    "title": "FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1352,
    "title": "FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1353,
    "title": "GOAT-Bench: A Benchmark for Multi-modal Lifelong Navigation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1354,
    "title": "Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene Scale and Realism Tradeoffs for ObjectGoal Navigation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1355,
    "title": "HardMo: A Large-Scale Hardcase Dataset for Motion Capture",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1356,
    "title": "HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1357,
    "title": "HouseCat6D - A Large-Scale Multi-Modal Category Level 6D Object Perception Dataset with Household Objects in Realistic Scenarios",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1358,
    "title": "How to Train Neural Field Representations: A Comprehensive Study and Benchmark",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1359,
    "title": "Insect-Foundation: A Foundation Model and Large-scale 1M Dataset for Visual Insect Understanding",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1360,
    "title": "InstaGen: Enhancing Object Detection by Training on Synthetic Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1361,
    "title": "JRDB-PanoTrack: An Open-world Panoptic Segmentation and Tracking Robotic Dataset in Crowded Human Environments",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1362,
    "title": "JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1363,
    "title": "LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1364,
    "title": "LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1365,
    "title": "LUWA Dataset: Learning Lithic Use-Wear Analysis on Microscopic Images",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1366,
    "title": "LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1367,
    "title": "Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1368,
    "title": "LiDAR-Net: A Real-scanned 3D Point Cloud Dataset for Indoor Scenes",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1369,
    "title": "MAGICK: A Large-scale Captioned Dataset from Matting Generated Images using Chroma Keying",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1370,
    "title": "MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1371,
    "title": "MCD: Diverse Large-Scale Multi-Campus Dataset for Robot Perception",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Navigation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1372,
    "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1373,
    "title": "MMSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1374,
    "title": "MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1375,
    "title": "MSU-4S - The Michigan State University Four Seasons Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1376,
    "title": "MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1377,
    "title": "MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1378,
    "title": "MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1379,
    "title": "MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human Captures",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1380,
    "title": "MatSynth: A Modern PBR Materials Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1381,
    "title": "Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1382,
    "title": "Multiview Aerial Visual RECognition (MAVREC) Dataset: Can Multi-view Improve Aerial Visual Perception?",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1383,
    "title": "Narrative Action Evaluation with Prompt-Guided Multimodal Interaction",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1384,
    "title": "OAKINK2: A Dataset of Bimanual Hands-Object Manipulation in Complex Task Completion",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1385,
    "title": "OmniMedVQA: A New Large-Scale Comprehensive  Evaluation Benchmark for Medical LVLM",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1386,
    "title": "On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1387,
    "title": "Pseudo Label Refinery for Unsupervised Domain Adaptation on Cross-dataset 3D Object Detection",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1388,
    "title": "RCooper: A Real-world Large-scale Dataset for Roadside Cooperative Perception",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1389,
    "title": "RELI11D: A Comprehensive Multimodal Human Motion Dataset and Method",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1390,
    "title": "Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1391,
    "title": "Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1392,
    "title": "Real-World Mobile Image Denoising Dataset with Efficient Baselines",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1393,
    "title": "Rethinking FID: Towards a Better Evaluation Metric for Image Generation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1394,
    "title": "Rethinking the Evaluation Protocol of Domain Generalization",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1395,
    "title": "SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1396,
    "title": "SURE: SUrvey REcipes for building reliable and robust deep networks",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1397,
    "title": "Sieve: Multimodal Dataset Pruning using Image-Captioning Models",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1398,
    "title": "Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for Enhanced Dataset Pruning",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1399,
    "title": "Spectral and Polarization Vision: Spectro-polarimetric Real-world Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1400,
    "title": "Spectrum AUC Difference (SAUCD): Human Aligned 3D Shape Evaluation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1401,
    "title": "SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1402,
    "title": "SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1403,
    "title": "SynFog: A Photo-realistic Synthetic Fog Dataset based on End-to-end Imaging Simulation for Advancing Real-World Defogging in Autonomous Driving",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1404,
    "title": "THRONE: A Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1405,
    "title": "TUMTraf V2X Cooperative Perception Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1406,
    "title": "The STVchrono Dataset: Towards Continuous Change Recognition in Time",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1407,
    "title": "Towards Automatic Power Battery Detection:  New Challenge, Benchmark Dataset and Baseline",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1408,
    "title": "Towards Co-Evaluation of Cameras, HDR, and Algorithms for Industrial-Grade 6DoF Pose Estimation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1409,
    "title": "Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1410,
    "title": "Towards Modern Image Manipulation Localization: A Large-Scale Dataset and Novel Methods",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1411,
    "title": "Towards Real-World HDR Video Reconstruction: A Large-Scale Benchmark Dataset and A Two-Stage Alignment Network",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1412,
    "title": "Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1413,
    "title": "Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1414,
    "title": "Towards Surveillance Video-and-Language Understanding: New Dataset, Baselines, and Challenges",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1415,
    "title": "Towards a Perceptual Evaluation Framework for Lighting Estimation",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1416,
    "title": "Traffic Scene Parsing through the TSP6K Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1417,
    "title": "UVEB: A Large-scale Benchmark and Baseline Towards Real-World Underwater Video Enhancement",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1418,
    "title": "Uncovering What, Why and How:  A Comprehensive Benchmark for Causation Understanding of Video Anomaly",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1419,
    "title": "VBench: Comprehensive Benchmark Suite for Video Generative Models",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1420,
    "title": "When Visual Grounding Meets Gigapixel-level Large-scale Scenes: Benchmark and Approach",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1421,
    "title": "WinSyn: A High Resolution Testbed for Synthetic Data",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 1422,
    "title": "eTraM: Event-based Traffic Monitoring Dataset",
    "conference": "CVPR",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1423,
    "title": "3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1424,
    "title": "A Dataset for Semantic Segmentation in the Presence of Unknowns",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1425,
    "title": "AG-VPReID: A Challenging Large-Scale Benchmark for Aerial-Ground Video-based Person Re-Identification",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1426,
    "title": "AI-Face: A Million-Scale Demographically Annotated AI-Generated Face Dataset and Fairness Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1427,
    "title": "AVQACL: A Novel Benchmark for Audio-Visual Question Answering Continual Learning",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1428,
    "title": "Advancing Manga Analysis: Comprehensive Segmentation Annotations for the Manga109 Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1429,
    "title": "Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1430,
    "title": "Automatic Spectral Calibration of Hyperspectral Images: Method, Dataset and Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1431,
    "title": "BASKET: A Large-Scale Video Dataset for Fine-Grained Skill Estimation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1432,
    "title": "BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1433,
    "title": "Beyond Image Classification: A Video Benchmark and Dual-Branch Hybrid Discrimination Framework for Compositional Zero-Shot Learning",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1434,
    "title": "CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1435,
    "title": "CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1436,
    "title": "Can Machines Understand Composition? Dataset and Benchmark for Photographic Image Composition Embedding and Understanding",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1437,
    "title": "CheXwhatsApp: A Dataset for Exploring Challenges in the Diagnosis of Chest X-rays through Mobile Devices",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1438,
    "title": "CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1439,
    "title": "CholecTrack20: A Multi-Perspective Tracking Dataset for Surgical Tools",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1440,
    "title": "ClimbingCap: Multi-Modal Dataset and Method for Rock Climbing in World Coordinate",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1441,
    "title": "CoMM: A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1442,
    "title": "CroCoDL: Cross-device Collaborative Dataset for Localization",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1443,
    "title": "Curriculum Coarse-to-Fine Selection for High-IPC Dataset Distillation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1444,
    "title": "DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1445,
    "title": "Dataset Distillation with Neural Characteristic Function: A Minmax Perspective",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1446,
    "title": "Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1447,
    "title": "Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1448,
    "title": "Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1449,
    "title": "ECBench: Can Multi-modal Foundation Models Understand the Egocentric World? A Holistic Embodied Cognition Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1450,
    "title": "EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1451,
    "title": "EgoPressure: A Dataset for Hand Pressure and Pose Estimation in Egocentric Vision",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1452,
    "title": "Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1453,
    "title": "Enhancing Dataset Distillation via Non-Critical Region Refinement",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1454,
    "title": "EntropyMark: Towards More Harmless Backdoor Watermark via Entropy-based Constraint for Open-source Dataset Copyright Protection",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1455,
    "title": "Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1456,
    "title": "FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1457,
    "title": "FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1458,
    "title": "Fish-Vista: A Multi-Purpose Dataset for Understanding & Identification of Traits from Images",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1459,
    "title": "Forensics-Bench: A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1460,
    "title": "From Laboratory to Real World: A New Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1461,
    "title": "From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1462,
    "title": "GazeGene: Large-scale Synthetic Gaze Dataset with 3D Eyeball Annotations",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1463,
    "title": "Gen3DEval: Using vLLMs for Automatic Evaluation of Generated 3D Objects",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1464,
    "title": "GigaHands: A Massive Annotated Dataset of Bimanual Hand Activities",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1465,
    "title": "HD-EPIC: A Highly-Detailed Egocentric Video Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1466,
    "title": "HELVIPAD: A Real-World Dataset for Omnidirectional Stereo Depth Estimation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1467,
    "title": "HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1468,
    "title": "HarmonySet: A Comprehensive Dataset for Understanding Video-Music Semantic Alignment and Temporal Synchronization",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1469,
    "title": "Hierarchical Features Matter: A Deep Exploration of Progressive Parameterization Method for Dataset Distillation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1470,
    "title": "High Dynamic Range Video Compression: A Large-Scale Benchmark Dataset and A Learned Bit-depth Scalable Compression Algorithm",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1471,
    "title": "HuPerFlow: A Comprehensive Benchmark for Human vs. Machine Motion Estimation Comparison",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1472,
    "title": "HumanRig: Learning Automatic Rigging for Humanoid Character in a Large Scale Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1473,
    "title": "HyperPose: Hypernetwork-Infused Camera Pose Localization and an Extended Cambridge Landmarks Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1474,
    "title": "Image Over Text: Transforming Formula Recognition Evaluation with Character Detection Matching",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1475,
    "title": "Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1476,
    "title": "Is Your World Simulator a Good Story Presenter? A Consecutive Events-Based Benchmark for Future Long Video Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1477,
    "title": "Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1478,
    "title": "LiSu: A Dataset and Method for LiDAR Surface Normal Estimation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1479,
    "title": "LongVALE: Vision-Audio-Language-Event Benchmark Towards Time-Aware Omni-Modal Perception of Long Videos",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1480,
    "title": "Low-Biased General Annotated Dataset Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1481,
    "title": "Lux Post Facto: Learning Portrait Performance Relighting with Conditional Video Diffusion and a Hybrid Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1482,
    "title": "M3GYM: A Large-Scale Multimodal Multi-view Multi-person Pose Dataset for Fitness Activity Understanding in Real-world Settings",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1483,
    "title": "MANTA: A Large-Scale Multi-View and Visual-Text Anomaly Detection Dataset for Tiny Objects",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1484,
    "title": "MM-OR: A Large Multimodal Operating Room Dataset for Semantic Understanding of High-Intensity Surgical Environments",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1485,
    "title": "MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1486,
    "title": "MaSS13K: A Matting-level Semantic Segmentation Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1487,
    "title": "MammAlps: A Multi-view Video Behavior Monitoring Dataset of Wild Mammals in the Swiss Alps",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1488,
    "title": "MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1489,
    "title": "Mono2Stereo: A Benchmark and Empirical Study for Stereo Conversion",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1490,
    "title": "Mosaic of Modalities: A Comprehensive Benchmark for Multimodal Graph Learning",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1491,
    "title": "Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1492,
    "title": "MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1493,
    "title": "MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieval",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1494,
    "title": "MultimodalStudio: A Heterogeneous Sensor Dataset and Framework for Neural Rendering across Multiple Imaging Modalities",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1495,
    "title": "NSD-Imagery: A Benchmark Dataset for Extending fMRI Vision Decoding Methods to Mental Imagery",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1496,
    "title": "Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1497,
    "title": "ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1498,
    "title": "OPTICAL: Leveraging Optimal Transport for Contribution Allocation in Dataset Distillation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1499,
    "title": "ORIDa: Object-centric Real-world Image Composition Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1500,
    "title": "Object Detection using Event Camera: A MoE Heat Conduction based Detector and A New Benchmark Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1501,
    "title": "OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1502,
    "title": "OmniMMI: A Comprehensive Multi-modal Interaction Benchmark in Streaming Video Contexts",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1503,
    "title": "OpenHumanVid: A Large-Scale High-Quality Dataset for Enhancing Human-Centric Video Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1504,
    "title": "OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1505,
    "title": "OpticalNet: An Optical Imaging Dataset and Benchmark Beyond the Diffraction Limit",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1506,
    "title": "PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1507,
    "title": "Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1508,
    "title": "PhD: A ChatGPT-Prompted Visual Hallucination Evaluation Dataset",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1509,
    "title": "Pixel-aligned RGB-NIR Stereo Imaging and Dataset for Robot Vision",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Navigation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1510,
    "title": "PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1511,
    "title": "Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1512,
    "title": "Q-Bench-Video: Benchmark the Video Quality Understanding of LMMs",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1513,
    "title": "Quad-Pixel Image Defocus Deblurring: A New Benchmark and Model",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1514,
    "title": "RAEncoder: A Label-Free Reversible Adversarial Examples Encoder for Dataset Intellectual Property Protection",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1515,
    "title": "RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1516,
    "title": "RUBIK: A Structured Benchmark for Image Matching across Geometric Challenges",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1517,
    "title": "Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1518,
    "title": "RealEdit: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1519,
    "title": "Rethinking Diffusion for Text-Driven Human Motion Generation: Redundant Representations, Evaluation, and Masked Autoregression",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1520,
    "title": "RipVIS: Rip Currents Video Instance Segmentation Benchmark for Beach Monitoring and Safety",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1521,
    "title": "RoadSocial: A Diverse VideoQA Dataset and Benchmark for Road Event Understanding from Social Video Narratives",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1522,
    "title": "RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot Perception and Navigation in Crowded and Unstructured Environments",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Navigation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1523,
    "title": "RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1524,
    "title": "SMTPD: A New Benchmark for Temporal Prediction of Social Media Popularity",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1525,
    "title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1526,
    "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1527,
    "title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1528,
    "title": "Sketchtopia: A Dataset and Foundational Agents for Benchmarking Asynchronous Multimodal Communication with Iconic Feedback",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1529,
    "title": "Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Mutimodal Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1530,
    "title": "Spotting the Unexpected (STU): A 3D LiDAR Dataset for Anomaly Segmentation in Autonomous Driving",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1531,
    "title": "T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1532,
    "title": "T2V-CompBench: A Comprehensive Benchmark for Compositional Text-to-video Generation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1533,
    "title": "Taxonomy-Aware Evaluation of Vision-Language Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1534,
    "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1535,
    "title": "Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1536,
    "title": "Towards Million-Scale Adversarial Robustness Evaluation With Stronger Individual Attacks",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1537,
    "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1538,
    "title": "Towards Satellite Image Road Graph Extraction: A Global-Scale Dataset and A Novel Method",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1539,
    "title": "Towards Scalable Human-aligned Benchmark for Text-guided Image Editing",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1540,
    "title": "Towards Stable and Storage-efficient Dataset Distillation: Matching Convexified Trajectory",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1541,
    "title": "Towards Universal Dataset Distillation via Task-Driven Diffusion",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1542,
    "title": "UCM-VeID V2: A Richer Dataset and A Pre-training Method for UAV Cross-Modality Vehicle Re-Identification",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1543,
    "title": "UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1544,
    "title": "Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1545,
    "title": "VL-RewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1546,
    "title": "ViCaS: A Dataset for Combining Holistic and Pixel-level Video Understanding using Captions with Grounded Segmentation",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1547,
    "title": "Video-Bench: Human-Aligned Video Generation Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1548,
    "title": "Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1549,
    "title": "VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1550,
    "title": "VinaBench: Benchmark for Faithful and Consistent Visual Narratives",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1551,
    "title": "What Makes a Good Dataset for Knowledge Distillation?",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1552,
    "title": "nnWNet: Rethinking the Use of Transformers in Biomedical Image Segmentation and Calling for a Unified Evaluation Benchmark",
    "conference": "CVPR",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1553,
    "title": "\"A Framework for Efficient Model Evaluation through Stratification, Sampling, and Estimation\"",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1554,
    "title": "\"BlinkVision: A Benchmark for Optical Flow, Scene Flow and Point Tracking Estimation using RGB Frames and Events\"",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1555,
    "title": "\"On Calibration of Object Detectors: Pitfalls, Evaluation and Baselines\"",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1556,
    "title": "\"Towards Dual Transparent Liquid Level Estimation in Biomedical Lab: Dataset, Methods and Practice\"",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1557,
    "title": "A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1558,
    "title": "A New Dataset and Framework for Real-World Blurred Images Super-Resolution",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1559,
    "title": "A high-quality robust diffusion framework for corrupted dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1560,
    "title": "AD3: Introducing a score for Anomaly Detection Dataset Difficulty assessment using VIADUCT dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1561,
    "title": "AID-AppEAL: Automatic Image Dataset and Algorithm for Content Appeal Enhancement and Assessment Labeling",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1562,
    "title": "AddBiomechanics Dataset: Capturing the Physics of Human Motion at Scale",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1563,
    "title": "Affective Visual Dialog: A Large-Scale Benchmark for Emotional Reasoning Based on Visually Grounded Conversations",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1564,
    "title": "AutoEval-Video: An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1565,
    "title": "BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1566,
    "title": "BugNIST - a Large Volumetric Dataset for Detection under Domain Shift",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1567,
    "title": "CMD: A Cross Mechanism Domain Adaptation Dataset for 3D Object Detection",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1568,
    "title": "COM Kitchens: An Unedited Overhead-view Procedural Videos Dataset a Vision-Language Benchmark",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1569,
    "title": "Caltech Aerial RGB-Thermal Dataset in the Wild",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1570,
    "title": "Context-Aware Action Recognition: Introducing a Comprehensive Dataset for Behavior Contrast",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1571,
    "title": "Cross-Platform Video Person ReID: A New Benchmark Dataset and Adaptation Approach",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1572,
    "title": "CrossScore: A Multi-View Approach to Image Evaluation and Scoring",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1573,
    "title": "DailyDVS-200: A Comprehensive Benchmark Dataset for Event-Based Action Recognition",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1574,
    "title": "DataDream: Few-shot Guided Dataset Generation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1575,
    "title": "Dataset Distillation by Automatic Training Trajectories",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1576,
    "title": "Dataset Enhancement with Instance-Level Augmentations",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1577,
    "title": "Dataset Growth",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1578,
    "title": "Dataset Quantization with Active Learning based Adaptive Sampling",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1579,
    "title": "Distill Gold from Massive Ores: Bi-level Data Pruning towards Efficient Dataset Distillation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1580,
    "title": "E3V-K5: An Authentic Benchmark for Redefining Video-Based Energy Expenditure Estimation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1581,
    "title": "EgoBody3M: Egocentric Body Tracking on a VR Headset using a Diverse Dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1582,
    "title": "EgoCVR: An Egocentric Benchmark for Fine-Grained Composed Video Retrieval",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1583,
    "title": "Enhancing Plausibility Evaluation for Generated Designs with Denoising Autoencoder",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1584,
    "title": "Event-based Head Pose Estimation: Benchmark and Method",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1585,
    "title": "FYI: Flip Your Images for Dataset Distillation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1586,
    "title": "Fully Authentic Visual Question Answering Dataset from Online Communities",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1587,
    "title": "GarmentCodeData: A Dataset of 3D Made-to-Measure Garments With Sewing Patterns",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1588,
    "title": "H-V2X: A Large Scale Highway Dataset for BEV Perception",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1589,
    "title": "HIMO: A New Benchmark for Full-Body Human Interacting with Multiple Objects",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1590,
    "title": "HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1591,
    "title": "HiFi-Score: Fine-grained Image Description Evaluation with Hierarchical Parsing Graphs",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1592,
    "title": "How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1593,
    "title": "HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and Analysis",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1594,
    "title": "Insect Identification in the Wild: The AMI Dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1595,
    "title": "LLM as Dataset Analyst: Subpopulation Structure Discovery with Large Language Model",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1596,
    "title": "LayeredFlow: A Real-World Benchmark for Non-Lambertian Multi-Layer Optical Flow",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1597,
    "title": "Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1598,
    "title": "Long-range Turbulence Mitigation: A Large-scale Dataset and A Coarse-to-fine Framework",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1599,
    "title": "MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1600,
    "title": "MMVR: Millimeter-wave Multi-View Radar Dataset and Benchmark for Indoor Perception",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1601,
    "title": "MSD: A Benchmark Dataset for Floor Plan Generation of Building Complexes",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1602,
    "title": "MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1603,
    "title": "MetaAT: Active Testing for Label-Efficient Evaluation of Dense Recognition Tasks",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1604,
    "title": "Neural Spectral Decomposition for Dataset Distillation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1605,
    "title": "Omni6D: Large-Vocabulary 3D Object Dataset for Category-Level 6D Object Pose Estimation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1606,
    "title": "Omni6DPose: A Benchmark and Model for Universal 6D Object Pose Estimation and Tracking",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1607,
    "title": "OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1608,
    "title": "OmniNOCS: A unified NOCS dataset and model for 3D lifting of 2D objects",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1609,
    "title": "On the Evaluation Consistency of Attribution-based Explanations",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1610,
    "title": "OphNet: A Large-Scale Video Benchmark for Ophthalmic Surgical Workflow Understanding",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1611,
    "title": "PDT Uav Target Detection Dataset for Pests and Diseases Tree",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1612,
    "title": "PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1613,
    "title": "PathMMU: A Massive Multimodal Expert-Level Benchmark for Understanding and Reasoning in Pathology",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1614,
    "title": "Perceptual Evaluation of Audio-Visual Synchrony Grounded in Viewers’ Opinion Scores",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1615,
    "title": "PetFace: A Large-Scale Dataset and Benchmark for Animal Identification",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1616,
    "title": "Plain-Det: A Plain Multi-Dataset Object Detector",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1617,
    "title": "RT-Pose: A 4D Radar-Tensor based 3D Human Pose Estimation and Localization Benchmark",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1618,
    "title": "Raindrop Clarity: A Dual-Focused Dataset for Day and Night Raindrop Removal",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1619,
    "title": "ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environments",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1620,
    "title": "Rethinking Data Bias: Dataset Copyright Protection via Embedding Class-wise Hidden Bias",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1621,
    "title": "RoScenes: A Large-scale Multi-view 3D Dataset for Roadside Perception",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1622,
    "title": "Seeing Faces in Things: A Model and Dataset for Pareidolia",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1623,
    "title": "SemTrack: A Large-scale Dataset for Semantic Tracking in the Wild",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1624,
    "title": "SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1625,
    "title": "SkyScenes: A Synthetic Dataset for Aerial Scene Understanding",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1626,
    "title": "Spatially-Variant Degradation Model for Dataset-free Super-resolution",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1627,
    "title": "Teddy: Efficient Large-Scale Dataset Distillation via Taylor-Approximated Matching",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1628,
    "title": "Towards Model-Agnostic Dataset Condensation by Heterogeneous Models",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1629,
    "title": "Towards More Practical Group Activity Detection: A New Benchmark and Model",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1630,
    "title": "Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with Spatial Relation Matching",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1631,
    "title": "Towards Reliable Evaluation and Fast Training of Robust Semantic Segmentation Models",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1632,
    "title": "TrafficNight : An Aerial Multimodal Benchmark For Nighttime Vehicle Surveillance",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1633,
    "title": "Tree-D Fusion: Simulation-Ready Tree Dataset from Single Images with Diffusion Priors",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1634,
    "title": "Uncertainty Calibration with Energy Based Instance-wise Scaling in the Wild Dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1635,
    "title": "Unlocking the Potential of Federated Learning: The Symphony of Dataset Distillation via Deep Generative Latents",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1636,
    "title": "Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1637,
    "title": "V2X-Real: a Largs-Scale Dataset for Vehicle-to-Everything Cooperative Perception",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1638,
    "title": "VETRA: A Dataset for Vehicle Tracking in Aerial Imagery - New Challenges for Multi-Object Tracking",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1639,
    "title": "VITATECS: A Diagnostic Dataset for Temporal Concept Understanding of Video-Language Models",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1640,
    "title": "WAS: Dataset and Methods for Artistic Text Segmentation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Segmentation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1641,
    "title": "WTS: A Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1642,
    "title": "When Pedestrian Detection Meets Multi-Modal Learning: Generalist Model and Benchmark Dataset",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1643,
    "title": "WiMANS: A Benchmark Dataset for WiFi-based Multi-user Activity Sensing",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1644,
    "title": "WorldPose: A World Cup Dataset for Global 3D Human Pose Estimation",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1645,
    "title": "m&m’s: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks",
    "conference": "ECCV",
    "year": 2024,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1646,
    "title": "3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1647,
    "title": "3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1648,
    "title": "A Real-world Display Inverse Rendering Dataset",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1649,
    "title": "ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1650,
    "title": "ARGUS: Hallucination and Omission Evaluation in Video-LLMs",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1651,
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1652,
    "title": "AgroBench: Vision-Language Model Benchmark in Agriculture",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1653,
    "title": "Anomaly Detection of Integrated Circuits Package Substrates Using the Large Vision Model SAIC: Dataset Construction, Methodology, and Application",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1654,
    "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1655,
    "title": "Automated Model Evaluation for Object Detection via Prediction Consistency and Reliability",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1656,
    "title": "Benchmarking Burst Super-Resolution for Polarization Images: Noise Dataset and Analysis",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1657,
    "title": "Beyond Walking: A Large-Scale Image-Text Benchmark for Text-based Person Anomaly Search",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1658,
    "title": "Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1659,
    "title": "Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1660,
    "title": "BlueNeg: A 35mm Negative Film Dataset for Restoring Channel-Heterogeneous Deterioration",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1661,
    "title": "Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1662,
    "title": "CAP: Evaluation of Persuasive and Creative Image Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1663,
    "title": "CC-OCR: A Comprehensive and Challenging OCR Benchmark for Evaluating Large Multimodal Models in Literacy",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1664,
    "title": "CMB-ML: A Cosmic Microwave Background Dataset for the Oldest Possible Computer Vision Task",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1665,
    "title": "CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1666,
    "title": "CULTURE3D: A Large-Scale and Diverse Dataset of Cultural Landmarks and Terrains for Gaussian-Based Scene Rendering",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1667,
    "title": "CaO2: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1668,
    "title": "CityNav: A Large-Scale Dataset for Real-World Aerial Navigation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Navigation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1669,
    "title": "ClaraVid: A Holistic Scene Reconstruction Benchmark From Aerial Perspective With Delentropy-Based Complexity Profiling",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1670,
    "title": "Context-Aware Academic Emotion Dataset and Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1671,
    "title": "Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1672,
    "title": "DH-FaceVid-1K: A Large-Scale High-Quality Dataset for Face Video Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1673,
    "title": "DIMCIM: A Quantitative Evaluation Framework for Default-mode Diversity and Generalization in Text-to-Image Generative Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1674,
    "title": "Dataset Distillation as Data Compression: A Rate-Utility Perspective",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1675,
    "title": "Dataset Distillation via Vision-Language Category Prototype",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1676,
    "title": "Dataset Distillation via the Wasserstein Metric",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1677,
    "title": "Dataset Ownership Verification for Pre-trained Masked Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1678,
    "title": "Derm1M: A Million-scale Vision-Language Dataset Aligned with Clinical Ontology Knowledge for Dermatology",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1679,
    "title": "DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1680,
    "title": "DiffTell: A High-Quality Dataset for Describing Image Manipulation Changes",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1681,
    "title": "Diversity-Enhanced Distribution Alignment for Dataset Distillation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1682,
    "title": "DropletVideo: A Dataset and Approach to Explore Integral Spatio-Temporal Consistent Video Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1683,
    "title": "ETVA: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1684,
    "title": "End-to-End Driving with Online Trajectory Evaluation via BEV World Model",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1685,
    "title": "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1686,
    "title": "Extrapolated Urban View Synthesis Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1687,
    "title": "F-Bench: Rethinking Human Preference Evaluation Metrics for Benchmarking Face Generation, Customization, and Restoration",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1688,
    "title": "Feature Coding in the Era of Large Models: Dataset, Test Conditions, and Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1689,
    "title": "FiVE-Bench: A Fine-grained Video Editing Benchmark for Evaluating Emerging Diffusion and Rectified Flow Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1690,
    "title": "Fine-Grained Evaluation of Large Vision-Language Models in Autonomous Driving",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1691,
    "title": "FineMotion: A Dataset and Benchmark with both Spatial and Temporal Annotation for Fine-grained Motion Generation and Editing",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1692,
    "title": "From Abyssal Darkness to Blinding Glare: A Benchmark on Extreme Exposure Correction in Real World",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1693,
    "title": "From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1694,
    "title": "Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1695,
    "title": "GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1696,
    "title": "GRAB: A Challenging GRaph Analysis Benchmark for Large Multimodal Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1697,
    "title": "GUIOdyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1698,
    "title": "HUMOTO: A 4D Dataset of Mocap Human Object Interactions",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1699,
    "title": "Heavy Labels Out! Dataset Distillation with Label Space Lightening",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1700,
    "title": "Holistic Unlearning Benchmark: A Multi-Faceted Evaluation for Text-to-Image Diffusion Model Unlearning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1701,
    "title": "How Far are AI-generated Videos from Simulating the 3D Visual World: A Learned 3D Evaluation Approach",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1702,
    "title": "HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1703,
    "title": "ICE-Bench: A Unified and Comprehensive Benchmark for Image Creating and Editing",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1704,
    "title": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1705,
    "title": "IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1706,
    "title": "ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1707,
    "title": "Improving Noise Efficiency in Privacy-preserving Dataset Distillation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1708,
    "title": "InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1709,
    "title": "JailbreakDiffBench: A Comprehensive Benchmark for Jailbreaking Diffusion Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1710,
    "title": "Kaputt: A Large-Scale Dataset for Visual Defect Detection",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1711,
    "title": "LANGTRAJ: Diffusion Model and Dataset for Language-Conditioned Trajectory Simulation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1712,
    "title": "LVBench: An Extreme Long Video Understanding Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1713,
    "title": "Learning Large Motion Estimation from Intermediate Representations with a High-Resolution Optical Flow Dataset Featuring Long-Range Dynamic Motion",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1714,
    "title": "LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1715,
    "title": "MA-CIR: A Multimodal Arithmetic Benchmark for Composed Image Retrieval",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1716,
    "title": "MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1717,
    "title": "MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1718,
    "title": "MEH: A Multi-Style Dataset and Toolkit for Advancing Egyptian Hieroglyph Recognition",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1719,
    "title": "MIEB: Massive Image Embedding Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1720,
    "title": "MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1721,
    "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1722,
    "title": "MVGBench: a Comprehensive Benchmark for Multi-view Generation Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1723,
    "title": "Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1724,
    "title": "MoMa-Kitchen: A 100K+ Benchmark for Affordance-Grounded Last-Mile Navigation in Mobile Manipulation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1725,
    "title": "Modeling Saliency Dataset Bias",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1726,
    "title": "Multi-modal Multi-platform Person Re-Identification: Benchmark and Method",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1727,
    "title": "MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1728,
    "title": "NuPlanQA: A Large-Scale Dataset and Benchmark for Multi-View Driving Scene Understanding in Multi-Modal Large Language Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1729,
    "title": "OmniDiff: A Comprehensive Benchmark for Fine-grained Image Difference Captioning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1730,
    "title": "One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1731,
    "title": "OpenSubstance: A High-quality Measured Dataset of Multi-View and -Lighting Images and Shapes",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1732,
    "title": "PBFG: A New Physically-Based Dataset and Removal of Lens Flares and Glares",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1733,
    "title": "Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1734,
    "title": "Princeton365: A Diverse Dataset with Accurate Camera Pose",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1735,
    "title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1736,
    "title": "ProJudge: A Multi-Modal Multi-Discipline Benchmark and Instruction-Tuning Dataset for MLLM-based Process Judges",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1737,
    "title": "R-LiViT: A LiDAR-Visual-Thermal Dataset Enabling Vulnerable Road User Focused Roadside Perception",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1738,
    "title": "RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1739,
    "title": "ROADWork: A Dataset and Benchmark for Learning to Recognize, Observe, Analyze and Drive Through Work Zones",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1740,
    "title": "ROVI: A VLM-LLM Re-Captioned Dataset for Open-Vocabulary Instance-Grounded Text-to-Image Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1741,
    "title": "ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1742,
    "title": "RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1743,
    "title": "Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 1744,
    "title": "RobAVA: A Large-scale Dataset and Baseline Towards Video based Robotic Arm Action Understanding",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1745,
    "title": "Robust Dataset Condensation using Supervised Contrastive Learning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1746,
    "title": "SITE: towards Spatial Intelligence Thorough Evaluation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1747,
    "title": "Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1748,
    "title": "SciVid: Cross-Domain Evaluation of Video Models in Scientific Applications",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1749,
    "title": "SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1750,
    "title": "SimpleVQA: Multimodal Factuality Evaluation for Multimodal Large Language Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1751,
    "title": "Stylized-Face: A Million-level Stylized Face Dataset for Face Recognition",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1752,
    "title": "TAD-E2E: A Large-scale End-to-end Autonomous Driving Dataset",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1753,
    "title": "TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for Image-to-Video Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1754,
    "title": "Target Bias Is All You Need: Zero-Shot Debiasing of Vision-Language Models with Bias Corpus",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1755,
    "title": "ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1756,
    "title": "Towards Annotation-Free Evaluation: KPAScore for Human Keypoint Detection",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1757,
    "title": "Towards Comprehensive Lecture Slides Understanding: Large-scale Dataset and Effective Method",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1758,
    "title": "Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1759,
    "title": "Towards Video Turing Test: Video Comprehension and Reasoning Benchmark with Complex Visual Narratives",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1760,
    "title": "TrackVerse: A Large-Scale Object-Centric Video Dataset for Image-Level Representation Learning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1761,
    "title": "TrackVerse: A Large-scale Dataset of Object Tracks for Visual Representation Learning",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1762,
    "title": "Tracking Tiny Drones against Clutter: Large-Scale Infrared Benchmark with Motion-Centric Adaptive Algorithm",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1763,
    "title": "Trust but Verify: Programmatic VLM Evaluation in the Wild",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1764,
    "title": "UAVScenes: A Multi-Modal Dataset for UAVs",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1765,
    "title": "UDC-VIT: A Real-World Video Dataset for Under-Display Cameras",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1766,
    "title": "UINavBench: A Framework for Comprehensive Evaluation of Interactive Digital Agents",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1767,
    "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1768,
    "title": "V2XScenes: A Multiple Challenging Traffic Conditions Dataset for Large-Range Vehicle-Infrastructure Collaborative Perception",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Autonomous Driving",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1769,
    "title": "VIGFace: Virtual Identity Generation for Privacy-Free Face Recognition Dataset",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1770,
    "title": "VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Robotics & Embodied AI Benchmark",
    "subcategory": "Manipulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1771,
    "title": "VLRMBench: A Comprehensive and Challenging Benchmark for Vision-Language Reward Models",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1772,
    "title": "VMBench: A Benchmark for Perception-Aligned Video Motion Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1773,
    "title": "VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1774,
    "title": "VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1775,
    "title": "WorldScore: A Unified Evaluation Benchmark for World Generation",
    "conference": "ICCV",
    "year": 2025,
    "domain": "CV",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1776,
    "title": "3DLNews: A Three-decade Dataset of US Local News Articles",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1777,
    "title": "A Generative Benchmark Creation Framework for Detecting Common Data Table Versions",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1778,
    "title": "A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1779,
    "title": "Advancing Multivariate Time Series Anomaly Detection: A Comprehensive Benchmark with Real-World Data from Alibaba Cloud",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1780,
    "title": "An Evaluation Framework for Attributed Information Retrieval using Large Language Models",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1781,
    "title": "Assessing Image Inpainting via Re-Inpainting Self-Consistency Evaluation",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1782,
    "title": "Automatic Large Language Model Evaluation via Peer Review",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1783,
    "title": "BioMAISx: A Corpus for Aspect-Based Sentiment Analysis of Media Representations of Agricultural Biotechnologies in Africa",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1784,
    "title": "CH-Mits: A Cross-Modal Dataset for User Sentiment Analysis on Chinese Social Media",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1785,
    "title": "CheckGuard: Advancing Stolen Check Detection with a Cross-Modal Image-Text Benchmark Dataset",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1786,
    "title": "Covid19-twitter: A Twitter-based Dataset for Discourse Analysis in Sentence-level Sentiment Classification",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1787,
    "title": "Dataset Generation for Korean Urban Parks Analysis with Large Language Models",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1788,
    "title": "Distributed Boosting: An Enhancing Method on Dataset Distillation",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1789,
    "title": "EDGE: Evaluation Framework for Logical vs. Subgraph Explanations for Node Classifiers on Knowledge Graphs",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1790,
    "title": "EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1791,
    "title": "Ensembles for Outlier Detection and Evaluation",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1792,
    "title": "Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1793,
    "title": "InfinityMath: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1794,
    "title": "Introducing CausalBench: A Flexible Benchmark Framework for Causal Analysis and Machine Learning",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1795,
    "title": "LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1796,
    "title": "LeDQA: A Chinese Legal Case Document-based Question Answering Dataset",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1797,
    "title": "M3: A Multi-Image Multi-Modal Entity Alignment Dataset",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1798,
    "title": "MMLRec: A Unified Multi-Task and Multi-Scenario Learning Benchmark for Recommendation",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1799,
    "title": "Multi-turn Classroom Dialogue Dataset: Assessing Student Performance from One-on-one Conversations",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1800,
    "title": "On Evaluation Metrics for Diversity-enhanced Recommendations",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1801,
    "title": "Privacy-preserving Spatial Dataset Search in Cloud",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1802,
    "title": "Towards Fair Graph Anomaly Detection: Problem, Benchmark Datasets, and Evaluation",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1803,
    "title": "Understanding the User: An Intent-Based Ranking Dataset",
    "conference": "CIKM",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1804,
    "title": "A Content-Driven Micro-Video Recommendation Dataset at Scale",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1805,
    "title": "A Large-Scale Dataset of Interactions Between Weibo Users and Platform-Empowered LLM Agent",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1806,
    "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1807,
    "title": "A Privacy-preserving Spatial Dataset Joinable Search in Cloud",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1808,
    "title": "A Universal Framework for Offline Serendipity Evaluation in Recommender Systems via Large Language Models",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1809,
    "title": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1810,
    "title": "Achoio: A Skill-Aware Evaluation Management System for Text-To-Speech Research",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1811,
    "title": "Adapting LLMs for Personalized Evaluation of Explanations for Recommendations: A Meta-Learning Approach based on MAML",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1812,
    "title": "Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Benchmark",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1813,
    "title": "C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1814,
    "title": "CLUE: Using Large Language Models for Judging Document Usefulness in Web Search Evaluation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1815,
    "title": "CSMD: Curated Multimodal Dataset for Chinese Stock Analysis",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1816,
    "title": "Chunked Data Shapley: A Scalable Dataset Quality Assessment for Machine Learning",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1817,
    "title": "ClimateBench-M: A Multi-Modal Climate Data Benchmark with a Simple Generative Method",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1818,
    "title": "E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1819,
    "title": "EventPuzzle: A Benchmark for Multi-Perspective Event Prediction Based on Event Arguments",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1820,
    "title": "FediData: A Comprehensive Multi-Modal Fediverse Dataset from Mastodon",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1821,
    "title": "FinS-Pilot: A Benchmark for Online Financial RAG System",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1822,
    "title": "GSTBench: A Benchmark Study on the Transferability of Graph Self-Supervised Learning",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1823,
    "title": "HUSK: A Hierarchically Structured Urban Knowledge Graph Dataset for Multi-Level Spatial Tasks",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1824,
    "title": "IARD: Intruder Activity Recognition Dataset for Threat Detection",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1825,
    "title": "Identifying Critical Segments Affecting Piano Performance Evaluation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1826,
    "title": "Internet of Things Dataset for Human Operator Activity Recognition in Industrial Environment",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1827,
    "title": "Investigating the Usage and Evaluation of Quantum Computing Technologies for Information Access",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1828,
    "title": "Maneno Yetu: Dynamic Corpus Construction and Pretraining for Swahili NLP",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1829,
    "title": "Multi-Source Knowledge Pruning for Retrieval-Augmented Generation: A Benchmark and Empirical Study",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1830,
    "title": "Multimodal Banking Dataset: Understanding Client Needs through Event Sequences",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1831,
    "title": "NLP-QA: A Large-scale Benchmark for Informative Question Answering over Natural Language Processing Documents",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1832,
    "title": "OFedED: One-shot Federated Learning with Model Ensemble and Dataset Distillation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1833,
    "title": "PEQQS: a Dataset for Probing Extractive Quantity-focused Question Answering from Scientific Literature",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1834,
    "title": "Pedagogy-R1: Pedagogical Large Reasoning Model and Well-balanced Educational Benchmark",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1835,
    "title": "PersonaGen: A Persona-Driven Open-Ended Machine-Generated Text Dataset",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1836,
    "title": "QueryBridge: One Million Annotated Questions with SPARQL Queries - Dataset for Question Answering over Knowledge Graphs",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Knowledge Graph QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1837,
    "title": "ReDSM5: A Reddit Dataset for DSM-5 Depression Detection",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1838,
    "title": "Real-E: A Foundation Benchmark for Advancing Robust and Generalizable Electricity Forecasting",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1839,
    "title": "Revisiting Trajectories to Road: A New Diffusion Model and A New Dataset with 1, 000, 000, 000 Points",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1840,
    "title": "RuSemCor: A Word Sense Disambiguation corpus for Russian",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1841,
    "title": "S2Cap: A Benchmark and a Baseline for Singing Style Captioning",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1842,
    "title": "Scenario-Wise Rec: A Multi-Scenario Recommendation Benchmark",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1843,
    "title": "SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1844,
    "title": "SemiSegECG: A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1845,
    "title": "TSD-CT: A Benchmark Dataset for Truthfulness Stance Detection",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1846,
    "title": "Towards Fully-Automated Materials Discovery via Large-Scale Synthesis Dataset and Expert-Level LLM-as-a-Judge",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1847,
    "title": "Towards Understanding Bias in Synthetic Data for Evaluation",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1848,
    "title": "Traffic Safety Evaluation Based on Macroscopic Traffic Features in Road Tunnels",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1849,
    "title": "VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1850,
    "title": "Watch Your Step: A Fine-Grained Evaluation Framework for Multi-hop Knowledge Editing in Large Language Models",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1851,
    "title": "When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1852,
    "title": "YTCommentVerse: A Multi-Category Multi-Lingual YouTube Comment Corpus",
    "conference": "CIKM",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1853,
    "title": "A Field Guide to Automatic Evaluation of LLM-Generated Summaries",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1854,
    "title": "A Large Scale Test Corpus for Semantic Table Search",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1855,
    "title": "ACE-2005-PT: Corpus for Event Extraction in Portuguese",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1856,
    "title": "ACORDAR 2.0: A Test Collection for Ad Hoc Dataset Retrieval with Densely Pooled Datasets and Question-Style Queries",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1857,
    "title": "Amazon-KG: A Knowledge Graph Enhanced Cross-Domain Recommendation Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1858,
    "title": "An E-Commerce Dataset Revealing Variations during Sales",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1859,
    "title": "ArabicaQA: A Comprehensive Dataset for Arabic Question Answering",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1860,
    "title": "CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to Web Relevance Ranking",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1861,
    "title": "Can We Trust Recommender System Fairness Evaluation? The Role of Fairness and Relevance",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1862,
    "title": "ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1863,
    "title": "CivilSum: A Dataset for Abstractive Summarization of Indian Court Decisions",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1864,
    "title": "CorpusLM: Towards a Unified Language Model on Corpus for Knowledge-Intensive Tasks",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1865,
    "title": "Counterfactual Ranking Evaluation with Flexible Click Models",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1866,
    "title": "Dataset and Models for Item Recommendation Using Multi-Modal User Interactions",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1867,
    "title": "EEG-SVRec: An EEG Dataset with User Multidimensional Affective Engagement Labels in Short Video Recommendation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1868,
    "title": "Enhancing Dataset Search with Compact Data Snippets",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1869,
    "title": "Exploring Multi-Scenario Multi-Modal CTR Prediction with a Large Scale Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1870,
    "title": "JDivPS: A Diversified Product Search Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1871,
    "title": "LADy 💃: A Benchmark Toolkit for Latent Aspect Detection Enriched with Backtranslation Augmentation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1872,
    "title": "LLM4Eval: Large Language Model for Evaluation in IR",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1873,
    "title": "LeCaRDv2: A Large-Scale Chinese Legal Case Retrieval Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1874,
    "title": "MIND Your Language: A Multilingual Dataset for Cross-lingual News Recommendation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1875,
    "title": "Machine Generated Explanations and Their Evaluation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1876,
    "title": "MealRec+: A Meal Recommendation Dataset with Meal-Course Affiliation for Personalization and Healthiness",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1877,
    "title": "OEHR: An Orthopedic Electronic Health Record Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1878,
    "title": "On the Evaluation of Machine-Generated Reports",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1879,
    "title": "OpenSiteRec: An Open Dataset for Site Recommendation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1880,
    "title": "ProCIS: A Benchmark for Proactive Retrieval in Conversations",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1881,
    "title": "QuanTemp: A real-world open-domain benchmark for fact-checking numerical claims",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1882,
    "title": "Rethinking the Evaluation of Dialogue Systems: Effects of User Feedback on Crowdworkers and LLMs",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1883,
    "title": "SuicidEmoji: Derived Emoji Dataset and Tasks for Suicide-Related Social Content",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1884,
    "title": "SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1885,
    "title": "Synthetic Test Collections for Retrieval Evaluation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1886,
    "title": "Systematic Evaluation of Neural Retrieval Models on the Touché 2020 Argument Retrieval Subset of BEIR",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1887,
    "title": "Towards Robust QA Evaluation via Open LLMs",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1888,
    "title": "TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1889,
    "title": "Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1890,
    "title": "Unmasking Privacy: A Reproduction and Evaluation Study of Obfuscation-based Perturbation Techniques for Collaborative Filtering",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1891,
    "title": "What Matters in a Measure? A Perspective from Large-Scale Search Evaluation",
    "conference": "SIGIR",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1892,
    "title": "A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1893,
    "title": "A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1894,
    "title": "Advancing Ship Re-Identification in the Wild: The ShipReID-2400 Benchmark Dataset and D2InterNet Baseline Method",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1895,
    "title": "An EEG Dataset of Word-level Brain Responses for Semantic Text Relevance",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1896,
    "title": "Benchmark Granularity and Model Robustness for Image-Text Retrieval: A Reproducibility Study",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1897,
    "title": "ClusterChat: Multi-Feature Search for Corpus Exploration",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1898,
    "title": "CoLoTa: A Dataset for Entity-based Commonsense Reasoning over Long-Tail Knowledge",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1899,
    "title": "CoSRec: A Joint Conversational Search and Recommendation Dataset",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1900,
    "title": "Continuous Evaluation in Information Retrieval Across Methods and Time",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1901,
    "title": "Conversational Search: Towards Personalization and Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1902,
    "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1903,
    "title": "Extending MovieLens-32M to Provide New Evaluation Objectives",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1904,
    "title": "FACTors: A New Dataset for Studying the Fact-checking Ecosystem",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1905,
    "title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Community Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1906,
    "title": "IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1907,
    "title": "IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "corpus"
    ]
  },
  {
    "id": 1908,
    "title": "KIMERA: From Evaluation-as-a-Service to Evaluation-in-the-Cloud",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1909,
    "title": "LLM-Driven Usefulness Labeling for IR Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1910,
    "title": "LLM-Empowered Creator Simulation for Long-Term Evaluation of Recommender Systems Under Information Asymmetry",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1911,
    "title": "LLM4Eval: Large Language Model for Evaluation in IR",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1912,
    "title": "LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1913,
    "title": "Limitations of Automatic Relevance Assessments with Large Language Models for Fair and Reliable Retrieval Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1914,
    "title": "MRAMG-Bench: A Comprehensive Benchmark for Advancing Multimodal Retrieval-Augmented Multimodal Generation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1915,
    "title": "Measuring Hypothesis Testing Errors in the Evaluation of Retrieval Systems",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1916,
    "title": "MultiConAD: A Unified Multilingual Conversational Dataset for Early Alzheimer's Detection",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1917,
    "title": "Multilingual Evaluation of Main Content Extractors for Web Pages",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1918,
    "title": "OmniNER2025: Diverse and Comprehensive Fine-Grained NER Dataset and Benchmark for Chinese",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 1919,
    "title": "PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1920,
    "title": "PILs of Knowledge: A Synthetic Benchmark for Evaluating Question Answering Systems in Healthcare",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1921,
    "title": "PUB: An LLM-Enhanced Personality-Driven User Behaviour Simulator for Recommender System Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1922,
    "title": "Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1923,
    "title": "Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1924,
    "title": "RecGaze: The First Eye Tracking and User Interaction Dataset for Carousel Interfaces",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1925,
    "title": "Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for Deep Research",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1926,
    "title": "SAGraph: A Large-Scale Social Graph Dataset with Comprehensive Context for Influencer Selection in Marketing",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1927,
    "title": "SynthTRIPs: A Knowledge-Grounded Framework for Benchmark Data Generation for Personalized Tourism Recommenders",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1928,
    "title": "The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1929,
    "title": "The Viability of Crowdsourcing for RAG Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1930,
    "title": "Theory and Toolkits for User Simulation in the Era of Generative AI: User Modeling, Synthetic Data Generation, and System Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1931,
    "title": "Tip of the Tongue Query Elicitation for Simulated Evaluation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1932,
    "title": "Toward Holistic Evaluation of Recommender Systems Powered by Generative Models",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Recommendation System Benchmark",
    "subcategory": "",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1933,
    "title": "U-Sticker: A Large-Scale Multi-Domain User Sticker Dataset for Retrieval and Personalization",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1934,
    "title": "Understanding Large Language Model Performance in Software Engineering: A Large-scale Question Answering Benchmark",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1935,
    "title": "Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1936,
    "title": "WebClasSeg-25: A Dual-Classified Webpage Segmentation Dataset - Integrating Functional and Maturity-Based Analysis",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1937,
    "title": "WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1938,
    "title": "Wrong Answers Can Also Be Useful: PlausibleQA - A Large-Scale QA Dataset with Answer Plausibility Scores",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1939,
    "title": "nlcTables: A Dataset for Marrying Natural Language Conditions with Table Discovery",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1940,
    "title": "μDS: Multi-Objective Data Snippet Extraction for Dataset Search",
    "conference": "SIGIR",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1941,
    "title": "A Comprehensive Survey and Experimental Study of Subgraph Matching: Trends, Unbiasedness, and Interaction",
    "conference": "SIGMOD",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1942,
    "title": "MWP: Multi-Window Parallel Evaluation of Regular Path Queries on Streaming Graphs",
    "conference": "SIGMOD",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Graph Database",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1943,
    "title": "Relational Algorithms for Top-k Query Evaluation",
    "conference": "SIGMOD",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1944,
    "title": "An Adaptive Benchmark for Modeling User Exploration of Large Datasets",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1945,
    "title": "Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Knowledge Graph QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1946,
    "title": "Graph Edit Distance Estimation: A New Heuristic and A Holistic Evaluation of Learning-based Methods",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1947,
    "title": "Graph-Based Vector Search: An Experimental Evaluation of the State-of-the-Art",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1948,
    "title": "On the Feasibility and Benefits of Extensive Evaluation",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1949,
    "title": "Online Marketplace: A Benchmark for Data Management in Microservices",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1950,
    "title": "Revisiting Graph Analytics Benchmark",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1951,
    "title": "Yannakakis+: Practical Acyclic Query Evaluation with Theoretical Guarantees",
    "conference": "SIGMOD",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1952,
    "title": "A Comprehensive Benchmark on Spectral GNNs: The Impact on Efficiency, Memory, and Effectiveness",
    "conference": "SIGMOD",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1953,
    "title": "A Comprehensive Survey of Subgraph Matching: [Experiments & Analysis]",
    "conference": "SIGMOD",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1954,
    "title": "Analysis and Evaluation of Using Microsecond-Latency Memory for In-Memory Indices and Caches in SSD-Based Key-Value Stores",
    "conference": "SIGMOD",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1955,
    "title": "Burr: A Benchmark for Ontology Learning from Relational Databases",
    "conference": "SIGMOD",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1956,
    "title": "DRPQ: Distributed Evaluation of Regular Path Queries On Streaming Graphs",
    "conference": "SIGMOD",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Graph Database",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1957,
    "title": "A Benchmark Study of Deep-RL Methods for Maximum Coverage Problems over Graphs",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1958,
    "title": "An Empirical Evaluation of Columnar Storage Formats",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1959,
    "title": "An Experimental Evaluation of Anomaly Detection in Time Series",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1960,
    "title": "Comprehensive Evaluation of GNN Training Systems: A Data Management Perspective",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1961,
    "title": "Contributions Estimation in Federated Learning: A Comprehensive Experimental Evaluation",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1962,
    "title": "Fainder: A Fast and Accurate Index for Distribution-Aware Dataset Search",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1963,
    "title": "How do Categorical Duplicates Affect ML? A New Benchmark and Empirical Analyses",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1964,
    "title": "HyBench: A New Benchmark for HTAP Databases",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1965,
    "title": "ImputeVIS: An Interactive Evaluator to Benchmark Imputation Techniques for Time Series Data",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1966,
    "title": "LakeBench: A Benchmark for Discovering Joinable and Unionable Tables in Data Lakes",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1967,
    "title": "ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1968,
    "title": "TSGBench: Time Series Generation Benchmark",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1969,
    "title": "Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1970,
    "title": "The Dawn of Natural Language to SQL: Are We Fully Ready? [Experiment, Analysis & Benchmark ]",
    "conference": "VLDB",
    "year": 2024,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1971,
    "title": "A Comprehensive Survey and Experimental Study of Learning-based Community Search",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Community Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1972,
    "title": "An Evaluation of N-Gram Selection Strategies for Regular Expression Indexing in Contemporary Text Analysis Tasks",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1973,
    "title": "Anarchy in the Database: A Survey and Evaluation of Database Management System Extensibility",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 1974,
    "title": "Beyond Compression: A Comprehensive Evaluation of Lossless Floating-Point Compression",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1975,
    "title": "DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1976,
    "title": "Extensible and Robust Evaluation of Similarity Queries",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1977,
    "title": "GPEmu: A GPU Emulator for Faster and Cheaper Prototyping and Evaluation of Deep Learning System Research",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1978,
    "title": "Less is More: Efficient Time Series Dataset Condensation via Two-fold Modal Matching",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 1979,
    "title": "OpenFGL: A Comprehensive Benchmark for Federated Graph Learning",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1980,
    "title": "ParSEval: Plan-aware Test Database Generation for SQL Equivalence Evaluation",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1981,
    "title": "PrivEval: a tool for interactive evaluation of privacy metrics in synthetic data generation",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1982,
    "title": "Privacy-Enhanced Database Synthesis for Benchmark Publishing",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1983,
    "title": "Robust Plan Evaluation based on Approximate Probabilistic Machine Learning",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1984,
    "title": "Still More Shades of Null: An Evaluation Suite for Responsible Missing Value Imputation [Experiment, Analysis and Benchmark]",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 1985,
    "title": "The Accuracy of Cardinality Estimators: Unraveling the Evaluation Result Conundrum",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1986,
    "title": "The LDBC Financial Benchmark: Transaction Workload",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1987,
    "title": "The ParClusterers Benchmark Suite (PCBS): A Fine-Grained Analysis of Scalable Graph Clustering",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Graph & Network Benchmark",
    "subcategory": "Graph Learning",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1988,
    "title": "The UDFBench Benchmark for General-purpose UDF Queries",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1989,
    "title": "Time Series Motif Discovery: A Comprehensive Evaluation",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1990,
    "title": "Towards Sufficient GPU-accelerated Dynamic Graph Management: Survey and Experiment",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Graph Database",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 1991,
    "title": "VecCity: A Taxonomy-guided Library for Map Entity Representation Learning [Experiment, Analysis & Benchmark]",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Index & Storage",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1992,
    "title": "WeShap: Weak Supervision Source Evaluation with Shapley Values",
    "conference": "VLDB",
    "year": 2025,
    "domain": "DB/IR",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1993,
    "title": "An Experimental Evaluation of Hybrid Querying on Vectors",
    "conference": "VLDB",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1994,
    "title": "ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines",
    "conference": "VLDB",
    "year": 2026,
    "domain": "DB/IR",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1995,
    "title": "$\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 1996,
    "title": "A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for Verifiers of Reasoning Chains",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 1997,
    "title": "A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1998,
    "title": "AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German Consumer Contracts",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 1999,
    "title": "ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2000,
    "title": "Advancement in Graph Understanding: A Multimodal Benchmark and Fine-Tuning of Vision-Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2001,
    "title": "An Empirical Analysis on Large Language Models in Debate Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2002,
    "title": "Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2003,
    "title": "Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2004,
    "title": "Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2005,
    "title": "Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2006,
    "title": "BatchEval: Towards Human-like Text Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2007,
    "title": "Benchmarking Knowledge Boundary for Large Language Models: A Different Perspective on Model Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2008,
    "title": "BizBench: A Quantitative Reasoning Benchmark for Business and Finance",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2009,
    "title": "CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2010,
    "title": "COSMIC: Mutual Information for Task-Agnostic Summarization Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2011,
    "title": "CSCD-NS: a Chinese Spelling Check Dataset for Native Speakers",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2012,
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2013,
    "title": "Cleaner Pretraining Corpus Curation with Neural Web Scraping",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2014,
    "title": "CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2015,
    "title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2016,
    "title": "CritiqueLLM: Towards an Informative Critique Generation Model for Evaluation of Large Language Model Generation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2017,
    "title": "DAPR: A Benchmark on Document-Aware Passage Retrieval",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2018,
    "title": "DIALECTBENCH: An NLP Benchmark for Dialects, Varieties, and Closely-Related Languages",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2019,
    "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2020,
    "title": "DocLens: Multi-aspect Fine-grained Medical Text Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2021,
    "title": "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2022,
    "title": "Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2023,
    "title": "ECBD: Evidence-Centered Benchmark Design for NLP",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2024,
    "title": "EUROPA: A Legal Multilingual Keyphrase Generation Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2025,
    "title": "EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2026,
    "title": "EZ-STANCE: A Large Dataset for English Zero-Shot Stance Detection",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2027,
    "title": "Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2028,
    "title": "F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2029,
    "title": "FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2030,
    "title": "FOFO: A Benchmark to Evaluate LLMs’ Format-Following Capability",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2031,
    "title": "FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2032,
    "title": "FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2033,
    "title": "Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2034,
    "title": "FinTextQA: A Dataset for Long-form Financial Question Answering",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2035,
    "title": "FineSurE: Fine-grained Summarization Evaluation using LLMs",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2036,
    "title": "FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2037,
    "title": "Fora: A corpus and framework for the study of facilitated dialogue",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2038,
    "title": "Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2039,
    "title": "GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2040,
    "title": "GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2041,
    "title": "Greed is All You Need: An Evaluation of Tokenizer Inference Methods",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2042,
    "title": "Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2043,
    "title": "How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2044,
    "title": "I am a Strange Dataset: Metalinguistic Tests for Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2045,
    "title": "IEPile: Unearthing Large Scale Schema-Conditioned Information Extraction Corpus",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2046,
    "title": "IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2047,
    "title": "IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2048,
    "title": "IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2049,
    "title": "Intrinsic Task-based Evaluation for Referring Expression Generation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2050,
    "title": "Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2051,
    "title": "KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2052,
    "title": "KnowledgeFMath: A Knowledge-Intensive Math Reasoning Dataset in Finance Domains",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2053,
    "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2054,
    "title": "LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2055,
    "title": "LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2056,
    "title": "Latxa: An Open Language Model and Evaluation Suite for Basque",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2057,
    "title": "LePaRD: A Large-Scale Dataset of Judicial Citations to Precedent",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2058,
    "title": "Legal Case Retrieval: A Survey of the State of the Art",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2059,
    "title": "LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2060,
    "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2061,
    "title": "M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2062,
    "title": "M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2063,
    "title": "M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2064,
    "title": "M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2065,
    "title": "MAVEN-ARG: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2066,
    "title": "MELA: Multilingual Evaluation of Linguistic Acceptability",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2067,
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2068,
    "title": "MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2069,
    "title": "MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2070,
    "title": "MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2071,
    "title": "MULFE: A Multi-Level Benchmark for Free Text Model Editing",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2072,
    "title": "Media Framing: A typology and Survey of Computational Approaches Across Disciplines",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2073,
    "title": "Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2074,
    "title": "MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2075,
    "title": "Metaphor Understanding Challenge Dataset for LLMs",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2076,
    "title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2077,
    "title": "MultiLegalPile: A 689GB Multilingual Legal Corpus",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2078,
    "title": "MultiPICo: Multilingual Perspectivist Irony Corpus",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2079,
    "title": "Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2080,
    "title": "NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2081,
    "title": "Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2082,
    "title": "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2083,
    "title": "Navigating the Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2084,
    "title": "NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2085,
    "title": "OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2086,
    "title": "One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2087,
    "title": "Open Grounded Planning: Challenges and Benchmark Construction",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2088,
    "title": "Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "leaderboard"
    ]
  },
  {
    "id": 2089,
    "title": "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2090,
    "title": "PAGED: A Benchmark for Procedural Graphs Extraction from Documents",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2091,
    "title": "Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2092,
    "title": "PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2093,
    "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2094,
    "title": "RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2095,
    "title": "RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2096,
    "title": "REFINESUMM: Self-Refining MLLM for Generating a Multimodal Summarization Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2097,
    "title": "RORA: Robust Free-Text Rationale Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2098,
    "title": "Re3: A Holistic Framework and Dataset for Modeling Collaborative Document Revision",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2099,
    "title": "Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2100,
    "title": "SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2101,
    "title": "SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2102,
    "title": "SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2103,
    "title": "Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2104,
    "title": "Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2105,
    "title": "SyllabusQA: A Course Logistics Question Answering Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2106,
    "title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2107,
    "title": "The MERSA Dataset and a Transformer-Based Approach for Speech Emotion Recognition",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2108,
    "title": "Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2109,
    "title": "TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2110,
    "title": "Towards Real-World Writing Assistance: A Chinese Character Checking Benchmark with Faked and Misspelled Characters",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2111,
    "title": "UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised Fine-tuning Dataset",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2112,
    "title": "Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2113,
    "title": "VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2114,
    "title": "VisDiaHalBench: A Visual Dialogue Benchmark For Diagnosing Hallucination in Large Vision-Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2115,
    "title": "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2116,
    "title": "What Do Dialect Speakers Want? A Survey of Attitudes Towards Language Technology for German Dialects",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2117,
    "title": "XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval",
    "conference": "ACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2118,
    "title": "$\\text{M}^3\\text{GQA}$: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2119,
    "title": "A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2120,
    "title": "A Survey of Post-Training Scaling in Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2121,
    "title": "A Survey on Foundation Language Models for Single-cell Biology",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2122,
    "title": "A Survey on Patent Analysis: From NLP to Multimodal AI",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2123,
    "title": "A-TASC: Asian TED-Based Automatic Subtitling Corpus",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2124,
    "title": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2125,
    "title": "AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2126,
    "title": "AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2127,
    "title": "AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2128,
    "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2129,
    "title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2130,
    "title": "AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2131,
    "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2132,
    "title": "Agri-CM$^3$: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2133,
    "title": "AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2134,
    "title": "An Expanded Massive Multilingual Dataset for High-Performance Language Technologies",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2135,
    "title": "Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2136,
    "title": "AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2137,
    "title": "Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2138,
    "title": "Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2139,
    "title": "BQA: Body Language Question Answering Dataset for Video Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2140,
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2141,
    "title": "Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2142,
    "title": "Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2143,
    "title": "BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2144,
    "title": "Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2145,
    "title": "Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2146,
    "title": "Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2147,
    "title": "Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2148,
    "title": "Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2149,
    "title": "Building a Long Text Privacy Policy Corpus with Multi-Class Labels",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2150,
    "title": "CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2151,
    "title": "CECT dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2152,
    "title": "CFBench: A Comprehensive Constraints-Following Benchmark for LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2153,
    "title": "CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2154,
    "title": "CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2155,
    "title": "CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2156,
    "title": "COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2157,
    "title": "CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2158,
    "title": "CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2159,
    "title": "Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2160,
    "title": "Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2161,
    "title": "Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2162,
    "title": "ChatBench: From Static Benchmarks to Human-AI Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2163,
    "title": "ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2164,
    "title": "Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2165,
    "title": "Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2166,
    "title": "CiteEval: Principle-Driven Citation Evaluation for Source Attribution",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2167,
    "title": "CoAM: Corpus of All-Type Multiword Expressions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2168,
    "title": "CoIR: A Comprehensive Benchmark for Code Information Retrieval Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2169,
    "title": "Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2170,
    "title": "CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2171,
    "title": "Com$^2$ : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2172,
    "title": "ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2173,
    "title": "ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2174,
    "title": "CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2175,
    "title": "Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2176,
    "title": "CrafText Benchmark: Advancing Language Grounding in Complex Multimodal Open-Ended World",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2177,
    "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2178,
    "title": "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2179,
    "title": "Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2180,
    "title": "CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs' Cultural Knowledge Through Human-AI Red-Teaming",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2181,
    "title": "Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2182,
    "title": "DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2183,
    "title": "DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2184,
    "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2185,
    "title": "Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2186,
    "title": "Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2187,
    "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2188,
    "title": "ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2189,
    "title": "EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2190,
    "title": "EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2191,
    "title": "EffiVLM-Bench: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Visual-Languge Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2192,
    "title": "Enhancing Human Evaluation in Machine Translation with Comparative Judgement",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2193,
    "title": "Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2194,
    "title": "Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2195,
    "title": "Evaluating the Evaluation of Diversity in Commonsense Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2196,
    "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2197,
    "title": "Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2198,
    "title": "EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2199,
    "title": "Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2200,
    "title": "FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2201,
    "title": "FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2202,
    "title": "FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2203,
    "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2204,
    "title": "FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2205,
    "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2206,
    "title": "FinMME: A Financial Multi-Modal Evaluation Dataset",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2207,
    "title": "From Selection to Generation: A Survey of LLM-based Active Learning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2208,
    "title": "GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2209,
    "title": "GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2210,
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2211,
    "title": "GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2212,
    "title": "Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2213,
    "title": "Grounded, or a Good Guesser? A Per-Question Balanced Dataset to Separate Blind from Grounded Models for Embodied Question Answering",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2214,
    "title": "HalluLens: LLM Hallucination Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2215,
    "title": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2216,
    "title": "HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2217,
    "title": "Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2218,
    "title": "Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2219,
    "title": "HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2220,
    "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2221,
    "title": "How LLMs Comprehend Temporal Structure in Narratives: A Case Study in Cognitive Evaluation of LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2222,
    "title": "How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2223,
    "title": "INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2224,
    "title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2225,
    "title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2226,
    "title": "ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2227,
    "title": "Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2228,
    "title": "IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2229,
    "title": "InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2230,
    "title": "Knowledge Boundary of Large Language Models: A Survey",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2231,
    "title": "KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2232,
    "title": "LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2233,
    "title": "LLMs Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2234,
    "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2235,
    "title": "La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "leaderboard"
    ]
  },
  {
    "id": 2236,
    "title": "LangMark: A Multilingual Dataset for Automatic Post-Editing",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2237,
    "title": "Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2238,
    "title": "LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2239,
    "title": "Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2240,
    "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2241,
    "title": "M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2242,
    "title": "M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2243,
    "title": "MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2244,
    "title": "MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2245,
    "title": "MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2246,
    "title": "MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2247,
    "title": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2248,
    "title": "MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2249,
    "title": "MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2250,
    "title": "MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2251,
    "title": "MUSTS: MUltilingual Semantic Textual Similarity Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2252,
    "title": "MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2253,
    "title": "Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2254,
    "title": "Meaning Variation and Data Quality in the Corpus of Founding Era American English",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2255,
    "title": "MemeQA: Holistic Evaluation of Meme Understanding",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2256,
    "title": "MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2257,
    "title": "Minimal Pair-Based Evaluation of Code-Switching",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2258,
    "title": "MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2259,
    "title": "Movie101v2: Improved Movie Narration Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2260,
    "title": "MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2261,
    "title": "Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2262,
    "title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2263,
    "title": "Navigating Rifts in Human-LLM Grounding: Study and Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2264,
    "title": "NewsInterview: a Dataset and a Playground to Evaluate LLMs' Grounding Gap via Informational Interviews",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2265,
    "title": "NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2266,
    "title": "OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2267,
    "title": "On Many-Shot In-Context Learning for Long-Context Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2268,
    "title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2269,
    "title": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasiveness Ratings, Persuasion Strategies, and Viewer Characteristic",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2270,
    "title": "Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2271,
    "title": "Personalized Generation In Large Model Era: A Survey",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2272,
    "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2273,
    "title": "PlanGenLLMs: A Modern Survey of LLM Planning Capabilities",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2274,
    "title": "PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2275,
    "title": "PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2276,
    "title": "Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2277,
    "title": "Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2278,
    "title": "Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2279,
    "title": "ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Recommendation System Benchmark",
    "subcategory": "Recommendation System Benchmark",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2280,
    "title": "PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2281,
    "title": "QAEval: Mixture of Evaluators for Question-Answering Task Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2282,
    "title": "QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2283,
    "title": "RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2284,
    "title": "REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2285,
    "title": "Recent Advances in Speech Language Models: A Survey",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2286,
    "title": "Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2287,
    "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2288,
    "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2289,
    "title": "Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2290,
    "title": "RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2291,
    "title": "SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2292,
    "title": "SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2293,
    "title": "SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2294,
    "title": "SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2295,
    "title": "SOTOPIA-Ω: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2296,
    "title": "SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2297,
    "title": "SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2298,
    "title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2299,
    "title": "SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2300,
    "title": "Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2301,
    "title": "Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2302,
    "title": "Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2303,
    "title": "Sinhala Encoder-only Language Models and Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2304,
    "title": "SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2305,
    "title": "SocialDuolingo: Interactive Evaluation for Cultural Competence in Language Agents",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2306,
    "title": "Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2307,
    "title": "SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2308,
    "title": "SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2309,
    "title": "SwiLTra-Bench: The Swiss Legal Translation Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2310,
    "title": "TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2311,
    "title": "TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2312,
    "title": "Targeted Syntactic Evaluation for Grammatical Error Correction",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2313,
    "title": "Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2314,
    "title": "The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2315,
    "title": "The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2316,
    "title": "The Mirage of Model Editing: Revisiting Evaluation in the Wild",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2317,
    "title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2318,
    "title": "ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2319,
    "title": "Towards Better Evaluation for Generated Patent Claims",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2320,
    "title": "Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2321,
    "title": "Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2322,
    "title": "Towards Effective Extraction and Evaluation of Factual Claims",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2323,
    "title": "Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2324,
    "title": "Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2325,
    "title": "Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2326,
    "title": "TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2327,
    "title": "TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2328,
    "title": "TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2329,
    "title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2330,
    "title": "Unanswerability Evaluation for Retrieval Augmented Generation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2331,
    "title": "Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2332,
    "title": "Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2333,
    "title": "VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2334,
    "title": "VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2335,
    "title": "Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2336,
    "title": "ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2337,
    "title": "What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2338,
    "title": "What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2339,
    "title": "What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2340,
    "title": "Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2341,
    "title": "WinSpot: GUI Grounding Benchmark with Multimodal Large Language Models",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2342,
    "title": "iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2343,
    "title": "𝛿-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation",
    "conference": "ACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2344,
    "title": "***YesBut***: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2345,
    "title": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2346,
    "title": "A Survey of AMR Applications",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2347,
    "title": "A Survey of Ontology Expansion for Conversational Understanding",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2348,
    "title": "A Survey on In-context Learning",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2349,
    "title": "A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Recommendation System Benchmark",
    "subcategory": "Recommendation System Benchmark",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2350,
    "title": "A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2351,
    "title": "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2352,
    "title": "ABSEval: An Agent-based Framework for Script Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2353,
    "title": "APPLS: Evaluating Evaluation Metrics for Plain Language Summarization",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2354,
    "title": "ASL STEMpedia: Dataset and Benchmark for Interpreting STEM Articles",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2355,
    "title": "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2356,
    "title": "C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Privacy",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2357,
    "title": "CELLO: Causal Evaluation of Large Vision-Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2358,
    "title": "Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2359,
    "title": "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2360,
    "title": "CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2361,
    "title": "ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2362,
    "title": "CmdCaliper: A Semantic-Aware Command-Line Embedding Model and Dataset for Security Research",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2363,
    "title": "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2364,
    "title": "Computational Meme Understanding: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2365,
    "title": "CorrSynth - A Correlated Sampling Method for Diverse dataset Generation from LLMs",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2366,
    "title": "Cross-Domain Audio Deepfake Detection: Dataset and Analysis",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2367,
    "title": "D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2368,
    "title": "DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2369,
    "title": "DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2370,
    "title": "Data, Data Everywhere: A Guide for Pretraining Dataset Construction",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2371,
    "title": "DataTales: A Benchmark for Real-World Intelligent Data Narration",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2372,
    "title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2373,
    "title": "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2374,
    "title": "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2375,
    "title": "DocHieNet: A Large and Diverse Dataset for Document Hierarchy Parsing",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2376,
    "title": "ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2377,
    "title": "EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2378,
    "title": "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Time Series",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2379,
    "title": "FAME: Factual Multi-task Model Editing Benchmark",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2380,
    "title": "FOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2381,
    "title": "FairFlow: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2382,
    "title": "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2383,
    "title": "FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2384,
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2385,
    "title": "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2386,
    "title": "GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2387,
    "title": "GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2388,
    "title": "GuardBench: A Large-Scale Benchmark for Guardrail Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2389,
    "title": "Holistic Evaluation for Interleaved Text-and-Image Generation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2390,
    "title": "Is C4 Dataset Enough for Pruning? An Investigation of Calibration Data for LLM Pruning",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2391,
    "title": "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2392,
    "title": "Is This a Bad Table? A Closer Look at the Evaluation of Table Generation from Text",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2393,
    "title": "Knowledge Conflicts for LLMs: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2394,
    "title": "LLM-Evolve: Evaluation for LLM’s Evolving Capability on Benchmarks",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2395,
    "title": "Large Language Models for Data Annotation: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2396,
    "title": "Large Language Models in the Clinic: A Comprehensive Benchmark",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2397,
    "title": "Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2398,
    "title": "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2399,
    "title": "Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2400,
    "title": "LitSearch: A Retrieval Benchmark for Scientific Literature Search",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2401,
    "title": "MINT: A Benchmark for Evaluating Instructed Information Retrieval",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2402,
    "title": "MIPD: Exploring Manipulation and Intention In a Novel Corpus of Polish Disinformation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2403,
    "title": "MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2404,
    "title": "MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2405,
    "title": "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2406,
    "title": "MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2407,
    "title": "Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2408,
    "title": "MiTTenS: A Dataset for Evaluating Gender Mistranslation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2409,
    "title": "Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2410,
    "title": "Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2411,
    "title": "More Insightful Feedback for Tutoring: Enhancing Generation Mechanisms and Automatic Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2412,
    "title": "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2413,
    "title": "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2414,
    "title": "Multilingual Topic Classification in X: Dataset and Analysis",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2415,
    "title": "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2416,
    "title": "NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2417,
    "title": "No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2418,
    "title": "Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2419,
    "title": "PrExMe: Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2420,
    "title": "Puzzle Solving using Reasoning of Large Language Models: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2421,
    "title": "QGEval: Benchmarking Multi-dimensional Evaluation for Question Generation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2422,
    "title": "Rationale-Aware Answer Verification by Pairwise Self-Evaluation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2423,
    "title": "Re-Evaluating Evaluation for Multilingual Summarization",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2424,
    "title": "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2425,
    "title": "Related Work and Citation Text Generation: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2426,
    "title": "RepEval: Effective Text Evaluation with LLM Representation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2427,
    "title": "Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2428,
    "title": "Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2429,
    "title": "Rethinking the Evaluation of In-Context Learning for LLMs",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2430,
    "title": "Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2431,
    "title": "Revisiting Automated Evaluation for Long-form Table Question Answering in the Era of Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2432,
    "title": "RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2433,
    "title": "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2434,
    "title": "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2435,
    "title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2436,
    "title": "SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2437,
    "title": "SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2438,
    "title": "Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2439,
    "title": "Simul-MuST-C: Simultaneous Multilingual Speech Translation Corpus Using Large Language Model",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2440,
    "title": "Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2441,
    "title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2442,
    "title": "The Greatest Good Benchmark: Measuring LLMs’ Alignment with Utilitarian Moral Dilemmas",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2443,
    "title": "The Lou Dataset - Exploring the Impact of Gender-Fair Language in German Text Classification",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2444,
    "title": "The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2445,
    "title": "Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2446,
    "title": "ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2447,
    "title": "Toward Compositional Behavior in Neural Models: A Survey of Current Views",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2448,
    "title": "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2449,
    "title": "Towards Measuring and Modeling “Culture\" in LLMs: A Survey",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2450,
    "title": "Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2451,
    "title": "UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2452,
    "title": "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2453,
    "title": "VGBench: A Comprehensive Benchmark of Vector Graphics Understanding and Generation for Large Language Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2454,
    "title": "VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2455,
    "title": "VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2456,
    "title": "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2457,
    "title": "What do large language models need for machine translation evaluation?",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2458,
    "title": "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2459,
    "title": "xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics",
    "conference": "EMNLP",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2460,
    "title": "$\\mathrm{Wojood^{Relations}}$: Arabic Relation Extraction Corpus and Modeling",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2461,
    "title": "3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2462,
    "title": "A Comprehensive Literary Chinese Reading Comprehension Dataset with an Evidence Curation Based Solution",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2463,
    "title": "A Culturally-diverse Multilingual Multimodal Video Benchmark & Model",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2464,
    "title": "A Fully Probabilistic Perspective on Large Language Model Unlearning: Evaluation and Optimization",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2465,
    "title": "A Multi-Level Benchmark for Causal Language Understanding in Social Media Discourse",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2466,
    "title": "A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2467,
    "title": "A Survey of Link Prediction in N-ary Knowledge Graphs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2468,
    "title": "A Systematic Survey of Automatic Prompt Optimization Techniques",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2469,
    "title": "AFRIDOC-MT: Document-level MT Corpus for African Languages",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2470,
    "title": "Adapting Bias Evaluation to Domain Contexts using Generative Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2471,
    "title": "Adversarial Attacks Against Automated Fact-Checking: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2472,
    "title": "AraEval: An Arabic Multi-Task Evaluation Suite for Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2473,
    "title": "Are Checklists Really Useful for Automatic Evaluation of Generative Tasks?",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2474,
    "title": "Are Large Language Models Chronically Online Surfers? A Dataset for Chinese Internet Meme Explanation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2475,
    "title": "Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2476,
    "title": "Arena-lite: Efficient and Reliable Large Language Model Evaluation via Tournament-Based Direct Comparisons",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2477,
    "title": "ArgCMV: An Argument Summarization Benchmark for the LLM-era",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2478,
    "title": "Argument Summarization and its Evaluation in the Era of Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2479,
    "title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2480,
    "title": "Audio-centric Video Understanding Benchmark without Text Shortcut",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Video Understanding",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2481,
    "title": "BOUQuET : dataset, Benchmark and Open initiative for Universal Quality Evaluation in Translation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2482,
    "title": "BRSpeech-DF: A Deep Fake Synthetic Speech Dataset for Portuguese Zero-Shot TTS",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2483,
    "title": "Benchmark Profiling: Mechanistic Diagnosis of LLM Benchmarks",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2484,
    "title": "Benchmarking Large Language Models Under Data Contamination: A Survey from Static to Dynamic Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2485,
    "title": "Beyond A Single AI Cluster: A Survey of Decentralized LLM Training",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2486,
    "title": "Beyond Demographics: Enhancing Cultural Value Survey Simulation with Multi-Stage Personality-Driven Cognitive Reasoning",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2487,
    "title": "Beyond Human Labels: A Multi-Linguistic Auto-Generated Benchmark for Evaluating Large Language Models on Resume Parsing",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2488,
    "title": "Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "leaderboard"
    ]
  },
  {
    "id": 2489,
    "title": "Bias Mitigation or Cultural Commonsense? Evaluating LLMs with a Japanese Dataset",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2490,
    "title": "Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2491,
    "title": "Building Trust in Clinical LLMs: Bias Analysis and Dataset Transparency",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2492,
    "title": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2493,
    "title": "CLLMate: A Multimodal Benchmark for Weather and Climate Events Forecasting",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2494,
    "title": "CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2495,
    "title": "CMedCalc-Bench: A Fine-Grained Benchmark for Chinese Medical Calculations in LLM",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2496,
    "title": "COAS2W: A Chinese Older-Adults Spoken-to-Written Transformation Corpus with Context Awareness",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2497,
    "title": "CR4-NarrEmote: An Open Vocabulary Dataset of Narrative Emotions Derived Using Citizen Science",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2498,
    "title": "CREPE: Rapid Chest X-ray Report Evaluation by Predicting Multi-category Error Counts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2499,
    "title": "Can Large Language Models Outperform Non-Experts in Poetry Evaluation? A Comparative Study Using the Consensual Assessment Technique",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2500,
    "title": "Chart2Code53: A Large-Scale Diverse and Complex Dataset for Enhancing Chart-to-Code Generation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2501,
    "title": "ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2502,
    "title": "CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Embodied Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2503,
    "title": "ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2504,
    "title": "Co-Eval: Augmenting LLM-based Evaluation with Machine Metrics",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2505,
    "title": "CoVoGER: A Multilingual Multitask Benchmark for Speech-to-text Generative Error Correction with Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2506,
    "title": "Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2507,
    "title": "ComicScene154: A Scene Dataset for Comic Analysis",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2508,
    "title": "CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2509,
    "title": "ComplexTempQA: A 100m Dataset for Complex Temporal Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2510,
    "title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2511,
    "title": "Concept-pedia: a Wide-coverage Semantically-annotated Multimodal Dataset",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2512,
    "title": "CondAmbigQA: A Benchmark and Dataset for Conditional Ambiguous Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2513,
    "title": "CondenseLM: LLMs-driven Text Dataset Condensation via Reward Matching",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2514,
    "title": "Creativity in LLM-based Multi-Agent Systems: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2515,
    "title": "DCR: Quantifying Data Contamination in LLMs Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2516,
    "title": "DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2517,
    "title": "DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2518,
    "title": "DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2519,
    "title": "Debatable Intelligence: Benchmarking LLM Judges via Debate Speech Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2520,
    "title": "DeepWell-Adol: A Scalable Expert-Based Dialogue Corpus for Adolescent Positive Mental Health and Wellbeing Promotion",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2521,
    "title": "Deriving Strategic Market Insights with Large Language Models: A Benchmark for Forward Counterfactual Generation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2522,
    "title": "Detecting Corpus-Level Knowledge Inconsistencies in Wikipedia with Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2523,
    "title": "Disambiguation in Conversational Question Answering in the Era of LLMs and Agents: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2524,
    "title": "DischargeSim: A Simulation Benchmark for Educational Doctor–Patient Communication at Discharge",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2525,
    "title": "Don’t Sweat the Small Stuff: Segment-Level Meta-Evaluation Based on Pairwise Difference Correlation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2526,
    "title": "DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2527,
    "title": "ECC: An Emotion-Cause Conversation Dataset for Empathy Response",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2528,
    "title": "EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2529,
    "title": "Editing Across Languages: A Survey of Multilingual Knowledge Editing",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2530,
    "title": "EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2531,
    "title": "Evaluation and Facilitation of Online Discussions in the LLM Era: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2532,
    "title": "Explainability and Interpretability of Multilingual Large Language Models: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2533,
    "title": "Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2534,
    "title": "Extending Automatic Machine Translation Evaluation to Book-Length Documents",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2535,
    "title": "F2TEval: Human-Aligned Multi-Dimensional Evaluation for Figure-to-Text Task",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2536,
    "title": "FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs' Responsiveness to Human Feedback",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2537,
    "title": "FLUID QA: A Multilingual Benchmark for Figurative Language Usage in Dialogue across English, Chinese, and Korean",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2538,
    "title": "Fann or Flop: A Multigenre, Multiera Benchmark for Arabic Poetry Understanding in LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2539,
    "title": "FinMTEB: Finance Massive Text Embedding Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2540,
    "title": "FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2541,
    "title": "FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2542,
    "title": "Fingerprinting LLMs through Survey Item Factor Correlation: A Case Study on Humor Style Questionnaire",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2543,
    "title": "FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2544,
    "title": "FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2545,
    "title": "Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2546,
    "title": "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2547,
    "title": "F²Bench: An Open-ended Fairness Evaluation Benchmark for LLMs with Factuality Considerations",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2548,
    "title": "GraDaSE: Graph-Based Dataset Search with Examples",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2549,
    "title": "HESEIA: A community-based dataset for evaluating social biases in large language models, co-designed in real school settings in Latin America",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2550,
    "title": "Hanfu-Bench: A Multimodal Benchmark on Cross-Temporal Cultural Understanding and Transcreation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2551,
    "title": "How Do Social Bots Participate in Misinformation Spread? A Comprehensive Dataset and Analysis",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2552,
    "title": "How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2553,
    "title": "How do Language Models Reshape Entity Alignment? A Survey of LM-Driven EA Methods: Advances, Benchmarks, and Future",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2554,
    "title": "IL-PCSR: Legal Corpus for Prior Case and Statute Retrieval",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2555,
    "title": "Incorporating Diverse Perspectives in Cultural Alignment: Survey of Evaluation Benchmarks Through A Three-Dimensional Framework",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2556,
    "title": "InfiniBench: A Benchmark for Large Multi-Modal Models in Long-Form Movies and TV Shows",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2557,
    "title": "Interpretable Text Embeddings and Text Similarity Explanation: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2558,
    "title": "Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2559,
    "title": "KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2560,
    "title": "LASER: An LLM-based ASR Scoring and Evaluation Rubric",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2561,
    "title": "LLM-Driven Completeness and Consistency Evaluation for Cultural Heritage Data Augmentation in Cross-Modal Retrieval",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2562,
    "title": "LORAXBENCH: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2563,
    "title": "LaMP-QA: A Benchmark for Personalized Long-form Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2564,
    "title": "Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2565,
    "title": "Large Language Models for Automated Literature Review: An Evaluation of Reference Generation, Abstract Writing, and Review Composition",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2566,
    "title": "Let’s Play Across Cultures: A Large Multilingual, Multicultural Benchmark for Assessing Language Models' Understanding of Sports",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2567,
    "title": "LiTransProQA: An LLM-based Literary Translation Evaluation Metric with Professional Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2568,
    "title": "LiteraryQA: Towards Effective Evaluation of Long-document Narrative QA",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2569,
    "title": "Long-Form Information Alignment Evaluation Beyond Atomic Facts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2570,
    "title": "M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2571,
    "title": "M-LongDoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Cross-modal Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2572,
    "title": "MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2573,
    "title": "ML-Promise: A Multilingual Dataset for Corporate Promise Verification",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2574,
    "title": "MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2575,
    "title": "MULTIVOX: A Benchmark for Evaluating Voice Assistants for Multimodal Interactions",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2576,
    "title": "Mahānāma: A Unique Testbed for Literary Entity Discovery and Linking",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 2577,
    "title": "Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2578,
    "title": "MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical Capabilities of LLM Tutors",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2579,
    "title": "Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2580,
    "title": "Measuring Risk of Bias in Biomedical Reports: The RoBBR Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2581,
    "title": "MedFact: A Large-scale Chinese Dataset for Evidence-based Medical Fact-checking of LLM Responses",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2582,
    "title": "MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2583,
    "title": "MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2584,
    "title": "MessIRve: A Large-Scale Spanish Information Retrieval Dataset",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2585,
    "title": "Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2586,
    "title": "Mind the Blind Spots: A Focus-Level Evaluation Framework for LLM Reviews",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2587,
    "title": "Mind the Inclusivity Gap: Multilingual Gender-Neutral Translation Evaluation with mGeNTE",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2588,
    "title": "Morables: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2589,
    "title": "MultiLogicNMR(er): A Benchmark and Neural-Symbolic Framework for Non-monotonic Reasoning with Multiple Extensions",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2590,
    "title": "Multimodal Neural Machine Translation: A Survey of the State of the Art",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2591,
    "title": "NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2592,
    "title": "OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2593,
    "title": "OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2594,
    "title": "P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2595,
    "title": "PERSEVAL: A Framework for Perspectivist Classification Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2596,
    "title": "PLLuM-Align: Polish Preference Dataset for Large Language Model Alignment",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2597,
    "title": "PSET: a Phonetics-Semantics Evaluation Testbed",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "testbed"
    ]
  },
  {
    "id": 2598,
    "title": "PakBBQ: A Culturally Adapted Bias Benchmark for QA",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2599,
    "title": "PatentScore: Multi-dimensional Evaluation of LLM-Generated Patent Claims",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2600,
    "title": "PrimeX: A Dataset of Worldview, Opinion, and Explanation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2601,
    "title": "PunMemeCN: A Benchmark to Explore Vision-Language Models' Understanding of Chinese Pun Memes",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2602,
    "title": "QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2603,
    "title": "QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2604,
    "title": "Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2605,
    "title": "ReEvalMed: Rethinking Medical Report Evaluation by Aligning Metrics with Real-World Clinical Judgment",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2606,
    "title": "ReMedy: Learning Machine Translation Evaluation from Human Preferences with Reward Modeling",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2607,
    "title": "ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2608,
    "title": "Reliable Evaluation and Benchmarks for Statement Autoformalization",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2609,
    "title": "Representation Potentials of Foundation Models for Multimodal Alignment: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2610,
    "title": "Rethinking Backdoor Detection Evaluation for Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2611,
    "title": "RoDEval: A Robust Word Sense Disambiguation Evaluation Framework for Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2612,
    "title": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2613,
    "title": "SQLWOZ: A Realistic Task-Oriented Dialogue Dataset with SQL-Based Dialogue State Representation for Complex User Requirements",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2614,
    "title": "STARQA: A Question Answering Dataset for Complex Analytical Reasoning over Structured Databases",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2615,
    "title": "STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2616,
    "title": "SYNC: A Synthetic Long-Context Understanding Benchmark for Controlled Comparisons of Model Capabilities",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2617,
    "title": "Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2618,
    "title": "Scalable and Culturally Specific Stereotype Dataset Construction via Human-LLM Collaboration",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2619,
    "title": "SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2620,
    "title": "Seeing Culture: A Benchmark for Visual Reasoning and Grounding",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2621,
    "title": "Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2622,
    "title": "SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn Evaluation of AI Assistants?",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2623,
    "title": "SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2624,
    "title": "Social Bias in Multilingual Language Models: A Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2625,
    "title": "Structured Moral Reasoning in Language Models: A Value-Grounded Evaluation Framework",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2626,
    "title": "Summarizing Speech: A Comprehensive Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2627,
    "title": "SurveyGen: Quality-Aware Scientific Survey Generation with Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2628,
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2629,
    "title": "T2R-BENCH: A Benchmark for Real World Table-to-Report Task",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2630,
    "title": "TCP: a Benchmark for Temporal Constraint-Based Planning",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2631,
    "title": "TFDP: Token-Efficient Disparity Audits for Autoregressive LLMs via Single-Token Masked Evaluation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2632,
    "title": "TLUE: A Tibetan Language Understanding Evaluation Benchmark",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2633,
    "title": "TSVer: A Benchmark for Fact Verification Against Time-Series Evidence",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2634,
    "title": "TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2635,
    "title": "TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2636,
    "title": "Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2637,
    "title": "The Good, the Bad, and the Debatable: A Survey on the Impacts of Data for In-Context Learning",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2638,
    "title": "The Psychology of Falsehood: A Human-Centric Survey of Misinformation Detection",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2639,
    "title": "The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Medical Imaging",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2640,
    "title": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2641,
    "title": "ToolSafety: A Comprehensive Dataset for Enhancing Safety in LLM-Based Agent Tool Invocations",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2642,
    "title": "Toward Multi-Session Personalized Conversation: A Large-Scale Dataset and Hierarchical Tree Framework for Implicit Reasoning",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2643,
    "title": "Towards Controllable Speech Synthesis in the Era of Large Language Models: A Systematic Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2644,
    "title": "Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2645,
    "title": "Towards Optimal Evaluation Efficiency for Large Language Models",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2646,
    "title": "Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2647,
    "title": "TracSum: A New Benchmark for Aspect-Based Summarization with Sentence-Level Traceability in Medical Domain",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2648,
    "title": "Tracing L1 Interference in English Learner Writing: A Longitudinal Corpus with Error Annotations",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2649,
    "title": "Transitive self-consistency evaluation of NLI models without gold labels",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2650,
    "title": "Trojsten Benchmark: Evaluating LLM Problem-Solving in Slovak STEM Competition Problems",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2651,
    "title": "Trustworthy Medical Question Answering: An Evaluation-Centric Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2652,
    "title": "TurBLiMP: A Turkish Benchmark of Linguistic Minimal Pairs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2653,
    "title": "TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2654,
    "title": "TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2655,
    "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2656,
    "title": "ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Fact-Checking",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2657,
    "title": "Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2658,
    "title": "VisEscape: A Benchmark for Evaluating Exploration-driven Decision-making in Virtual Escape Rooms",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Game & Simulation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2659,
    "title": "VisFinEval: A Scenario-Driven Chinese Multimodal Benchmark for Holistic Financial Understanding",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2660,
    "title": "WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2661,
    "title": "Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Climate",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2662,
    "title": "WebMMU: A Benchmark for Multimodal Multilingual Website Understanding and Code Generation",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2663,
    "title": "What Do Indonesians Really Need from Language Technology? A Nationwide Survey",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2664,
    "title": "XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2665,
    "title": "iVISPAR — An Interactive Visual-Spatial Reasoning Benchmark for VLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2666,
    "title": "seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs",
    "conference": "EMNLP",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2667,
    "title": "A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2668,
    "title": "A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2669,
    "title": "A School Student Essay Corpus for Analyzing Interactions of Argumentative Structure and Quality",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2670,
    "title": "A Survey of Confidence Estimation and Calibration in Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2671,
    "title": "A Survey of Meaning Representations – From Theory to Practical Utility",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2672,
    "title": "A diverse Multilingual News Headlines Dataset from around the World",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2673,
    "title": "ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2674,
    "title": "AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2675,
    "title": "AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2676,
    "title": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2677,
    "title": "Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2678,
    "title": "Automatic, Meta and Human Evaluation for Multimodal Summarization with Multimodal Output",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2679,
    "title": "BUST: Benchmark for the evaluation of detectors of LLM-Generated Text",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2680,
    "title": "Benchmark Transparency: Measuring the Impact of Data on Evaluation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2681,
    "title": "Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2682,
    "title": "Beyond Read-Only: Crafting a Comprehensive Chinese Text-to-SQL Dataset for Database Manipulation and Query",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2683,
    "title": "BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2684,
    "title": "Branch-Solve-Merge Improves Large Language Model Evaluation and Generation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2685,
    "title": "CCSum: A Large-Scale and High-Quality Dataset for Abstractive News Summarization",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2686,
    "title": "CLEAN–EVAL: Clean Evaluation on Contaminated Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2687,
    "title": "CMB: A Comprehensive Medical Benchmark in Chinese",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2688,
    "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2689,
    "title": "Carpe diem: On the Evaluation of World Knowledge in Lifelong Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2690,
    "title": "CoUDA: Coherence Evaluation via Unified Data Augmentation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2691,
    "title": "Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2692,
    "title": "Corpus Considerations for Annotator Modeling and Scaling",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2693,
    "title": "Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2694,
    "title": "Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2695,
    "title": "DiLM: Distilling Dataset into Language Model for Text-level Dataset Distillation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2696,
    "title": "DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2697,
    "title": "Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of Depression Detection on Twitter",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2698,
    "title": "Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2699,
    "title": "Enhancing Argument Summarization: Prioritizing Exhaustiveness in Key Point Generation and Introducing an Automatic Coverage Evaluation Metric",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2700,
    "title": "Exploring Cross-Cultural Differences in English Hate Speech Annotations: From Dataset Construction to Analysis",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2701,
    "title": "FIRE: A Dataset for Financial Relation Extraction",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2702,
    "title": "FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2703,
    "title": "Few-TK: A Dataset for Few-shot Scientific Typed Keyphrase Recognition",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2704,
    "title": "GenRES: Rethinking Evaluation for Generative Relation Extraction in the Era of Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2705,
    "title": "HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2706,
    "title": "HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2707,
    "title": "Improving Adversarial Data Collection by Supporting Annotators: Lessons from GAHD, a German Hate Speech Dataset",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2708,
    "title": "IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2709,
    "title": "IndiSentiment140: Sentiment Analysis Dataset for Indian Languages with Emphasis on Low-Resource Languages using Machine Translation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2710,
    "title": "InstructEval: Systematic Evaluation of Instruction Selection Methods",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2711,
    "title": "Instruction-following Evaluation through Verbalizer Manipulation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2712,
    "title": "Is Reference Necessary in the Evaluation of NLG Systems? When and Where?",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2713,
    "title": "LEAF: Language Learners' English Essays and Feedback Corpus",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2714,
    "title": "Long-form evaluation of model editing",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2715,
    "title": "Low-Cost Generation and Evaluation of Dictionary Example Sentences",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2716,
    "title": "M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2717,
    "title": "MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2718,
    "title": "MCECR: A Novel Dataset for Multilingual Cross-Document Event Coreference Resolution",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2719,
    "title": "METAL: Towards Multilingual Meta-Evaluation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2720,
    "title": "MOSAICo: a Multilingual Open-text Semantically Annotated Interlinked Corpus",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2721,
    "title": "MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2722,
    "title": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Distillation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2723,
    "title": "NLP for Counterspeech against Hate: A Survey and How-To Guide",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2724,
    "title": "Native Language Identification in Texts: A Survey",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2725,
    "title": "Not All Metrics Are Guilty: Improving NLG Evaluation by Diversifying References",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2726,
    "title": "ODD: A Benchmark Dataset for the Natural Language Processing Based Opioid Related Aberrant Behavior Detection",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2727,
    "title": "On the Role of Summary Content Units in Text Summarization Evaluation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2728,
    "title": "POLYIE: A Dataset of Information Extraction from Polymer Material Scientific Literature",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2729,
    "title": "PRODIGy: a PROfile-based DIalogue Generation dataset",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2730,
    "title": "QualEval: Qualitative Evaluation for Model Improvement",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2731,
    "title": "RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural Conversations",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2732,
    "title": "ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large Language Models via Transferable Adversarial Attacks",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2733,
    "title": "RoDia: A New Dataset for Romanian Dialect Identification from Speech",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2734,
    "title": "S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2735,
    "title": "SELF-EXPERTISE: Knowledge-based Instruction Dataset Augmentation for a Legal Expert Language Model",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2736,
    "title": "SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2737,
    "title": "SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2738,
    "title": "SocREval: Large Language Models with the Socratic Method for Reference-free Reasoning Evaluation",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Document Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2739,
    "title": "SportQA: A Benchmark for Sports Understanding in Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2740,
    "title": "SuperGLEBer: German Language Understanding Evaluation Benchmark",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2741,
    "title": "UGIF-DataSet: A New Dataset for Cross-lingual, Cross-modal Sequential actions on the UI",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2742,
    "title": "Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2743,
    "title": "VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for Vietnamese Natural Language Understanding",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2744,
    "title": "ViGLUE: A Vietnamese General Language Understanding Benchmark and Analysis of Vietnamese Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2745,
    "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2746,
    "title": "XNLIeu: a dataset for cross-lingual NLI in Basque",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2747,
    "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "test suite"
    ]
  },
  {
    "id": 2748,
    "title": "XferBench: a Data-Driven Benchmark for Emergent Language",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2749,
    "title": "ZSEE: A Dataset based on Zeolite Synthesis Event Extraction for Automated Synthesis Platform",
    "conference": "NAACL",
    "year": 2024,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2750,
    "title": "A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision-Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2751,
    "title": "A Comprehensive Survey of Contemporary Arabic Sentiment Analysis: Methods, Challenges, and Future Directions",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2752,
    "title": "A Large-Scale Benchmark for Vietnamese Sentence Paraphrases",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2753,
    "title": "A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2754,
    "title": "A Survey of NLP Progress in Sino-Tibetan Low-Resource Languages",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2755,
    "title": "A Survey of QUD Models for Discourse Processing",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2756,
    "title": "A Survey to Recent Progress Towards Understanding In-Context Learning",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2757,
    "title": "ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2758,
    "title": "AEGIS2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2759,
    "title": "AI-Assisted Human Evaluation of Machine Translation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2760,
    "title": "ALERT: An LLM-powered Benchmark for Automatic Evaluation of Recommendation Explanations",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Recommendation System Benchmark",
    "subcategory": "Recommendation System Benchmark",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2761,
    "title": "AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2762,
    "title": "AdTEC: A Unified Benchmark for Evaluating Text Quality in Search Engine Advertising",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Web Search",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2763,
    "title": "Adapting Sentence-level Automatic Metrics for Document-level Simplification Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2764,
    "title": "Advancing Persian LLM Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2765,
    "title": "Advocating Character Error Rate for Multilingual ASR Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2766,
    "title": "Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2767,
    "title": "An Annotated Dataset of Errors in Premodern Greek and Baselines for Detecting Them",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2768,
    "title": "Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2769,
    "title": "Arabic Dataset for LLM Safeguard Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2770,
    "title": "Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2771,
    "title": "Are Multimodal LLMs Robust Against Adversarial Perturbations? RoMMath: A Systematic Evaluation on Multimodal Math Reasoning",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2772,
    "title": "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2773,
    "title": "AudioBench: A Universal Benchmark for Audio Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Audio-Visual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2774,
    "title": "AutoEval-ToD: Automated Evaluation of Task-oriented Dialog Systems",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2775,
    "title": "Automatic Evaluation of Healthcare LLMs Beyond Question-Answering",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2776,
    "title": "BanNERD: A Benchmark Dataset and Context-Driven Approach for Bangla Named Entity Recognition",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2777,
    "title": "BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2778,
    "title": "Beemo: Benchmark of Expert-edited Machine-generated Outputs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2779,
    "title": "Beyond Benchmarks: Building a Richer Cross-Document Event Coreference Dataset with Decontextualization",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2780,
    "title": "Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2781,
    "title": "BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2782,
    "title": "Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2783,
    "title": "CAMEL-Bench: A Comprehensive Arabic LMM Benchmark",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2784,
    "title": "CAMIEval: Enhancing NLG Evaluation through Multidimensional Comparative Instruction-Following Analysis",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2785,
    "title": "CAPE: A Chinese Dataset for Appraisal-based Emotional Generation in Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2786,
    "title": "CAST: Corpus-Aware Self-similarity Enhanced Topic modelling",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2787,
    "title": "CA\\*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2788,
    "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2789,
    "title": "CLERC: A Dataset for U. S. Legal Case Retrieval and Retrieval-Augmented Analysis Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2790,
    "title": "CRScore: Grounding Automated Evaluation of Code Review Comments in Code Claims and Smells",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Software Engineering Benchmark",
    "subcategory": "Software Evolution",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2791,
    "title": "CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2792,
    "title": "Capturing Human Cognitive Styles with Language: Towards an Experimental Evaluation Paradigm",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2793,
    "title": "CaseSumm: A Large-Scale Dataset for Long-Context Summarization from U.S. Supreme Court Opinions",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2794,
    "title": "Causal Inference with Large Language Model: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2795,
    "title": "ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2796,
    "title": "Challenges in Trustworthy Human Evaluation of Chatbots",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2797,
    "title": "Chatbot Arena Estimate: towards a generalized performance benchmark for LLM capabilities",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2798,
    "title": "CollagePrompt: A Benchmark for Budget-Friendly Visual Recognition with GPT-4V",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Image Recognition & Detection",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2799,
    "title": "Communication Makes Perfect: Persuasion Dataset Construction via Multi-LLM Communication",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2800,
    "title": "ConMeC: A Dataset for Metonymy Resolution with Common Nouns",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2801,
    "title": "ConQRet: A New Benchmark for Fine-Grained Automatic Evaluation of Retrieval Augmented Computational Argumentation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2802,
    "title": "Contextual Metric Meta-Evaluation by Measuring Local Metric Accuracy",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2803,
    "title": "Cracking the Code: Multi-domain LLM Evaluation on Real-World Professional Exams in Indonesia",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2804,
    "title": "DHP Benchmark: Are LLMs Good NLG Evaluators?",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2805,
    "title": "Discourse-Driven Evaluation: Unveiling Factual Inconsistency in Long Document Summarization",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2806,
    "title": "Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation",
      "survey"
    ]
  },
  {
    "id": 2807,
    "title": "DomainSum: A Hierarchical Benchmark for Fine-Grained Domain Shift in Abstractive Text Summarization",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2808,
    "title": "Emo3D: Metric and Benchmarking Dataset for 3D Facial Expression Generation from Emotion Description",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "3D & Point Cloud",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2809,
    "title": "Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Dataset Construction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2810,
    "title": "Evaluating Input Feature Explanations through a Unified Diagnostic Evaluation Framework",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2811,
    "title": "Evaluation of LLMs-based Hidden States as Author Representations for Psychological Human-Centered NLP Tasks",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2812,
    "title": "Evaluation of Multilingual Image Captioning: How far can we get with CLIP models?",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2813,
    "title": "Examining Spanish Counseling with MIDAS: a Motivational Interviewing Dataset in Spanish",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2814,
    "title": "Explore the Reasoning Capability of LLMs in the Chess Testbed",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "testbed"
    ]
  },
  {
    "id": 2815,
    "title": "FLEURS-ASL: Including American Sign Language in Massively Multilingual Multitask Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2816,
    "title": "FLEX: A Benchmark for Evaluating Robustness of Fairness in Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2817,
    "title": "FLEX: Expert-level False-Less EXecution Metric for Text-to-SQL Benchmark",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2818,
    "title": "Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2819,
    "title": "FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2820,
    "title": "Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial Stance for Summary Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2821,
    "title": "Familarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Information Retrieval Benchmark",
    "subcategory": "Entity Extraction",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2822,
    "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2823,
    "title": "FinNLI: Novel Dataset for Multi-Genre Financial Natural Language Inference Benchmarking",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2824,
    "title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2825,
    "title": "GameTox: A Comprehensive Dataset and Analysis for Enhanced Toxicity Detection in Online Gaming Communities",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2826,
    "title": "GroundCocoa: A Benchmark for Evaluating Compositional & Conditional Reasoning in Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2827,
    "title": "HISTOIRESMORALES: A French Dataset for Assessing Moral Alignment",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2828,
    "title": "Hard Emotion Test Evaluation Sets for Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2829,
    "title": "How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2830,
    "title": "How LLMs React to Industrial Spatio-Temporal Data? Assessing Hallucination with a Novel Traffic Incident Benchmark Dataset",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2831,
    "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2832,
    "title": "IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2833,
    "title": "INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question Answering capability of LLMs for Indic Languages",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2834,
    "title": "ITALIC: An Italian Culture-Aware Natural Language Benchmark",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2835,
    "title": "IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark for LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2836,
    "title": "Ihquin tlahtouah in Tetelahtzincocah: An annotated, multi-purpose audio and text corpus of Western Sierra Puebla Nahuatl",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Annotation",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2837,
    "title": "Improving Model Evaluation using SMART Filtering of Benchmark Datasets",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2838,
    "title": "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2839,
    "title": "Is your benchmark truly adversarial? AdvScore: Evaluating Human-Grounded Adversarialness",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2840,
    "title": "It Is Not Only the Negative that Deserves Attention! Understanding, Generation & Evaluation of (Positive) Moderation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2841,
    "title": "JAWAHER: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2842,
    "title": "JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2843,
    "title": "KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2844,
    "title": "KODIS: A Multicultural Dispute Resolution Dialogue Corpus",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2845,
    "title": "Knowledge Graph Guided Evaluation of Abstention Techniques",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Graph & Network Benchmark",
    "subcategory": "Knowledge Graph",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2846,
    "title": "KwaiChat: A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue Corpus",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2847,
    "title": "LLMs Are Not Intelligent Thinkers: Introducing Mathematical Topic Tree Benchmark for Comprehensive Evaluation of LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2848,
    "title": "LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2849,
    "title": "LMOD: A Large Multimodal Ophthalmology Dataset and Benchmark for Large Vision-Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2850,
    "title": "LOFT: Scalable and More Realistic Long-Context Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2851,
    "title": "Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2852,
    "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2853,
    "title": "Large-Scale Corpus Construction and Retrieval-Augmented Generation for Ancient Chinese Poetry: New Method and Data Insights",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2854,
    "title": "Lessons from a User Experience Evaluation of NLP Interfaces",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2855,
    "title": "LibEvolutionEval: A Benchmark and Study for Version-Specific Code Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2856,
    "title": "LongLeader: A Comprehensive Leaderboard for Large Language Models in Long-context Scenarios",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "leaderboard"
    ]
  },
  {
    "id": 2857,
    "title": "M-IFEval: Multilingual Instruction-Following Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2858,
    "title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2859,
    "title": "MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2860,
    "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2861,
    "title": "MILU: A Multi-task Indic Language Understanding Benchmark",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2862,
    "title": "MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2863,
    "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "RAG Pipeline",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2864,
    "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2865,
    "title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2866,
    "title": "MRE-MI: A Multi-image Dataset for Multimodal Relation Extraction in Social Media Posts",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2867,
    "title": "MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2868,
    "title": "Matina: A Large-Scale 73B Token Persian Text Corpus",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2869,
    "title": "MedEureka: A Medical Domain Benchmark for Multi-Granularity and Multi-Data-Type Embedding-Based Retrieval",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2870,
    "title": "MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Medical",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2871,
    "title": "Multilingual Blending: Large Language Model Safety Alignment Evaluation with Language Mixture",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2872,
    "title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2873,
    "title": "Natural Language Processing for Human Resources: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2874,
    "title": "Omni-Chart-600K: A Comprehensive Dataset of Chart Types for Chart Understanding",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2875,
    "title": "On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Hallucination",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2876,
    "title": "Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2877,
    "title": "Open-World Evaluation for Retrieving Diverse Perspectives",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2878,
    "title": "PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Database & Data Management Benchmark",
    "subcategory": "Query Processing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2879,
    "title": "PROMPTEVALS: A Dataset of Assertions and Guardrails for Custom Production Large Language Model Pipelines",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2880,
    "title": "Patent-CR: A Dataset for Patent Claim Revision",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2881,
    "title": "PeerQA: A Scientific Question Answering Dataset from Peer Reviews",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Science",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2882,
    "title": "PerCul: A Story-Driven Cultural Evaluation of LLMs in Persian",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2883,
    "title": "PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2884,
    "title": "Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2885,
    "title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2886,
    "title": "ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2887,
    "title": "Prompt Compression for Large Language Models: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2888,
    "title": "PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2889,
    "title": "ProverbEval: Exploring LLM Evaluation Challenges for Low-resource Language Understanding",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2890,
    "title": "QSpell 250K: A Large-Scale, Practical Dataset for Chinese Search Query Spell Correction",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2891,
    "title": "ReIFE: Re-evaluating Instruction-Following Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2892,
    "title": "RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Vision & CV Benchmark",
    "subcategory": "Generation & Editing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2893,
    "title": "SCORE: Systematic COnsistency and Robustness Evaluation for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2894,
    "title": "SEEval: Advancing LLM Text Evaluation Efficiency and Accuracy through Self-Explanation Prompting",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2895,
    "title": "SafetyQuizzer: Timely and Dynamic Evaluation on the Safety of LLMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2896,
    "title": "Seeds of Discourse: A Multilingual Corpus of Direct Quotations from African Media on Agricultural Biotechnologies",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2897,
    "title": "Self-Training Meets Consistency: Improving LLMs’ Reasoning with Consistency-Driven Rationale Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Reasoning & Math",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2898,
    "title": "Single Ground Truth Is Not Enough: Adding Flexibility to Aspect-Based Sentiment Analysis Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2899,
    "title": "Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2900,
    "title": "SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2901,
    "title": "TabComp: A Dataset for Visual Table Reading Comprehension",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Knowledge & QA",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2902,
    "title": "Tackling Social Bias against the Poor: a Dataset and a Taxonomy on Aporophobia",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2903,
    "title": "Taxi1500: A Dataset for Multilingual Text Classification in 1500 Languages",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2904,
    "title": "The BiGGen Bench: A Principled Benchmark for Fine-grained Evaluation of Language Models with Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Data & Evaluation Methodology",
    "subcategory": "Evaluation Frameworks",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2905,
    "title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2906,
    "title": "The Promises and Pitfalls of LLM Annotations in Dataset Labeling: a Case Study on Media Bias Detection",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2907,
    "title": "The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2908,
    "title": "The State and Fate of Summarization Datasets: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2909,
    "title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Tool Use",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2910,
    "title": "Towards Automatic Evaluation for Image Transcreation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2911,
    "title": "Towards Better Multi-task Learning: A Framework for Optimizing Dataset Combinations in Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "General NLU",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2912,
    "title": "Towards Rationality in Language and Multimodal Agents: A Survey",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2913,
    "title": "Tricking Retrievers with Influential Tokens: An Efficient Black-Box Corpus Poisoning Attack",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Retrieval & RAG Benchmark",
    "subcategory": "Dense/Sparse Retrieval",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "corpus"
    ]
  },
  {
    "id": 2914,
    "title": "TurkingBench: A Challenge Benchmark for Web Agents",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Agent & Planning Benchmark",
    "subcategory": "Web/OS Agent",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2915,
    "title": "TurtleBench: A Visual Programming Benchmark in Turtle Geometry",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2916,
    "title": "UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Finance",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2917,
    "title": "UCL-Bench: A Chinese User-Centric Legal Benchmark for Large Language Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Legal",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2918,
    "title": "Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Translation & Multilingual",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "leaderboard"
    ]
  },
  {
    "id": 2919,
    "title": "Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Domain-Specific Benchmark",
    "subcategory": "Education",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2920,
    "title": "VANE-Bench: Video Anomaly Evaluation Benchmark for Conversational LMMs",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Dialogue",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2921,
    "title": "VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Summarization & Writing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "dataset"
    ]
  },
  {
    "id": 2922,
    "title": "WebQuality: A Large-scale Multi-modal Web Page Quality Assessment Dataset with Multiple Scoring Dimensions",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2923,
    "title": "What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free Text-Image Corruption and Evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2924,
    "title": "Where is this coming from? Making groundedness count in the evaluation of Document VQA models",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2925,
    "title": "WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2926,
    "title": "WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "Multimodal Benchmark",
    "subcategory": "Vision-Language",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset",
      "evaluation"
    ]
  },
  {
    "id": 2927,
    "title": "mHumanEval - A Multilingual Benchmark to Evaluate Large Language Models for Code Generation",
    "conference": "NAACL",
    "year": 2025,
    "domain": "NLP",
    "category": "LLM & NLP Benchmark",
    "subcategory": "Code",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2928,
    "title": "A Systematic Evaluation of Large Code Models in API Suggestion: When, Which, and How",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2929,
    "title": "ComplexCodeEval: A Benchmark for Evaluating Large Code Models on More Complex Code",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2930,
    "title": "Evaluation of Version Control Merge Tools",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Software Evolution",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2931,
    "title": "GPTZoo: A Large-scale Dataset of GPTs for the Research Community",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "SE for AI",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2932,
    "title": "JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2933,
    "title": "LLMs and Prompting for Unit Test Generation: A Large-Scale Evaluation",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2934,
    "title": "Navigating Mobile Testing Evaluation: A Comprehensive Statistical Analysis of Android GUI Testing Metrics",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2935,
    "title": "On the Evaluation of Large Language Models in Unit Test Generation",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2936,
    "title": "VulZoo: A Comprehensive Vulnerability Intelligence Dataset",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2937,
    "title": "What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners' Perspective",
    "conference": "ASE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "SE for AI",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2938,
    "title": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2939,
    "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2940,
    "title": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2941,
    "title": "An Agent-based Evaluation Framework for Complex Code Generation",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2942,
    "title": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2943,
    "title": "Code-DiTing: Automatic Evaluation of Code Generation without References or Test Cases",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2944,
    "title": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "test suite"
    ]
  },
  {
    "id": 2945,
    "title": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2946,
    "title": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2947,
    "title": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2948,
    "title": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2949,
    "title": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2950,
    "title": "R3-Bench: Reproducible Real-world Reverse Engineering Dataset for Symbol Recovery",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2951,
    "title": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2952,
    "title": "RustRepoTrans: Repository-level Context Code Translation Benchmark Targeting Rust",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2953,
    "title": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2954,
    "title": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
    "conference": "ASE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2955,
    "title": "A Critical Review of Common Log Data Sets Used for Evaluation of Sequence-Based Anomaly Detection Techniques",
    "conference": "FSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2956,
    "title": "A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault Localization",
    "conference": "FSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2957,
    "title": "AI-Assisted Code Authoring at Scale: Fine-Tuning, Deploying, and Mixed Methods Evaluation",
    "conference": "FSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2958,
    "title": "DyPyBench: A Benchmark of Executable Python Software",
    "conference": "FSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2959,
    "title": "Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks",
    "conference": "FSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2960,
    "title": "COFFE: A Code Efficiency Benchmark for Code Generation",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2961,
    "title": "Causality-Aided Evaluation and Explanation of Large Language Model-Based Code Generation",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2962,
    "title": "DeCoMa: Detecting and Purifying Code Dataset Watermarks through Dual Channel Code Abstraction",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2963,
    "title": "Gleipner: A Benchmark for Gadget Chain Detection in Java Deserialization Vulnerabilities",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2964,
    "title": "LogBase: A Large-Scale Benchmark for Semantic Log Parsing",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2965,
    "title": "OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Software Evolution",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2966,
    "title": "S-Eval: Towards Automated and Comprehensive Safety Evaluation for Large Language Models",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Jailbreak & Red Teaming",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2967,
    "title": "SoK: A Taxonomic Analysis of DeFi Rug Pulls: Types, Dataset, and Tool Assessment",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2968,
    "title": "The First Prompt Counts the Most! An Evaluation of Large Language Models on Iterative Example-Based Code Generation",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2969,
    "title": "Understanding Industry Perspectives of Static Application Security Testing (SAST) Evaluation",
    "conference": "FSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2970,
    "title": "A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2971,
    "title": "A User-centered Security Evaluation of Copilot",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2972,
    "title": "Are Prompt Engineering and TODO Comments Friends or Foes? An Evaluation on GitHub Copilot",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2973,
    "title": "CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2974,
    "title": "Language Models for Code Completion: A Practical Evaluation",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2975,
    "title": "SCTrans: Constructing a Large Public Scenario Dataset for Simulation Testing of Autonomous Driving Systems",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2976,
    "title": "Unraveling the Drivers of Sense of Belonging in Software Delivery Teams: Insights from a Large-Scale Survey",
    "conference": "ICSE",
    "year": 2024,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  },
  {
    "id": 2977,
    "title": "HumanEvo: An Evolution-Aware Benchmark for More Realistic Evaluation of Repository-Level Code Generation",
    "conference": "ICSE",
    "year": 2025,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Software Evolution",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2978,
    "title": "Defects4REST: A Benchmark of Real-World Defects to Enable Controlled Testing and Debugging Studies for REST APIs",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2979,
    "title": "FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2980,
    "title": "FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Software Evolution",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2981,
    "title": "Is Call Graph Pruning Really Effective? An Empirical Re-evaluation",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2982,
    "title": "JEDI: Java Evaluation of Declarative and Imperative Queries - Benchmarking the Java Stream API",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2983,
    "title": "On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "SE for AI",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2984,
    "title": "Rethinking the Evaluation of Secure Code Generation",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2985,
    "title": "SeRe: A Security-Related Code Review Dataset Aligned with Real-World Review Activities",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Vulnerability & Security",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2986,
    "title": "Synthetic Repo-level Bug Dataset for Training Automated Program Repair Models",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "dataset"
    ]
  },
  {
    "id": 2987,
    "title": "Top General Performance = Top Domain Performance? DomainCodeBench: A Multi-domain Code Generation Benchmark",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Code Analysis & Testing",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark"
    ]
  },
  {
    "id": 2988,
    "title": "Toward Systematic Counterfactual Fairness Evaluation of Large Language Models: The CAFFE Framework",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "SE for AI",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "evaluation"
    ]
  },
  {
    "id": 2989,
    "title": "VADA: A Multicultural Benchmark for Value-Aware Data Generation and Alignment Evaluation in LLMs",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Safety, Alignment & Trustworthiness",
    "subcategory": "Fairness & Bias",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "benchmark",
      "evaluation"
    ]
  },
  {
    "id": 2990,
    "title": "Weak Programmers Need Not Apply, LLMs Welcome! Survey Screening in the AI Era",
    "conference": "ICSE",
    "year": 2026,
    "domain": "SE",
    "category": "Software Engineering Benchmark",
    "subcategory": "Empirical SE Studies",
    "url": "",
    "abstract": "",
    "matchedKeywords": [
      "survey"
    ]
  }
]